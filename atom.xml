<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>我的学习记录</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.updatecg.xin/"/>
  <updated>2021-09-03T09:41:46.830Z</updated>
  <id>http://www.updatecg.xin/</id>
  
  <author>
    <name>陈 武</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>虚拟币-ETH(Ethereum)</title>
    <link href="http://www.updatecg.xin/2021/09/01/%E8%99%9A%E6%8B%9F%E5%B8%81-ETH/"/>
    <id>http://www.updatecg.xin/2021/09/01/虚拟币-ETH/</id>
    <published>2021-09-01T07:18:00.000Z</published>
    <updated>2021-09-03T09:41:46.830Z</updated>
    
    <content type="html"><![CDATA[<h2 id="以太坊简介"><a href="#以太坊简介" class="headerlink" title="以太坊简介"></a>以太坊简介</h2><blockquote><p>以太坊是一个为去中心化应用（DApp）而生的全球开源平台，官方地址》<a href="https://ethereum.org/zh" target="_blank" rel="noopener">https://ethereum.org/zh</a></p></blockquote><p>以太坊主网于 2015 年上线，是世界领先的可编程区块链。和其它区块链一样，以太坊也拥有原生加密货币，叫作 Ether (ETH)。 ETH 是一种数字货币， 和比特币有许多相同的功能。</p><h2 id="以太坊历史"><a href="#以太坊历史" class="headerlink" title="以太坊历史"></a>以太坊历史</h2><table><thead><tr><th>年份</th><th>历史名</th><th>区块高度</th><th>价格</th><th>概述</th><th>改进提议EIP</th></tr></thead><tbody><tr><td>2013年11月27日</td><td>白皮书发布</td><td>0</td><td>$0</td><td>该项目在 2015 年启动。但早在 2013 年，以太坊的创始人 维塔利克·巴特林 就发表了介绍性<a href="https://ethereum.org/zh/whitepaper/" target="_blank" rel="noopener">[文章]</a>。</td></tr><tr><td>2014年4月1日</td><td>黄皮书发布</td><td>0</td><td>$0</td><td>以太坊白皮书概要性地介绍了以太坊，以太坊黄皮书通过大量的定义和公式详细地描述了以太坊的技术实现的<a href="https://github.com/ethereum/yellowpaper" target="_blank" rel="noopener">[文章]</a>。</td></tr><tr><td>2014年7月22日 - 9月2日</td><td>公开招募</td><td>0</td><td>$0</td><td>以太币预售为期 42 天。 你可以使用比特币进行购买。<a href="https://blog.ethereum.org/2014/07/22/launching-the-ether-sale/" target="_blank" rel="noopener">[请阅读以太坊基金会公告]</a></td></tr><tr><td>2015-7月-30日</td><td>Frontier</td><td>0</td><td>$0</td><td>边境是以太坊的最初版本，但在上面能做的事情很少。 它是在 Olympic 测试阶段之后进行的。 它面向技术用户，特别是开发者。 每个区块有一个 gas 限制为 5,000。 这个“缓冲”期使矿工能够开始工作，并使早期采用者能够安装他们的客户端而不必“匆忙”。</td></tr><tr><td>2015-9月-7日</td><td>Frontier thawing</td><td>200000</td><td>$1.24 USD</td><td>Frontier thawing 分叉取消了每个区块 5,000 gas 的限制，并将默认的 gas 价格设置为 51 gwei。 这开启了交易功能——交易需要 21,000 gas。</td></tr><tr><td>2016-3月-14日</td><td>Homestead</td><td>1150000</td><td>$12.50 USD</td><td>展望未来的 Homestead 分叉。 其中包括若干协议修改和网络变更，使以太坊能够进一步进行网络升级。</td><td>EIP-2\EIP-7\EIP-8 <a href="https://ethereum.org/zh/eips/" target="_blank" rel="noopener">[EIP详情]</a></td></tr><tr><td>2016-7月-20日</td><td>DAO 分叉</td><td>1920000</td><td>$12.54 USD</td><td>DAO 分叉是为了解决 2016 DAO 攻击 ，当时一个不安全 DAO 合约被黑客盗走了超过 3 百万个 ETH。 这个分叉将资金从错误的合约转移到 这个只有 withDraw 方法的新合约。 任何损失资金的人都可以在他们的钱包中为每 100 个 DAO 代币提取 1 个 ETH。</td></tr><tr><td>2016-10月-18日</td><td>Tangerine Whistle</td><td>2463000</td><td>$12.50 USD</td><td>处理与价格低廉的操作代码有关的紧急网络健康问题</td><td>EIP-150\EIP-158</td></tr><tr><td>2016-11月-22日</td><td>Spurious Dragon</td><td>2675000</td><td>$9.84 USD</td><td>1、调整操作码的价格以防止今后对网络的攻击。 2、启用区块链状态的“区块链减重”。 3、添加重放攻击保护。</td><td>EIP-155\EIP-160\EIP-161\EIP-170</td></tr><tr><td>2017-10月-16日</td><td>Byzantium</td><td>4370000</td><td>$334.23 USD</td><td>拜占庭分叉: 1、将区块挖矿奖励从 5 ETH 减少到 3 ETH  2、将<a href="https://ethereum.org/zh/glossary/#difficulty-bomb" target="_blank" rel="noopener">[难度炸弹]</a>升级延迟一年 3、增加了调用其他合约的能力 4、添加加密算法以允许[第二层扩容]</td><td>EIP-140\EIP-658\EIP-196\EIP-197\EIP-198\EIP-211\EIP-214\EIP-100\EIP-649</td></tr><tr><td>2018-2月-28日</td><td>君士坦丁堡升级</td><td>7280000</td><td>$136.29 USD</td><td>君士坦丁堡分叉: 1、保证在 POS 实现前区块不会被冻结 2、优化 EVM 数据存储操作的 Gas 耗用量计量方式 3、添加了与尚未创建的地址进行交互的能力</td><td>EIP-145\EIP-1014\EIP-1052\EIP-1234</td></tr><tr><td>2019-9月-8日</td><td>伊斯坦布尔升级</td><td>9069000</td><td>$151.06 USD</td><td>伊斯坦布尔分叉: 1、优化 EVM 数据存储操作的 gas 耗用量计量方式。 2、提高拒绝服务（DoS）攻击的弹性 3、使基于 SNARK 和 STARK 的 二层扩容第二层方案性能更佳 4、使以太坊和 Zcash 能够互操作 5、让合约能够引入更有创造性的功能</td><td>EIP-152\EIP-1108\EIP-1344\EIP-1884\EIP-2028\EIP-2200</td></tr><tr><td>2020-1月-2日</td><td>缪尔冰川升级</td><td>9200000</td><td>$127.18 USD</td><td>缪尔冰川分叉将 难度炸弹 的启动延迟。 增加Pow 的区块难度可能会增加发送交易和使用数据库的等待时间，从而降低以太坊的可用性。</td><td>EIP-2384</td></tr><tr><td>2020-10月-14日</td><td>质押合约部署</td><td>11052984</td><td>$379.04 USD</td><td><a href="https://ethereum.org/zh/eth2/staking/" target="_blank" rel="noopener">[质押合约]</a>将质押引入以太坊生态系统。 虽然这只是一个 ETH1.0 主网 合约，但它直接影响了启动 信标链重要的 Eth2 升级。</td></tr><tr><td>2020-12月-1日</td><td>信标链的起源</td><td>1 (信标链区块高度)</td><td>$586.23 USD</td><td><a href="https://ethereum.org/zh/eth2/beacon-chain/" target="_blank" rel="noopener">[信标链]</a>需要 16384 个 ETH 并且每个节点拥有 32 个 ETH 来保证网络的安全。 2020 年 11 月 27 日确定规则，并且在 2020 年 12 月 1 日开始生产区块。 这是实现 Eth2.0 愿景的重要一步。</td></tr><tr><td>2021-8月-5日</td><td>伦敦升级</td><td>1296500</td><td>$3292.71 USD</td><td>「伦敦」升级顺利完成，作为以太坊2.0全面部署前的最后一次全网升级，「伦敦」重要性不言而喻，尤其是以太坊改进提案EIP-1559的激活，不仅消除了用户通过投标系统竞争区块包含的方法，更会从根本上改变以太坊交易机制和ETH供应量。</td></tr></tbody></table><p>总结：2014年实行预售，可以从2016年到2017年价格上涨，然后2020年到2021年价格上涨。每次升级都会影响价格的波动。2020年12月上线的信标链，只是以太坊2.0“阶段 0”迈出的第一步，「伦敦」升级之后将会进入到「阶段 1」（最初预计是2021年完成，但目前几乎可以肯定会延迟到2022年），而 ETH 1.0ETH 2.0 的完整升级则可能需要5-10年。个人觉得可以买币，放个几年。</p><h2 id="以太坊智能合约"><a href="#以太坊智能合约" class="headerlink" title="以太坊智能合约"></a>以太坊智能合约</h2><blockquote><p>以太坊的智能合约并非现实中常见的合同，而是存在区块链上，可以被触发执行的一段程序代码，这些代码实现了某种预定的规则，是存在于以太坊执行环境中的“自治代理”</p></blockquote><h3 id="智能合约是什么"><a href="#智能合约是什么" class="headerlink" title="智能合约是什么"></a>智能合约是什么</h3><p><img alt="智能合约" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210902141601.png" class="lozad"><br>以太坊的智能合约设计很简明。</p><ul><li>任何人都可以在以太坊区块链上开发智能合约，这些智能合约的代码是存在于以太坊的账户中的，这类存有代码的账户叫合约账户。对应地，由密钥控制的账户可称为外部账户。</li><li>以太坊的智能合约程序，是在以太坊虚拟机（Ethereum Virtual Machine,EVM）上运行的。</li><li>合约账户不能自己启动运行自己的智能合约。要运行一个智能合约，需要由外部账户对合约账户发起交易，从而启动其中的代码的执行。</li><li>智能合约的代码永远不能被修改。</li></ul><p>在以太坊，智能合约是可以处理资金的脚本，就是这么简单。</p><p>这些合约由我们称为“矿工”的参与方强制执行和证明。我们给这些矿工支付一种叫作 “Gas” 的东西，它是运行一份合约的成本。当你发布一份智能合约，或者执行一份智能合约，或者把钱转到另一个账户，你就要支付一些被转换成Gas的以太币。</p><h4 id="智能合约有什么用"><a href="#智能合约有什么用" class="headerlink" title="智能合约有什么用"></a>智能合约有什么用</h4><p>图2 是一个简明的图示，图示是一个典型的 ERC20 通证发行过程：一个项目通过智能合约创建通证，这个通证是实体资产或线上资产的价值表示物。投资者（用户）发起交易，向智能合约转入以太币（ETH），智能合约自动运转，在满足一定规则后，它向投资者账户转入相应数量的通证。<br><img alt="智能合约" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210902141936.png" class="lozad"></p><h4 id="为什么我们需要合约？"><a href="#为什么我们需要合约？" class="headerlink" title="为什么我们需要合约？"></a>为什么我们需要合约？</h4><p>在一个没有合约或货币的世界里，我们只能局限于同步的易货交易——你有一个苹果，我有一条面包，我可以当场用面包换你的苹果。 然而，我们交易的越多，就越有可能陷入经济学家所谓的需求的双重偶合（double coincidence of wants）问题：我们之间达成交易的前提必须是我们同时想要对方手里的东西，而这种情况不常出现。</p><p>货币是解决这个问题的一种方法。 我可以卖了面包换到钱，然后用钱换苹果或其他物品。通过钱，我们可以把双重需求减少成单一需求：我无需持有你想交易的东西；我可以通过后续交易获得苹果。这样时间限制就被削弱了。</p><p>合约的工作原理与货币类似，但它们能促进更多潜在的交易。 合约不要求同步交换价值，甚至不需要以货币作为中介。 我现在可以把一条面包卖出去，买方可以答应下个月付款给我。 这种能力从根本上扩展了我们可以进行的交易类型。</p><p>但仍有一个问题。 你怎么确定我会履行承诺付款给你？ 我们如何建立可信的约定？</p><h4 id="履行合约约定"><a href="#履行合约约定" class="headerlink" title="履行合约约定"></a>履行合约约定</h4><p>在点对点交易过程中，无论谁先履行合约都要承担对方违背合约的风险。 如果卖方先发货，买方可能不会付款；如果买方先付款，卖方可能不会发货。 </p><p>怎么来解决这个问题?</p><p>解决方案是使用多重签名的智能合约，在针对在线交易的多重签名合约中，可以要求至少获得三方（买方，卖方和中立的第三方）中任意两方的签名。 第三方可以是任何人（或任何事物！），只要能让我们相信 ta 能公正地解决争议即可。 特别要注意的是，第三方仲裁员的权力非常有限，ta 们只能在买卖双方出现争议的情况下，决定将钱汇给其中一方。 仲裁员不能私吞这笔钱或是将它汇给买卖双方以外的其他人。</p><h4 id="合约的风险"><a href="#合约的风险" class="headerlink" title="合约的风险"></a>合约的风险</h4><h5 id="事件1-Parity钱包"><a href="#事件1-Parity钱包" class="headerlink" title="事件1-Parity钱包"></a>事件1-Parity钱包</h5><p>在2016年6月，一名黑客企图转移一大笔众筹资金 （350 万个 ETH, 占当时ETH总数的15%）至他自己的子合约，这笔资金被锁定在该子合约中 28 天。</p><p>众多创业公司使用的多重签名钱包的逻辑大多通过库合约实现。每个钱包都包含一个轻量级的客户端合约，连接到这个单点故障。漏洞是一种叫做wallet.sol的多重签名合约出现bug导致的，问题在于其中一个初始化函数只能被调用一次。<br><img alt="parity多重签名钱包" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210902160647.png" class="lozad"></p><h4 id="预防措施"><a href="#预防措施" class="headerlink" title="预防措施"></a>预防措施</h4><ul><li>使用开放的资源与社区接受的库合约的实质标准 (de facto standards)，例如 Open Zeppelin’s contracts。</li><li>使用推荐的模式与最优操作指导手册，例如 Consensys 提供的。</li><li>考虑由信誉好的供应商审核您的智能合约。</li></ul><h2 id="以太坊地址"><a href="#以太坊地址" class="headerlink" title="以太坊地址"></a>以太坊地址</h2><h3 id="以太坊地址-1"><a href="#以太坊地址-1" class="headerlink" title="以太坊地址"></a>以太坊地址</h3><h4 id="以太坊地址生成过程-可以借鉴此-文章"><a href="#以太坊地址生成过程-可以借鉴此-文章" class="headerlink" title="以太坊地址生成过程 可以借鉴此[文章]"></a>以太坊地址生成过程 可以借鉴此<a href="https://blog.csdn.net/u013137970/article/details/87821243?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163063844116780271565572%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=163063844116780271565572&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~sobaiduend~default-1-87821243.pc_v2_rank_blog_default&amp;utm_term=%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%94%9F%E6%88%90%E5%9C%B0%E5%9D%80&amp;spm=1018.2226.3001.4450" target="_blank" rel="noopener">[文章]</a></h4><p>1、生成256位随机数作为私钥<br>2、将私钥转化为 secp256k1 非压缩格式的公钥，即 512 位的公钥。<br>3、使用散列算法 Keccak256 计算公钥的哈希值，转化为十六进制字符串。<br>4、取十六进制字符串的后 40 个字母，开头加上 0x 作为地址。</p><h4 id="以太坊地址生成实例"><a href="#以太坊地址生成实例" class="headerlink" title="以太坊地址生成实例"></a>以太坊地址生成实例</h4><ul><li>私钥：1f2b77<strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>*</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>6a7efaa065d20</li><li>公钥：04dfa1<strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>*</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>0bbf8865734252953c9884af787b2cadd45f92dff2b81e21cfdf98873e492e5fdc07e9eb67ca74d</li><li>地址：0xabcd<strong><strong><strong><strong><strong><strong><strong>**</strong></strong></strong></strong></strong></strong></strong>4A2d57</li></ul><h3 id="以太坊合约地址"><a href="#以太坊合约地址" class="headerlink" title="以太坊合约地址"></a>以太坊合约地址</h3><h4 id="以太坊合约地址生成过程-可借鉴此-文章"><a href="#以太坊合约地址生成过程-可借鉴此-文章" class="headerlink" title="以太坊合约地址生成过程 可借鉴此[文章]"></a>以太坊合约地址生成过程 可借鉴此<a href="https://gitee.com/updatecg_admin/ether-erc20-token/tree/master#https://cn.etherscan.com/token/0xdac17f958d2ee523a2206206994597c13d831ec7" target="_blank" rel="noopener">[文章]</a></h4><blockquote><p>利用发送代币生成合约地址</p></blockquote><p>利用Remix - Solidity IDE 网站来发布智能合约 <a href="http://remix.app.hubwiz.com/#optimize=false&amp;runs=200&amp;evmVersion=null&amp;version=soljson-v0.4.16+commit.d7661dd9.js" target="_blank" rel="noopener">[地址]</a></p><h4 id="发币过程"><a href="#发币过程" class="headerlink" title="发币过程"></a>发币过程</h4><h5 id="第一步：在-Chrome-插件商店搜索并安装-MetaMask"><a href="#第一步：在-Chrome-插件商店搜索并安装-MetaMask" class="headerlink" title="第一步：在 Chrome 插件商店搜索并安装 MetaMask"></a>第一步：在 Chrome 插件商店搜索并安装 MetaMask</h5><blockquote><p>MetaMask是钱包的一种，在chrome浏览器中，安装MetaMask插件即可，安装完成后，右上角会出现一个“狐狸头”的标志，点击该标志，打开钱包，第一步，创建账户，（创建账户只需要输入面密码即可，名称创建后可以随便改，该账户就是一个hash值，如何给自己创建的账户冲以太币呢，你可以通过在交易所买入一些ETH，然后转入即可）创建成功后，记住密码还有产生的几个随机单词（一定要记录下来）。<br><img alt="MetaMask" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210903163547.png" class="lozad"></p></blockquote><h5 id="第二步：编写合约代码"><a href="#第二步：编写合约代码" class="headerlink" title="第二步：编写合约代码"></a>第二步：编写合约代码</h5><p><img alt="智能合约代码" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210903120033.png" class="lozad"></p><p>注意事项：</p><ul><li><p>合约代码引用版本需要与编辑器所选版本匹配</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pragma solidity ^0.4.16;</span><br></pre></td></tr></table></figure></li><li><p>精度默认值decimals=18，就是小数点后18位。<br>BTC是8位，0.00000001 (Gwei) = 1(sat)<br>ERC20是18位，0.000000002578400219 (Ether) = 2.578400219 (Gwei)</p></li></ul><h5 id="第三步：注入环境、绑定合约、部署发币"><a href="#第三步：注入环境、绑定合约、部署发币" class="headerlink" title="第三步：注入环境、绑定合约、部署发币"></a>第三步：注入环境、绑定合约、部署发币</h5><p><img alt="发币" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/微信图片_20210903165727.png" class="lozad"></p><p>注意事项：</p><ul><li>以太币数量填写0，不然要报错</li></ul><h5 id="第四步：等待发币结果"><a href="#第四步：等待发币结果" class="headerlink" title="第四步：等待发币结果"></a>第四步：等待发币结果</h5><ul><li><p>MetaMask交易结果<br><img alt="小狐狸发币结果" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210903170041.png" class="lozad"></p></li><li><p>链上交易详情<a href="https://ropsten.etherscan.io/tx/0x1ff79a4e7690e2fffbc08a00eef2373e104c2f639d200ccb54cb225a2d428cc1" target="_blank" rel="noopener">[链上地址]</a><br><img alt="链上交易详情" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210903174023.png" class="lozad"></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;以太坊简介&quot;&gt;&lt;a href=&quot;#以太坊简介&quot; class=&quot;headerlink&quot; title=&quot;以太坊简介&quot;&gt;&lt;/a&gt;以太坊简介&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;以太坊是一个为去中心化应用（DApp）而生的全球开源平台，官方地址》&lt;a href=&quot;ht
      
    
    </summary>
    
      <category term="虚拟币" scheme="http://www.updatecg.xin/categories/%E8%99%9A%E6%8B%9F%E5%B8%81/"/>
    
    
      <category term="ETH" scheme="http://www.updatecg.xin/tags/ETH/"/>
    
      <category term="虚拟币" scheme="http://www.updatecg.xin/tags/%E8%99%9A%E6%8B%9F%E5%B8%81/"/>
    
  </entry>
  
  <entry>
    <title>K8s管理应用生命周期-Deployment</title>
    <link href="http://www.updatecg.xin/2021/08/27/K8s%E7%AE%A1%E7%90%86%E5%BA%94%E7%94%A8%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F-Deployment/"/>
    <id>http://www.updatecg.xin/2021/08/27/K8s管理应用生命周期-Deployment/</id>
    <published>2021-08-27T07:18:00.000Z</published>
    <updated>2021-08-27T09:48:27.682Z</updated>
    
    <content type="html"><![CDATA[<h2 id="在Kubernetes部署应用程序流程"><a href="#在Kubernetes部署应用程序流程" class="headerlink" title="在Kubernetes部署应用程序流程"></a>在Kubernetes部署应用程序流程</h2><p><img alt="kubernetes" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210827114906.png" class="lozad"></p><h2 id="使用Deployment部署Java应用"><a href="#使用Deployment部署Java应用" class="headerlink" title="使用Deployment部署Java应用"></a>使用Deployment部署Java应用</h2><ul><li>制作镜像利用镜像部署</li><li><p>使用Deployment控制器部署镜像</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl create deployment web --image=镜像地址</span><br><span class="line">kubectl get deployment,pods</span><br></pre></td></tr></table></figure></li><li><p>使用Service发布Pod</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl expose deployment web --port80 --type=NodePort --target-port=8080 --name=web</span><br><span class="line">kubectl get service</span><br></pre></td></tr></table></figure></li></ul><h2 id="服务编排"><a href="#服务编排" class="headerlink" title="服务编排"></a>服务编排</h2><h3 id="YAML文件格式说明"><a href="#YAML文件格式说明" class="headerlink" title="YAML文件格式说明"></a>YAML文件格式说明</h3><blockquote><p>K8s是一个容器编排引擎，使用YAML文件编排要部署应用，因此在学习之前，应先了解YAML语法格式：</p><ul><li>缩进表示层级关系</li><li>不支持制表符”tab”缩进，需使用空格缩进</li><li>通常开头缩进2个空格</li><li>字符后缩进1个空格，如冒号、逗号等</li><li>“—“ 表示YAML格式，一个文件的开始</li><li>“#” 注释</li></ul></blockquote><h3 id="YAML文件创建资源对象"><a href="#YAML文件创建资源对象" class="headerlink" title="YAML文件创建资源对象"></a>YAML文件创建资源对象</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">    replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">    selector:</span></span><br><span class="line"><span class="attr">      matchLabels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">    template:</span></span><br><span class="line"><span class="attr">      metadata:</span></span><br><span class="line"><span class="attr">        labels:</span></span><br><span class="line"><span class="attr">          app:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">      spec:</span></span><br><span class="line"><span class="attr">        containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">         image:</span> <span class="string">镜像地址</span></span><br></pre></td></tr></table></figure><p>等同于：kubectl create deployment web –image=镜像地址 –replicas=3 -n default</p><h4 id="标签描述："><a href="#标签描述：" class="headerlink" title="标签描述："></a>标签描述：</h4><table><thead><tr><th>标签key</th><th>含义</th></tr></thead><tbody><tr><td>apiVersion</td><td>API版本</td></tr><tr><td>kind</td><td>资源类型</td></tr><tr><td>metadata</td><td>资源元数据</td></tr><tr><td>spec</td><td>资源规格</td></tr><tr><td>replicas</td><td>副本数</td></tr><tr><td>selector</td><td>标签选择器，下面metadata.labels保持一致</td></tr><tr><td>template</td><td>Pod模板</td></tr><tr><td>metadata</td><td>Pod元数据</td></tr><tr><td>spec</td><td>pod规格</td></tr><tr><td>containers</td><td>容器配置</td></tr></tbody></table><h4 id="部署卸载"><a href="#部署卸载" class="headerlink" title="部署卸载"></a>部署卸载</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">部署: kubectl apply -f xxx.yaml</span><br><span class="line">卸载: kubectl delete -f xxx.yaml</span><br></pre></td></tr></table></figure><h3 id="资源字段太多，记不住怎么办？"><a href="#资源字段太多，记不住怎么办？" class="headerlink" title="资源字段太多，记不住怎么办？"></a>资源字段太多，记不住怎么办？</h3><ul><li><p>用get命令导出</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get deployment nginx -o yaml &gt; my-deploy.yaml</span><br></pre></td></tr></table></figure></li><li><p>Pod容器的字段拼写忘记了</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl explain pods.spec.containers</span><br><span class="line">kubectl explain deployment</span><br></pre></td></tr></table></figure></li></ul><h2 id="Deployment介绍"><a href="#Deployment介绍" class="headerlink" title="Deployment介绍"></a>Deployment介绍</h2><blockquote><p>Deployment是最常用的K8s工作负载控制器（Workload Controllers），是K8s的一个抽象概念，用于更高级层次对象，部署和管理Pod。其他控制器还有DaemonSet、StatefulSet等。</p></blockquote><h3 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h3><ul><li>管理Pod和ReplicaSet</li><li>具体上线部署、副本设定、滚动升级、回滚等功能</li><li>提供声明式更新、例如只更新一个新的Image</li></ul><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><blockquote><p>网站、API、微服务</p></blockquote><h3 id="应用生命周期管理流程"><a href="#应用生命周期管理流程" class="headerlink" title="应用生命周期管理流程"></a>应用生命周期管理流程</h3><p><img alt="kubernetes" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210827164349.png" class="lozad">多少钱</p><h4 id="第一步》部署应用"><a href="#第一步》部署应用" class="headerlink" title="第一步》部署应用"></a>第一步》部署应用</h4><blockquote><p>利用创建nginx为模板，创建nginx.yaml文件<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">nginx:1.16</span></span><br></pre></td></tr></table></figure></p></blockquote><p>执行创建yaml命令<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f nginx.yaml</span><br></pre></td></tr></table></figure></p><p>不使用yaml文件创建<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl create deployment web --image=nginx:1.16 --replicas=3</span><br></pre></td></tr></table></figure></p><h4 id="第二步》滚动升级"><a href="#第二步》滚动升级" class="headerlink" title="第二步》滚动升级"></a>第二步》滚动升级</h4><p><img alt="kubernetes" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210827165215.png" class="lozad"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;在Kubernetes部署应用程序流程&quot;&gt;&lt;a href=&quot;#在Kubernetes部署应用程序流程&quot; class=&quot;headerlink&quot; title=&quot;在Kubernetes部署应用程序流程&quot;&gt;&lt;/a&gt;在Kubernetes部署应用程序流程&lt;/h2&gt;&lt;p&gt;&lt;i
      
    
    </summary>
    
      <category term="K8S" scheme="http://www.updatecg.xin/categories/K8S/"/>
    
    
      <category term="devOps" scheme="http://www.updatecg.xin/tags/devOps/"/>
    
      <category term="K8S" scheme="http://www.updatecg.xin/tags/K8S/"/>
    
  </entry>
  
  <entry>
    <title>部署一套单Master的K8s集群</title>
    <link href="http://www.updatecg.xin/2021/08/19/%E9%83%A8%E7%BD%B2%E4%B8%80%E5%A5%97%E5%8D%95Master%E7%9A%84K8s%E9%9B%86%E7%BE%A4/"/>
    <id>http://www.updatecg.xin/2021/08/19/部署一套单Master的K8s集群/</id>
    <published>2021-08-19T07:18:00.000Z</published>
    <updated>2021-08-19T08:55:42.999Z</updated>
    
    <content type="html"><![CDATA[<p>kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。</p><h2 id="安装要求"><a href="#安装要求" class="headerlink" title="安装要求"></a>安装要求</h2><p>在开始之前，部署Kubernetes集群机器需要满足以下几个条件：</p><ul><li>一台或多台机器，操作系统 CentOS7.x-86_x64</li><li>硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多</li><li>集群中所有机器之间网络互通</li><li>可以访问外网，需要拉取镜像</li><li>禁止swap分区</li></ul><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><p><img alt="kubernetes" data-src="https://blog-1252881505.cos.ap-beijing.myqcloud.com/k8s/single-master.jpg" class="lozad"></p><table><thead><tr><th>角色</th><th>IP</th></tr></thead><tbody><tr><td>k8s-master</td><td>192.168.31.61</td></tr><tr><td>k8s-node1</td><td>192.168.31.62</td></tr><tr><td>k8s-node2</td><td>192.168.31.63</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">关闭防火墙：</span><br><span class="line">$ systemctl stop firewalld</span><br><span class="line">$ systemctl disable firewalld</span><br><span class="line"></span><br><span class="line">关闭selinux：</span><br><span class="line">$ sed -i &apos;s/enforcing/disabled/&apos; /etc/selinux/config  # 永久</span><br><span class="line">$ setenforce 0  # 临时</span><br><span class="line"></span><br><span class="line">关闭swap：</span><br><span class="line">$ swapoff -a  # 临时</span><br><span class="line">$ sed -i &apos;/swap/s/^\(.*\)$/#\1/g&apos; /etc/fstab # 永久</span><br><span class="line"></span><br><span class="line">设置主机名：</span><br><span class="line">$ hostnamectl set-hostname &lt;hostname&gt;</span><br><span class="line"></span><br><span class="line">在master添加hosts：</span><br><span class="line">$ cat &gt;&gt; /etc/hosts &lt;&lt; EOF</span><br><span class="line">192.168.31.61 k8s-master</span><br><span class="line">192.168.31.62 k8s-node1</span><br><span class="line">192.168.31.63 k8s-node2</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">将桥接的IPv4流量传递到iptables的链：</span><br><span class="line">$ cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">$ sysctl --system  # 生效</span><br><span class="line"></span><br><span class="line">时间同步：</span><br><span class="line">$ yum install ntpdate -y</span><br><span class="line">$ ntpdate time.windows.com</span><br></pre></td></tr></table></figure><h2 id="安装Docker-kubeadm-kubelet【所有节点】"><a href="#安装Docker-kubeadm-kubelet【所有节点】" class="headerlink" title="安装Docker/kubeadm/kubelet【所有节点】"></a>安装Docker/kubeadm/kubelet【所有节点】</h2><p>Kubernetes默认CRI（容器运行时）为Docker，因此先安装Docker。</p><h3 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">$ yum -y install docker-ce</span><br><span class="line">$ systemctl enable docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure><p>配置镜像下载加速器：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat &gt; /etc/docker/daemon.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">$ systemctl restart docker</span><br><span class="line">$ docker info</span><br></pre></td></tr></table></figure><h3 id="添加阿里云YUM软件源"><a href="#添加阿里云YUM软件源" class="headerlink" title="添加阿里云YUM软件源"></a>添加阿里云YUM软件源</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="安装kubeadm，kubelet和kubectl"><a href="#安装kubeadm，kubelet和kubectl" class="headerlink" title="安装kubeadm，kubelet和kubectl"></a>安装kubeadm，kubelet和kubectl</h3><p>由于版本更新频繁，这里指定版本号部署：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ yum install -y kubelet-1.20.0 kubeadm-1.20.0 kubectl-1.20.0</span><br><span class="line">$ systemctl enable kubelet</span><br></pre></td></tr></table></figure><h2 id="部署Kubernetes-Master"><a href="#部署Kubernetes-Master" class="headerlink" title="部署Kubernetes Master"></a>部署Kubernetes Master</h2><p><a href="https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file</a></p><p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#initializing-your-control-plane-node" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#initializing-your-control-plane-node</a></p><p>在192.168.31.61（Master）执行。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubeadm init \</span><br><span class="line">  --apiserver-advertise-address=192.168.31.61 \</span><br><span class="line">  --image-repository registry.aliyuncs.com/google_containers \</span><br><span class="line">  --kubernetes-version v1.20.0 \</span><br><span class="line">  --service-cidr=10.96.0.0/12 \</span><br><span class="line">  --pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">  --ignore-preflight-errors=all</span><br></pre></td></tr></table></figure><ul><li>–apiserver-advertise-address 集群通告地址</li><li>–image-repository  由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址</li><li>–kubernetes-version K8s版本，与上面安装的一致</li><li>–service-cidr 集群内部虚拟网络，Pod统一访问入口</li><li>–pod-network-cidr Pod网络，，与下面部署的CNI网络组件yaml中保持一致</li></ul><p>或者使用配置文件引导：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ vi kubeadm.conf</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1.20.0</span><br><span class="line">imageRepository: registry.aliyuncs.com/google_containers </span><br><span class="line">networking:</span><br><span class="line">  podSubnet: 10.244.0.0/16 </span><br><span class="line">  serviceSubnet: 10.96.0.0/12 </span><br><span class="line"></span><br><span class="line">$ kubeadm init --config kubeadm.conf --ignore-preflight-errors=all</span><br></pre></td></tr></table></figure><p>拷贝kubectl使用的连接k8s认证文件到默认路径：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get nodes</span><br><span class="line">NAME               STATUS     ROLES            AGE   VERSION</span><br><span class="line">localhost.localdomain   NotReady   control-plane,master   20s   v1.20.0</span><br></pre></td></tr></table></figure><h2 id="加入Kubernetes-Node"><a href="#加入Kubernetes-Node" class="headerlink" title="加入Kubernetes Node"></a>加入Kubernetes Node</h2><p>在192.168.31.62/63（Node）执行。</p><p>向集群添加新节点，执行在kubeadm init输出的kubeadm join命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubeadm join 192.168.31.61:6443 --token 7gqt13.kncw9hg5085iwclx \</span><br><span class="line">--discovery-token-ca-cert-hash sha256:66fbfcf18649a5841474c2dc4b9ff90c02fc05de0798ed690e1754437be35a01</span><br></pre></td></tr></table></figure><p>默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，可以直接使用命令快捷生成：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure><p><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-join/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-join/</a></p><h2 id="部署容器网络（CNI）"><a href="#部署容器网络（CNI）" class="headerlink" title="部署容器网络（CNI）"></a>部署容器网络（CNI）</h2><p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network</a></p><p>注意：只需要部署下面其中一个，推荐Calico。</p><p>Calico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等。</p><p>Calico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。</p><p>此外，Calico  项目还实现了 Kubernetes 网络策略，提供ACL功能。</p><p><a href="https://docs.projectcalico.org/getting-started/kubernetes/quickstart" target="_blank" rel="noopener">https://docs.projectcalico.org/getting-started/kubernetes/quickstart</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ wget https://docs.projectcalico.org/manifests/calico.yaml</span><br></pre></td></tr></table></figure><p>下载完后还需要修改里面定义Pod网络（CALICO_IPV4POOL_CIDR），与前面kubeadm init指定的一样</p><p>修改完后应用清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl apply -f calico.yaml</span><br><span class="line">$ kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure><h2 id="测试kubernetes集群"><a href="#测试kubernetes集群" class="headerlink" title="测试kubernetes集群"></a>测试kubernetes集群</h2><ul><li>验证Pod工作</li><li>验证Pod网络通信</li><li>验证DNS解析</li></ul><p>在Kubernetes集群中创建一个pod，验证是否正常运行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl create deployment nginx --image=nginx</span><br><span class="line">$ kubectl expose deployment nginx --port=80 --type=NodePort</span><br><span class="line">$ kubectl get pod,svc</span><br></pre></td></tr></table></figure><p>访问地址：<a href="http://NodeIP:Port" target="_blank" rel="noopener">http://NodeIP:Port</a></p><h2 id="部署-Dashboard"><a href="#部署-Dashboard" class="headerlink" title="部署 Dashboard"></a>部署 Dashboard</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure><p>默认Dashboard只能集群内部访问，修改Service为NodePort类型，暴露到外部：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ vi recommended.yaml</span><br><span class="line">...</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">      nodePort: 30001</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">$ kubectl apply -f recommended.yaml</span><br><span class="line">$ kubectl get pods -n kubernetes-dashboard</span><br><span class="line">NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">dashboard-metrics-scraper-6b4884c9d5-gl8nr   1/1     Running   0          13m</span><br><span class="line">kubernetes-dashboard-7f99b75bf4-89cds        1/1     Running   0          13m</span><br></pre></td></tr></table></figure><p>访问地址：<a href="https://NodeIP:30001" target="_blank" rel="noopener">https://NodeIP:30001</a></p><p>创建service account并绑定默认cluster-admin管理员集群角色：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建用户</span><br><span class="line">$ kubectl create serviceaccount dashboard-admin -n kube-system</span><br><span class="line"># 用户授权</span><br><span class="line">$ kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin</span><br><span class="line"># 获取用户Token</span><br><span class="line">$ kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk &apos;/dashboard-admin/&#123;print $1&#125;&apos;)</span><br></pre></td></tr></table></figure><p>使用输出的token登录Dashboard。</p><h2 id="切换容器引擎为Containerd"><a href="#切换容器引擎为Containerd" class="headerlink" title="切换容器引擎为Containerd"></a>切换容器引擎为Containerd</h2><p><a href="https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#containerd" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#containerd</a></p><p>1、配置先决条件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo modprobe overlay</span><br><span class="line">sudo modprobe br_netfilter</span><br><span class="line"></span><br><span class="line"># 设置必需的 sysctl 参数，这些参数在重新启动后仍然存在。</span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># Apply sysctl params without reboot</span><br><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure><p>2、安装containerd</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">yum update -y &amp;&amp; sudo yum install -y containerd.io</span><br><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | sudo tee /etc/containerd/config.toml</span><br><span class="line">systemctl restart containerd</span><br></pre></td></tr></table></figure><p>3、修改配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi /etc/containerd/config.toml</span><br><span class="line">   [plugins.&quot;io.containerd.grpc.v1.cri&quot;]</span><br><span class="line">      sandbox_image = &quot;registry.aliyuncs.com/google_containers/pause:3.2&quot;  </span><br><span class="line">         ...</span><br><span class="line">         [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">             SystemdCgroup = true</span><br><span class="line">             ...</span><br><span class="line">        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;docker.io&quot;]</span><br><span class="line">          endpoint = [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span><br><span class="line">          </span><br><span class="line">systemctl restart containerd</span><br></pre></td></tr></table></figure><p>4、配置kubelet使用containerd</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi /etc/sysconfig/kubelet </span><br><span class="line">KUBELET_EXTRA_ARGS=--container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock --cgroup-driver=systemd</span><br><span class="line"></span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure><p>5、验证</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get node -o wide</span><br><span class="line"></span><br><span class="line">k8s-node1  xxx  containerd://1.4.4</span><br></pre></td></tr></table></figure><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">怎么查看容器日志？</span><br><span class="line">kubectl logs &lt;容器名称&gt; -n kube-system</span><br><span class="line"></span><br><span class="line">怎么查看容器事件？</span><br><span class="line">kubectl describe pod &lt;容器名称&gt; -n kube-system</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">calico无法拉取镜像解决办法？</span><br><span class="line"></span><br><span class="line">grep image calico.yaml</span><br><span class="line"></span><br><span class="line">image: calico/cni:v3.15.1</span><br><span class="line">image: calico/pod2daemon-flexvol:v3.15.1</span><br><span class="line">image: calico/node:v3.15.1</span><br><span class="line"></span><br><span class="line">docker pull xxx</span><br><span class="line">docker save calico/cni:v3.15.1 &gt; cni.tar</span><br><span class="line">docker load &lt; cni.tar</span><br><span class="line">kubectl delete -f calico.yaml</span><br><span class="line">kubectl apply -f calico.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">init失败或者情况环境可以使用：</span><br><span class="line">kubeadm reset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">为什么部署网络组件？</span><br><span class="line">Q1：每个docker主机创建的容器ip可能冲突?</span><br><span class="line">Q2：容器1访问容器2，容器1怎么知道容器2在哪个docker主机？</span><br><span class="line">Q3：容器1访问容器2数据包怎么传输过去？</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1、k8s现在可以使用docker嘛？</span><br><span class="line">可以。</span><br><span class="line">2、dockershim什么时候被移除？</span><br><span class="line">预计1.23版本。</span><br><span class="line">3、docker还值的学习嘛？</span><br><span class="line">值得。</span><br><span class="line"></span><br><span class="line">kubectl get pods --show-labels  # 查看资源标签</span><br><span class="line">kubectl get pod -l app=web  # 根据标签筛选资源</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。&lt;/p&gt;
&lt;h2 id=&quot;安装要求&quot;&gt;&lt;a href=&quot;#安装要求&quot; class=&quot;headerlink&quot; title=&quot;安装要求&quot;&gt;&lt;/a&gt;安装要求&lt;/h2&gt;&lt;p&gt;在开始之前，部署Kuberne
      
    
    </summary>
    
      <category term="K8S" scheme="http://www.updatecg.xin/categories/K8S/"/>
    
    
      <category term="devOps" scheme="http://www.updatecg.xin/tags/devOps/"/>
    
      <category term="K8S" scheme="http://www.updatecg.xin/tags/K8S/"/>
    
  </entry>
  
  <entry>
    <title>服务器load average异常</title>
    <link href="http://www.updatecg.xin/2021/08/06/%E6%9C%8D%E5%8A%A1%E5%99%A8load%20average%E5%BC%82%E5%B8%B8/"/>
    <id>http://www.updatecg.xin/2021/08/06/服务器load average异常/</id>
    <published>2021-08-06T07:18:00.000Z</published>
    <updated>2021-08-19T08:56:10.985Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>4核16G的设备，正常load average不大于4，表示系统一直处在负载状态，程序有异常。</p></blockquote><h2 id="每日服务器性能邮件告警"><a href="#每日服务器性能邮件告警" class="headerlink" title="每日服务器性能邮件告警"></a>每日服务器性能邮件告警</h2><p>4核16G的服务器，load率达到了 6.97, 6.70, 4.87.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">信息总览:</span><br><span class="line"></span><br><span class="line">CPU 内核：4核</span><br><span class="line"></span><br><span class="line">CPU load率： 6.97, 6.70, 4.87</span><br><span class="line"></span><br><span class="line">总内存：15.3 GiB    使用内存：4.7 GiB    剩余内存：10.600000000000001GiB</span><br><span class="line"></span><br><span class="line">TOP前5:</span><br><span class="line">     PID         %CPU    %MEM    VSZ          RSS             Name</span><br><span class="line">    2805176      59.9      6.3       7.6 GiB     986.2 MiB     java</span><br><span class="line">    2901828      13.1      5.4       4.1 GiB     847.4 MiB     java</span><br><span class="line">    3532650       4.5      4.7       3.9 GiB     740.9 MiB     java</span><br><span class="line">    3769112       3.0      4.2       5.5 GiB     657.7 MiB     java</span><br><span class="line">    1619371       0.7      1.3       6.6 GiB     204.8 MiB     java</span><br></pre></td></tr></table></figure></p><p>注意：CPU load率： 6.97, 6.70, 4.87。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。</p><h2 id="load高可能的一些原因"><a href="#load高可能的一些原因" class="headerlink" title="load高可能的一些原因"></a>load高可能的一些原因</h2><blockquote><p>系统load高通常都是由于某段发布的代码有bug或者引入某些第三方jar而又使用不合理导致的，因此注意首先区分load高，是由于cpu高导致的还是io高导致的，根据不同的场景采取不同定位问题的方式。</p><ul><li>死循环或者不合理的大量循环操作，如果不是循环操作，按照现代cpu的处理速度来说处理一大段代码也就一会会儿的事，基本对能力无消耗</li><li>频繁的YoungGC</li><li>频繁的FullGC</li><li>高磁盘IO</li><li>高网络IO</li></ul></blockquote><p>当束手无策时，jmap打印堆栈文件多分析分析吧，或许能灵光一现能找到错误原因。</p><h2 id="发现YongGC块，FullGC也快，注定有问题"><a href="#发现YongGC块，FullGC也快，注定有问题" class="headerlink" title="发现YongGC块，FullGC也快，注定有问题"></a>发现YongGC块，FullGC也快，注定有问题</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jstat gcutil pid 100</span><br></pre></td></tr></table></figure><p><img alt data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/load_4.png" class="lozad"></p><p>可以看出行O也一直在增加，几乎99，速度很快，老年代一下就满了，立马执行了YongGC,然后进入FGC的速度也快，2天就525了。</p><h2 id="进一步排查获取dump文件"><a href="#进一步排查获取dump文件" class="headerlink" title="进一步排查获取dump文件"></a>进一步排查获取dump文件</h2><p>通过命令抓取dump文件，进行分析。<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jmap -dump:format=b,file=1.hprof pid</span><br></pre></td></tr></table></figure></p><h2 id="分析dump文件"><a href="#分析dump文件" class="headerlink" title="分析dump文件"></a>分析dump文件</h2><blockquote><p>通过JProfiler分析1.hprof文件</p></blockquote><p><img alt data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/load_average_hprof.jpg" class="lozad"><br><img alt data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/load_2.jpg" class="lozad"><br><img alt data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/load_3.jpg" class="lozad"><br>上述分析结果可以直观的看出，创建的对象线程非常多，并且一直在加，释放很慢。</p><h2 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h2><blockquote><p>发现程序确实有类似代码<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Provide a new ScheduledExecutorService instance.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;A shutdown hook is created to terminate the thread pool on application termination.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> new ScheduledExecutorService</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ScheduledExecutorService <span class="title">defaultExecutorService</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ScheduledExecutorService scheduledExecutorService =</span><br><span class="line">            Executors.newScheduledThreadPool(getCpuCount());</span><br><span class="line"></span><br><span class="line">    Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread(() -&gt; shutdown(scheduledExecutorService)));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> scheduledExecutorService;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><p>因为此方法是通过一个业务定时器在轮序，2秒一次，每次都去执行了一次，所以造成了内存不足，load值增加，系统负载增加。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><h3 id="代码解决"><a href="#代码解决" class="headerlink" title="代码解决"></a>代码解决</h3><p>程序改用单例模式，静态方法，执行一次就行。</p><h3 id="jvm调优优化"><a href="#jvm调优优化" class="headerlink" title="jvm调优优化"></a>jvm调优优化</h3><ul><li>-XX：MaxTenuringThreshold</li><li>-XX：+ UseConcMarkSweepGC</li><li>-XX：CMSFullGCsBeforeCompaction<br>具体参数详情请参考<a href="http://www.updatecg.xin/2019/01/24/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0/#%E5%A0%86%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%8F%82%E6%95%B0">[性能调优参数]</a></li></ul><h4 id="调优案例"><a href="#调优案例" class="headerlink" title="调优案例"></a>调优案例</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-XX:MaxTenuringThreshold=0 -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=0</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;4核16G的设备，正常load average不大于4，表示系统一直处在负载状态，程序有异常。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;每日服务器性能邮件告警&quot;&gt;&lt;a href=&quot;#每日服务器性能邮件告警&quot; class=&quot;headerl
      
    
    </summary>
    
      <category term="现网" scheme="http://www.updatecg.xin/categories/%E7%8E%B0%E7%BD%91/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
      <category term="JVM" scheme="http://www.updatecg.xin/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>服务无缘无故宕机</title>
    <link href="http://www.updatecg.xin/2020/06/20/%E6%9C%8D%E5%8A%A1%E6%97%A0%E7%BC%98%E6%97%A0%E6%95%85%E5%AE%95%E6%9C%BA/"/>
    <id>http://www.updatecg.xin/2020/06/20/服务无缘无故宕机/</id>
    <published>2020-06-20T07:18:00.000Z</published>
    <updated>2021-08-19T08:56:30.681Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>定时服务无缘无故宕机了，服务相关日志没有任何错误日志。<br>首先报告领导<br>恢复业务<br>排查问题<br>监控服务</p></blockquote><h2 id="服务宕机了"><a href="#服务宕机了" class="headerlink" title="服务宕机了"></a>服务宕机了</h2><p>因服务没有监控，导致服务宕机没有发现，还是通过统计数据异常发现问题，立马去查看log日志。。。<br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/20200601.png" class="lozad"></p><ul><li>很奇怪项目日志没有任何error日志，大大的加深了问题排查。</li></ul><h2 id="查看jvm错误日志hs-err-pid-log，JVM-crash信息，我们可以通过分析该文件定位到导致-JVM-Crash-的原因，从而修复保证系统稳定"><a href="#查看jvm错误日志hs-err-pid-log，JVM-crash信息，我们可以通过分析该文件定位到导致-JVM-Crash-的原因，从而修复保证系统稳定" class="headerlink" title="查看jvm错误日志hs_err_pid*.log，JVM crash信息，我们可以通过分析该文件定位到导致 JVM Crash 的原因，从而修复保证系统稳定"></a>查看jvm错误日志hs_err_pid<strong>*</strong>.log，JVM crash信息，我们可以通过分析该文件定位到导致 JVM Crash 的原因，从而修复保证系统稳定</h2><h3 id="日志头"><a href="#日志头" class="headerlink" title="日志头"></a>日志头</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#</span><br><span class="line"># There is insufficient memory for the Java Runtime Environment to continue.</span><br><span class="line"># Native memory allocation (mmap) failed to map 12288 bytes for committing reserved memory.</span><br><span class="line"># Possible reasons:</span><br><span class="line">#   The system is out of physical RAM or swap space</span><br><span class="line">#   In 32 bit mode, the process size limit was hit</span><br><span class="line"># Possible solutions:</span><br><span class="line">#   Reduce memory load on the system</span><br><span class="line">#   Increase physical memory or swap space</span><br><span class="line">#   Check if swap backing store is full</span><br><span class="line">#   Use 64 bit Java on a 64 bit OS</span><br><span class="line">#   Decrease Java heap size (-Xmx/-Xms)</span><br><span class="line">#   Decrease number of Java threads</span><br><span class="line">#   Decrease Java thread stack sizes (-Xss)</span><br><span class="line">#   Set larger code cache with -XX:ReservedCodeCacheSize=</span><br><span class="line"># This output file may be truncated or incomplete.</span><br><span class="line">#</span><br><span class="line">#  Out of Memory Error (os_linux.cpp:2640), pid=114181, tid=0x00007f9340e91700</span><br><span class="line">#</span><br><span class="line"># JRE version: Java(TM) SE Runtime Environment (8.0_171-b11) (build 1.8.0_171-b11)</span><br><span class="line"># Java VM: Java HotSpot(TM) 64-Bit Server VM (25.171-b11 mixed mode linux-amd64 compressed oops)</span><br><span class="line"># Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again</span><br><span class="line">#</span><br></pre></td></tr></table></figure><ul><li>Native memory allocation (mmap) failed to map 12288 bytes for committing reserved memory.<ul><li>减小thread stack的大小</li><li>线程数在3000~5000左右需要注意，JVM默认thread stack（-Xss）的大小为1024,这样当线程多时导致Native virtual memory被耗尽，实际上当thread stack的大小为128K 或 256K时是足够的，所以我们如果明确指定thread stack为128K 或 256K即可，具体使用-Xss</li></ul></li><li>Out of Memory Error (os_linux.cpp:2640), pid=114181, tid=0x00007f9340e91700<ul><li>日志头可清晰看出<span style="font-weight:bold;color:red">Out of Memory Error</span>-内存不足。</li><li>liunx64位解决优化方案<ul><li>减少Java堆大小（-Xmx / -Xms）</li><li>减少Java线程数（从业务出发）</li><li>减少Java线程堆栈大小（-Xss）</li><li>使用-XX：ReservedCodeCacheSize =设置更大的代码缓存</li></ul></li></ul></li></ul><h3 id="堆栈信息"><a href="#堆栈信息" class="headerlink" title="堆栈信息"></a>堆栈信息</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---------------  P R O C E S S  ---------------</span><br><span class="line"></span><br><span class="line">Java Threads: ( =&gt; current thread )</span><br><span class="line">=&gt;0x00007f9b9447d800 JavaThread &quot;pool-32458-thread-1&quot; [_thread_new, id=2337, stack(0x00007f9340d91000,0x00007f9340e92000)]</span><br><span class="line">  0x00007f9b8c471000 JavaThread &quot;pool-32456-thread-1&quot; [_thread_blocked, id=2336, stack(0x00007f932a62b000,0x00007f932a72c000)]</span><br><span class="line">  0x00007f9ba44a4000 JavaThread &quot;pool-32455-thread-1&quot; [_thread_blocked, id=2330, stack(0x00007f932a72c000,0x00007f932a82d000)]</span><br><span class="line">  0x00007f9b745ed800 JavaThread &quot;pool-32454-thread-1&quot; [_thread_blocked, id=2319, stack(0x00007f932a82d000,0x00007f932a92e000)]</span><br><span class="line">  0x00007f9b7862a000 JavaThread &quot;pool-32453-thread-1&quot; [_thread_blocked, id=2318, stack(0x00007f932a92e000,0x00007f932aa2f000)]</span><br><span class="line">  0x00007f9b6c5cd800 JavaThread &quot;pool-32452-thread-1&quot; [_thread_blocked, id=2302, stack(0x00007f932aa2f000,0x00007f932ab30000)]</span><br><span class="line">  0x00007f9b98bf0000 JavaThread &quot;pool-32451-thread-1&quot; [_thread_blocked, id=2297, stack(0x00007f932ab30000,0x00007f932ac31000)]</span><br><span class="line">  0x00007f9b44633000 JavaThread &quot;Keep-Alive-Timer&quot; daemon [_thread_blocked, id=2285, stack(0x00007f9330e93000,0x00007f9330f94000)]</span><br><span class="line">  0x00007f9b6450b000 JavaThread &quot;pool-32450-thread-1&quot; [_thread_blocked, id=2187, stack(0x00007f932ac31000,0x00007f932ad32000)]</span><br><span class="line">  0x00007f9b9447b000 JavaThread &quot;pool-32449-thread-1&quot; [_thread_blocked, id=2159, stack(0x00007f932ad32000,0x00007f932ae33000)]</span><br><span class="line">  0x00007f9b8c46f000 JavaThread &quot;pool-32448-thread-1&quot; [_thread_blocked, id=2100, stack(0x00007f932ae33000,0x00007f932af34000)]</span><br><span class="line">  0x00007f9b8059b800 JavaThread &quot;pool-32447-thread-1&quot; [_thread_blocked, id=2068, stack(0x00007f932af34000,0x00007f932b035000)]</span><br><span class="line">  0x00007f9ba44a2000 JavaThread &quot;pool-32446-thread-1&quot; [_thread_blocked, id=1895, stack(0x00007f932b035000,0x00007f932b136000)]</span><br><span class="line">  0x00007f9b745eb000 JavaThread &quot;pool-32445-thread-1&quot; [_thread_blocked, id=1865, stack(0x00007f932b136000,0x00007f932b237000)]</span><br><span class="line">  0x00007f9b78628000 JavaThread &quot;pool-32444-thread-1&quot; [_thread_blocked, id=1864, stack(0x00007f932b237000,0x00007f932b338000)]</span><br><span class="line">  0x00007f9b6c5cb800 JavaThread &quot;pool-32443-thread-1&quot; [_thread_blocked, id=1854, stack(0x00007f932b338000,0x00007f932b439000)]</span><br><span class="line">  0x00007f9b98bed800 JavaThread &quot;pool-32442-thread-1&quot; [_thread_blocked, id=1850, stack(0x00007f932b439000,0x00007f932b53a000)]</span><br><span class="line">  0x00007f9b64508800 JavaThread &quot;pool-32441-thread-1&quot; [_thread_blocked, id=1849, stack(0x00007f932b53a000,0x00007f932b63b000)]</span><br><span class="line">  0x00007f9b94479000 JavaThread &quot;pool-32440-thread-1&quot; [_thread_blocked, id=1835, stack(0x00007f932b63b000,0x00007f932b73c000)]</span><br><span class="line">  0x00007f9b8c46d000 JavaThread &quot;pool-32439-thread-1&quot; [_thread_blocked, id=1832, stack(0x00007f932b73c000,0x00007f932b83d000)]</span><br><span class="line">  0x00007f9b80599000 JavaThread &quot;pool-32438-thread-1&quot; [_thread_blocked, id=1729, stack(0x00007f932b83d000,0x00007f932b93e000)]</span><br><span class="line">  0x00007f9ba449f800 JavaThread &quot;pool-32437-thread-1&quot; [_thread_blocked, id=1657, stack(0x00007f932b93e000,0x00007f932ba3f000)]</span><br><span class="line">  0x00007f9b78625800 JavaThread &quot;pool-32436-thread-1&quot; [_thread_blocked, id=1412, stack(0x00007f932ba3f000,0x00007f932bb40000)]</span><br><span class="line">  0x00007f9b54782000 JavaThread &quot;pool-32435-thread-1&quot; [_thread_blocked, id=1183, stack(0x00007f932bb40000,0x00007f932bc41000)]</span><br><span class="line">  0x00007f9b486df800 JavaThread &quot;pool-32434-thread-1&quot; [_thread_blocked, id=1182, stack(0x00007f932bc41000,0x00007f932bd42000)]</span><br><span class="line">  0x00007f9b44631000 JavaThread &quot;pool-2-thread-16487&quot; [_thread_blocked, id=1180, stack(0x00007f932bd42000,0x00007f932be43000)]</span><br><span class="line">  0x00007f9b4462f000 JavaThread &quot;pool-2-thread-16486&quot; [_thread_blocked, id=1177, stack(0x00007f932be43000,0x00007f932bf44000)]</span><br><span class="line">  0x0000000001d29800 JavaThread &quot;pool-32433-thread-1&quot; [_thread_blocked, id=1176, stack(0x00007f932bf44000,0x00007f932c045000)]</span><br><span class="line">  0x00007f9c5458a800 JavaThread &quot;pool-32432-thread-1&quot; [_thread_blocked, id=1175, stack(0x00007f932c045000,0x00007f932c146000)]</span><br><span class="line">  0x00007f9b4462d000 JavaThread &quot;pool-2-thread-16485&quot; [_thread_blocked, id=1174, stack(0x00007f932c146000,0x00007f932c247000)]</span><br><span class="line">  0x00007f9c4465c800 JavaThread &quot;pool-32431-thread-1&quot; [_thread_blocked, id=1173, stack(0x00007f932c247000,0x00007f932c348000)]</span><br></pre></td></tr></table></figure><ul><li>JAVA线程堆栈，发现堆栈里面大量的pool的线程池，blocked阻塞线程高达32458个，这就是根本原因，每执行一个就创建。</li><li>误用JAVA线程池，每次用都新new一个线程池newSingleThreadScheduledExecutor</li><li>确实每次new会占用堆外堆存，没有跟踪到底层，但是线程池是管理线程的，虚拟机线程肯定是要跟OS申请线程资源的，linux中线程作为轻量进程，每fork一个肯定会占用OS的资源，相对于java虚拟机堆内内存来说，即是占用了堆外内存；而虚拟机本身由于线程池不释放，老生代会一直缓慢增加，但是没有堆外内存那么厉害，当老生代一直增加到100%后，虚拟机本身会报内存溢出。而操作系统层面，由于大量VIRT被占用，就连简单的top有时也会因为没有办法分配内存而执行不了</li></ul><p><a href="https://updatecg.oss-cn-beijing.aliyuncs.com/hs_err_pid114181.log" target="_blank" rel="noopener">[hs_err_pid文件]</a></p><h3 id="优化方案"><a href="#优化方案" class="headerlink" title="优化方案"></a>优化方案</h3><ul><li>线程池用完了必须shutdown()。</li><li>避免一直new创建新的线程池。</li><li>服务总内存16G，此服务启动设置了2G，增大了最大内存至3G，设置堆栈大小256K。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;定时服务无缘无故宕机了，服务相关日志没有任何错误日志。&lt;br&gt;首先报告领导&lt;br&gt;恢复业务&lt;br&gt;排查问题&lt;br&gt;监控服务&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;服务宕机了&quot;&gt;&lt;a href=&quot;#服务宕机了&quot; class=&quot;heade
      
    
    </summary>
    
      <category term="现网" scheme="http://www.updatecg.xin/categories/%E7%8E%B0%E7%BD%91/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
      <category term="JVM" scheme="http://www.updatecg.xin/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>ConcurrentHashMap详解</title>
    <link href="http://www.updatecg.xin/2020/01/20/ConcurrentHashMap/"/>
    <id>http://www.updatecg.xin/2020/01/20/ConcurrentHashMap/</id>
    <published>2020-01-20T06:08:00.000Z</published>
    <updated>2021-08-19T08:56:50.369Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ConcurrentHashMap线程安全</p></blockquote><h2 id="Segment段"><a href="#Segment段" class="headerlink" title="Segment段"></a>Segment段</h2><p>因Segment继承ReentrantLock加锁，所以ConcurrentHashMap支持并发操作。<br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/Segment.png" class="lozad"></p><h2 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h2><p>简单理解就是，ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。</p><h2 id="并行度（默认-16）"><a href="#并行度（默认-16）" class="headerlink" title="并行度（默认 16）"></a>并行度（默认 16）</h2><p><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/ConcurrentHashMapJDK7.jpg" class="lozad"><br>concurrencyLevel：并行级别、并发数、Segment 数，怎么翻译不重要，理解它。默认是 16， 也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。<br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/ConcurrentHashMapJDK8.jpg" class="lozad"><br>Java8 对 ConcurrentHashMap 进行了比较大的改动,Java8 也引入了红黑树。</p><h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><h3 id="减小锁粒度"><a href="#减小锁粒度" class="headerlink" title="减小锁粒度"></a>减小锁粒度</h3><p>减小锁粒度是指缩小锁定对象的范围，从而减小锁冲突的可能性，从而提高系统的并发能力。减小锁粒度是一种削弱多线程锁竞争的有效手段，这种技术典型的应用是 ConcurrentHashMap(高性能的 HashMap)类的实现。对于 HashMap 而言，最重要的两个方法是get 与set 方法，如果我们对整个 HashMap 加锁，可以得到线程安全的对象，但是加锁粒度太大。<span style="font-weight:bold;color:red">Segment 的大小也被称为ConcurrentHashMap 的并发度</span>。</p><h3 id="分段锁"><a href="#分段锁" class="headerlink" title="分段锁"></a>分段锁</h3><p>ConcurrentHashMap，它内部细分了若干个小的 HashMap，称之为段(Segment)。<span style="font-weight:bold;color:red">默认情况下一个ConcurrentHashMap 被进一步细分为 16 个段，既就是锁的并发度</span>。<br>如果需要在 ConcurrentHashMap 中添加一个新的表项，并不是将整个 HashMap 加锁，而是首先根据hashcode 得到该表项应该存放在哪个段中，然后对该段加锁，并完成put 操作。在多线程环境中，如果多个线程同时进行put 操作，只要被加入的表项不存放在同一个段中，则线程间可以做到真正的并行。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;ConcurrentHashMap线程安全&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Segment段&quot;&gt;&lt;a href=&quot;#Segment段&quot; class=&quot;headerlink&quot; title=&quot;Segment段&quot;&gt;&lt;/a&gt;Segmen
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
      <category term="JAVA" scheme="http://www.updatecg.xin/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>JAVA锁</title>
    <link href="http://www.updatecg.xin/2019/12/20/JAVA%E9%94%81/"/>
    <id>http://www.updatecg.xin/2019/12/20/JAVA锁/</id>
    <published>2019-12-20T09:16:00.000Z</published>
    <updated>2021-08-19T08:57:15.498Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>现场安全标识</p></blockquote><h2 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h2><p>乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是<span style="font-weight:bold;color:red">在更新的时候会判断一下在此期间别人有没有去更新这个数  据，采取在写时先读出当前版本号，然后加锁操作<span>（比较跟上一次的版本号，如果一样则更新）， 如果失败则要重复读-比较-写的操作。<br>java 中的乐观锁基本都是通过 CAS 操作实现的，CAS 是一种更新的原子操作，<span style="font-weight:bold;color:red">比较当前值跟传入值是否一样，一样则更新，否则失败<span>。</span></span></span></span></p><h2 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h2><p>悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block 直到拿到锁。java 中的悲观锁就是<span style="font-weight:bold;color:red">Synchronized<span>,AQS 框架下的锁则是先尝试cas 乐观锁去获取锁，获取不到， 才会转换为悲观锁，如RetreenLock。</span></span></p><h2 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h2><p>自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋）， 等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。<br>线程自旋是需要消耗 cup 的，说白了就是让 cup 在做无用功，如果一直获取不到锁，那线程也不能一直占用 cup 自旋做无用功，所以需要设定一个自旋等待的最大时间。<br>如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。</p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换！</p><p>但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，占着 XX 不 XX，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗， 其它需要 cup 的线程又不能获取到 cpu，造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁；</p><h2 id="公平与非公平锁"><a href="#公平与非公平锁" class="headerlink" title="公平与非公平锁"></a>公平与非公平锁</h2><h3 id="公平锁（Fair）"><a href="#公平锁（Fair）" class="headerlink" title="公平锁（Fair）"></a>公平锁（Fair）</h3><p>加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得</p><h3 id="非公平锁（Nonfair）"><a href="#非公平锁（Nonfair）" class="headerlink" title="非公平锁（Nonfair）"></a>非公平锁（Nonfair）</h3><p>加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待</p><ul><li>非公平锁性能比公平锁高 5~10 倍，因为公平锁需要在多核的情况下维护一个队列</li><li>Java 中的synchronized 是非公平锁，ReentrantLock 默认的lock()方法采用的是非公平锁。</li></ul><h2 id="ReadWriteLock-读写锁"><a href="#ReadWriteLock-读写锁" class="headerlink" title="ReadWriteLock 读写锁"></a>ReadWriteLock 读写锁</h2><p>为了提高性能，Java 提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的,在一定程度上提高了程序的执行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm 自己控制的，你只要上好相应的锁即可。</p><h3 id="读锁"><a href="#读锁" class="headerlink" title="读锁"></a>读锁</h3><p>如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁</p><h3 id="写锁"><a href="#写锁" class="headerlink" title="写锁"></a>写锁</h3><p>如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！<br>Java 中 读 写 锁 有 个 接 口 java.util.concurrent.locks.ReadWriteLock ， 也 有 具 体 的 实 现ReentrantReadWriteLock。</p><h2 id="共享锁和独占锁java-并发包提供的加锁模式分为独占锁和共享锁。独占锁"><a href="#共享锁和独占锁java-并发包提供的加锁模式分为独占锁和共享锁。独占锁" class="headerlink" title="共享锁和独占锁java 并发包提供的加锁模式分为独占锁和共享锁。独占锁"></a>共享锁和独占锁java 并发包提供的加锁模式分为独占锁和共享锁。独占锁</h2><p>独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。</p><h3 id="共享锁"><a href="#共享锁" class="headerlink" title="共享锁"></a>共享锁</h3><p>共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。</p><ul><li>AQS 的内部类Node 定义了两个常量 SHARED 和EXCLUSIVE，他们分别标识 AQS 队列中等待线程的锁获取模式。</li><li>java 的并发包中提供了ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问， 或者被一个 写操作访问，但两者不能同时进行。</li></ul><h2 id="分段锁"><a href="#分段锁" class="headerlink" title="分段锁"></a>分段锁</h2><p>分段锁也并非一种实际的锁，而是一种思想ConcurrentHashMap中Segment分段锁。</p><h2 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h2><h3 id="减少锁持有时间"><a href="#减少锁持有时间" class="headerlink" title="减少锁持有时间"></a>减少锁持有时间</h3><p>只用在有线程安全要求的程序上加锁</p><h3 id="减小锁粒度"><a href="#减小锁粒度" class="headerlink" title="减小锁粒度"></a>减小锁粒度</h3><p>将大对象（这个对象可能会被很多线程访问），拆成小对象，大大增加并行度，降低锁竞争。降低了锁的竞争，偏向锁，轻量级锁成功率才会提高。最最典型的减小锁粒度的案例就是ConcurrentHashMap。</p><h3 id="锁分离"><a href="#锁分离" class="headerlink" title="锁分离"></a>锁分离</h3><p><span style="font-weight:bold;color:red">最常见的锁分离就是读写锁 ReadWriteLock</span>，根据功能进行分离成读锁和写锁，这样读读不互斥，读写互斥，写写互斥，即保证了线程安全，又提高了性能，具体也请查看[高并发 Java 五] JDK 并发包 1。读写分离思想可以延伸，只要操作互不影响，锁就可以分离。比如LinkedBlockingQueue 从头部取出，从尾部放数据</p><h3 id="锁粗化"><a href="#锁粗化" class="headerlink" title="锁粗化"></a>锁粗化</h3><p>通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完公共资源后，应该立即释放锁。但是，凡事都有一个度，<span style="font-weight:bold;color:red">如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化 </span>。</p><h3 id="锁消除"><a href="#锁消除" class="headerlink" title="锁消除"></a>锁消除</h3><p>锁消除是在编译器级别的事情。在即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作，多数是因为程序员编码不规范引起。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;现场安全标识&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;乐观锁&quot;&gt;&lt;a href=&quot;#乐观锁&quot; class=&quot;headerlink&quot; title=&quot;乐观锁&quot;&gt;&lt;/a&gt;乐观锁&lt;/h2&gt;&lt;p&gt;乐观锁是一种乐观思想，即认为读多写少，遇到并发写的
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
      <category term="JAVA" scheme="http://www.updatecg.xin/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>RocketMq源码刨析之分布式事务</title>
    <link href="http://www.updatecg.xin/2019/10/01/RocketMq/"/>
    <id>http://www.updatecg.xin/2019/10/01/RocketMq/</id>
    <published>2019-10-01T09:05:02.000Z</published>
    <updated>2021-08-19T08:58:08.531Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RocketMq源码刨析"><a href="#RocketMq源码刨析" class="headerlink" title="RocketMq源码刨析"></a>RocketMq源码刨析</h2><blockquote><p>想必大家都比较熟悉RocketMQ,阿里开源消息队列项目。对于队列来说可以直接强势得理解成，处理并非、分布式事务得敌虫。</p></blockquote><h3 id="源码地址-https-github-com-apache-rocketmq"><a href="#源码地址-https-github-com-apache-rocketmq" class="headerlink" title="[源码地址]: https://github.com/apache/rocketmq"></a>[源码地址]: <a href="https://github.com/apache/rocketmq" target="_blank" rel="noopener">https://github.com/apache/rocketmq</a></h3><p><img data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/rocket.jpg" class="lozad"></p><h2 id="RocketMq4-3版本-支持分布式事物"><a href="#RocketMq4-3版本-支持分布式事物" class="headerlink" title="RocketMq4.3版本 支持分布式事物"></a>RocketMq4.3版本 支持分布式事物</h2><h3 id="案例入口【org-apache-rocketmq-example-transaction-TransactionProducer】"><a href="#案例入口【org-apache-rocketmq-example-transaction-TransactionProducer】" class="headerlink" title="案例入口【org.apache.rocketmq.example.transaction.TransactionProducer】"></a>案例入口【org.apache.rocketmq.example.transaction.TransactionProducer】</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//实现监听</span></span><br><span class="line">TransactionListener transactionListener = <span class="keyword">new</span> TransactionListenerImpl();</span><br><span class="line"><span class="comment">//生产者本地初始化</span></span><br><span class="line">TransactionMQProducer producer = <span class="keyword">new</span> TransactionMQProducer(<span class="string">"please_rename_unique_group_name"</span>);</span><br><span class="line">ExecutorService executorService = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">2</span>, <span class="number">5</span>, <span class="number">100</span>, TimeUnit.SECONDS, <span class="keyword">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class="number">2000</span>), <span class="keyword">new</span> ThreadFactory() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Thread <span class="title">newThread</span><span class="params">(Runnable r)</span> </span>&#123;</span><br><span class="line">        Thread thread = <span class="keyword">new</span> Thread(r);</span><br><span class="line">        thread.setName(<span class="string">"client-transaction-msg-check-thread"</span>);</span><br><span class="line">        <span class="keyword">return</span> thread;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">//设置线程池</span></span><br><span class="line">producer.setExecutorService(executorService);</span><br><span class="line"><span class="comment">//设置生产者本地事务得回调组件</span></span><br><span class="line">producer.setTransactionListener(transactionListener);</span><br><span class="line"><span class="comment">//开启消息处理</span></span><br><span class="line">producer.start();</span><br></pre></td></tr></table></figure><h3 id="案例入口【org-apache-rocketmq-client-impl-producer-DefaultMQProducerImpl-sendMessageInTransaction】"><a href="#案例入口【org-apache-rocketmq-client-impl-producer-DefaultMQProducerImpl-sendMessageInTransaction】" class="headerlink" title="案例入口【org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendMessageInTransaction】"></a>案例入口【org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendMessageInTransaction】</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> TransactionSendResult <span class="title">sendMessageInTransaction</span><span class="params">(<span class="keyword">final</span> Message msg,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                      <span class="keyword">final</span> LocalTransactionExecuter localTransactionExecuter, <span class="keyword">final</span> Object arg)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> MQClientException </span>&#123;</span><br><span class="line">    <span class="comment">//获取之前注册得TransactionListener本地事务回调组件</span></span><br><span class="line">    TransactionListener transactionListener = getCheckListener();</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == localTransactionExecuter &amp;&amp; <span class="keyword">null</span> == transactionListener) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> MQClientException(<span class="string">"tranExecutor is null"</span>, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//验证消息</span></span><br><span class="line">    Validators.checkMessage(msg, <span class="keyword">this</span>.defaultMQProducer);</span><br><span class="line"></span><br><span class="line">    SendResult sendResult = <span class="keyword">null</span>;</span><br><span class="line">    MessageAccessor.putProperty(msg, MessageConst.PROPERTY_TRANSACTION_PREPARED, <span class="string">"true"</span>);</span><br><span class="line">    MessageAccessor.putProperty(msg, MessageConst.PROPERTY_PRODUCER_GROUP, <span class="keyword">this</span>.defaultMQProducer.getProducerGroup());</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//发送消息</span></span><br><span class="line">        sendResult = <span class="keyword">this</span>.send(msg);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> MQClientException(<span class="string">"send message Exception"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW;</span><br><span class="line">    Throwable localException = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取发送消息回调结果</span></span><br><span class="line">    <span class="keyword">switch</span> (sendResult.getSendStatus()) &#123;</span><br><span class="line">        <span class="keyword">case</span> SEND_OK: &#123;<span class="comment">//发送成功</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (sendResult.getTransactionId() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    msg.putUserProperty(<span class="string">"__transactionId__"</span>, sendResult.getTransactionId());</span><br><span class="line">                &#125;</span><br><span class="line">                String transactionId = msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX);</span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">null</span> != transactionId &amp;&amp; !<span class="string">""</span>.equals(transactionId)) &#123;</span><br><span class="line">                    msg.setTransactionId(transactionId);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">//开启了本地事务回调组件才会进行回调处理</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">null</span> != localTransactionExecuter) &#123;</span><br><span class="line">                    localTransactionState = localTransactionExecuter.executeLocalTransactionBranch(msg, arg);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (transactionListener != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    log.debug(<span class="string">"Used new transaction API"</span>);</span><br><span class="line">                    <span class="comment">//执行本地事务</span></span><br><span class="line">                    localTransactionState = transactionListener.executeLocalTransaction(msg, arg);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">null</span> == localTransactionState) &#123;</span><br><span class="line">                    localTransactionState = LocalTransactionState.UNKNOW;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (localTransactionState != LocalTransactionState.COMMIT_MESSAGE) &#123;</span><br><span class="line">                    log.info(<span class="string">"executeLocalTransactionBranch return &#123;&#125;"</span>, localTransactionState);</span><br><span class="line">                    log.info(msg.toString());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">                log.info(<span class="string">"executeLocalTransactionBranch exception"</span>, e);</span><br><span class="line">                log.info(msg.toString());</span><br><span class="line">                localException = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> FLUSH_DISK_TIMEOUT:</span><br><span class="line">        <span class="keyword">case</span> FLUSH_SLAVE_TIMEOUT:</span><br><span class="line">        <span class="keyword">case</span> SLAVE_NOT_AVAILABLE:</span><br><span class="line">            localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//根据本地事务执行的结果去发送commit消息或者rollback消息</span></span><br><span class="line">        <span class="keyword">this</span>.endTransaction(sendResult, localTransactionState, localException);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        log.warn(<span class="string">"local transaction execute "</span> + localTransactionState + <span class="string">", but end broker transaction failed"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    TransactionSendResult transactionSendResult = <span class="keyword">new</span> TransactionSendResult();</span><br><span class="line">    transactionSendResult.setSendStatus(sendResult.getSendStatus());</span><br><span class="line">    transactionSendResult.setMessageQueue(sendResult.getMessageQueue());</span><br><span class="line">    transactionSendResult.setMsgId(sendResult.getMsgId());</span><br><span class="line">    transactionSendResult.setQueueOffset(sendResult.getQueueOffset());</span><br><span class="line">    transactionSendResult.setTransactionId(sendResult.getTransactionId());</span><br><span class="line">    transactionSendResult.setLocalTransactionState(localTransactionState);</span><br><span class="line">    <span class="keyword">return</span> transactionSendResult;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="总要节点"><a href="#总要节点" class="headerlink" title="总要节点"></a>总要节点</h4><ul><li>获取之前注册得TransactionListener本地事务回调组件：TransactionListener transactionListener = getCheckListener();</li><li>验证消息： Validators.checkMessage(msg, this.defaultMQProducer);</li><li>发送消息： sendResult = this.send(msg);</li><li>获取发送消息回调结果：switch (sendResult.getSendStatus())</li><li>如果开启事务transactionListener，执行本地事务：localTransactionState = transactionListener.executeLocalTransaction(msg, arg);</li><li>根据本地事务执行的结果去发送commit消息或者rollback消息：this.endTransaction(sendResult, localTransactionState, localException);</li></ul><h4 id="本地事务逻辑"><a href="#本地事务逻辑" class="headerlink" title="本地事务逻辑"></a>本地事务逻辑</h4><h5 id="案例入口【org-apache-rocketmq-example-transaction-executeLocalTransaction】"><a href="#案例入口【org-apache-rocketmq-example-transaction-executeLocalTransaction】" class="headerlink" title="案例入口【org.apache.rocketmq.example.transaction.executeLocalTransaction】"></a>案例入口【org.apache.rocketmq.example.transaction.executeLocalTransaction】</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> LocalTransactionState <span class="title">executeLocalTransaction</span><span class="params">(Message msg, Object arg)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//这里会执行本地业务逻辑，此处省略...</span></span><br><span class="line">      <span class="comment">//返回本地事物的执行结果（UNKNOW、commit、rollback）</span></span><br><span class="line">      <span class="keyword">int</span> value = transactionIndex.getAndIncrement();</span><br><span class="line">      <span class="keyword">int</span> status = value % <span class="number">3</span>;</span><br><span class="line">      localTrans.put(msg.getTransactionId(), status);</span><br><span class="line">      <span class="keyword">return</span> LocalTransactionState.UNKNOW;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h4 id="Netty线程检查事务状态"><a href="#Netty线程检查事务状态" class="headerlink" title="Netty线程检查事务状态"></a>Netty线程检查事务状态</h4><h5 id="案例入口【org-apache-rocketmq-example-transaction-checkLocalTransaction】"><a href="#案例入口【org-apache-rocketmq-example-transaction-checkLocalTransaction】" class="headerlink" title="案例入口【org.apache.rocketmq.example.transaction.checkLocalTransaction】"></a>案例入口【org.apache.rocketmq.example.transaction.checkLocalTransaction】</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> LocalTransactionState <span class="title">checkLocalTransaction</span><span class="params">(MessageExt msg)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//实现本地事务处理得结果逻辑</span></span><br><span class="line">    <span class="comment">//TODO 业务数据</span></span><br><span class="line">    <span class="comment">//比如本地业务想表A插入数据，那么此处可以去表A查询数据是否存在，就可以指导本地事务是否成功</span></span><br><span class="line">    <span class="comment">//根据本地事务响应得到结果，返回不同得状态。</span></span><br><span class="line">    <span class="comment">//本地事物执行成功返回COMMIT_MESSAGE，反之失败返回ROLLBACK_MESSAGE</span></span><br><span class="line">    Integer status = localTrans.get(msg.getTransactionId());</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> != status) &#123;</span><br><span class="line">        <span class="keyword">switch</span> (status) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> LocalTransactionState.UNKNOW;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>业务场景源码正在创作..</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;RocketMq源码刨析&quot;&gt;&lt;a href=&quot;#RocketMq源码刨析&quot; class=&quot;headerlink&quot; title=&quot;RocketMq源码刨析&quot;&gt;&lt;/a&gt;RocketMq源码刨析&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;想必大家都比较熟悉RocketMQ
      
    
    </summary>
    
      <category term="源码刨析" scheme="http://www.updatecg.xin/categories/%E6%BA%90%E7%A0%81%E5%88%A8%E6%9E%90/"/>
    
    
      <category term="RocketMq" scheme="http://www.updatecg.xin/tags/RocketMq/"/>
    
  </entry>
  
  <entry>
    <title>liunx常用命令</title>
    <link href="http://www.updatecg.xin/2019/05/30/liunx%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://www.updatecg.xin/2019/05/30/liunx常用命令/</id>
    <published>2019-05-30T08:21:00.000Z</published>
    <updated>2021-08-19T08:58:27.671Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>检验真理得决定性是实践。</p></blockquote><h1 id="查看服务器内存信息"><a href="#查看服务器内存信息" class="headerlink" title="查看服务器内存信息"></a>查看服务器内存信息</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@VM_0_12_centos 388]# free -m</span><br><span class="line">            total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:         1839         625         417           0         796        1013</span><br><span class="line">Swap:        0            0           0</span><br></pre></td></tr></table></figure><h1 id="Liunx查看进程运行得完成路径方法"><a href="#Liunx查看进程运行得完成路径方法" class="headerlink" title="Liunx查看进程运行得完成路径方法"></a>Liunx查看进程运行得完成路径方法</h1><h3 id="proc"><a href="#proc" class="headerlink" title="/proc"></a>/proc</h3><p>Linux在启动一个进程时，系统会在/proc下创建一个以PID命名的文件夹，在该文件夹下会有我们的进程的信息，<br>其中包括一个名为exe的文件即记录了绝对路径，通过ll或ls –l命令即可查看。</p><p>列入查看cpu高得服务情况<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PID  USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                                                                                                                                                388  root      16  -4  114564   1264   1032 S  0.3  0.1   4:50.63 auditd                                                                                                                                                                                                    5646 root      20   0  573864  20200   2772 S  0.3  1.1 258:37.17 YDService                                                                                                                                                                                                 5990 root      20   0  576604  41248  12820 S  0.3  2.2   0:03.58 node /data/blog</span><br></pre></td></tr></table></figure></p><p>查询PID等于388<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@VM_0_12_centos data]# cd /proc/388</span><br><span class="line">[root@VM_0_12_centos 388]# ll</span><br><span class="line">total 0</span><br><span class="line">dr-xr-xr-x 2 root root 0 Mar  7 15:03 attr</span><br><span class="line">-rw-r--r-- 1 root root 0 May 30 16:54 autogroup</span><br><span class="line">-r-------- 1 root root 0 May 30 16:54 auxv</span><br><span class="line">-r--r--r-- 1 root root 0 Mar  7 15:03 cgroup</span><br><span class="line">--w------- 1 root root 0 May 30 16:54 clear_refs</span><br><span class="line">-r--r--r-- 1 root root 0 Mar  7 15:03 cmdline</span><br><span class="line">-rw-r--r-- 1 root root 0 Mar  7 15:03 comm</span><br><span class="line">-rw-r--r-- 1 root root 0 May 30 16:54 coredump_filter</span><br><span class="line">-r--r--r-- 1 root root 0 May 30 16:54 cpuset</span><br><span class="line">lrwxrwxrwx 1 root root 0 Mar 24 02:36 cwd -&gt; /</span><br><span class="line">-r-------- 1 root root 0 May 30 16:54 environ</span><br><span class="line">lrwxrwxrwx 1 root root 0 Mar  7 15:03 exe -&gt; /usr/sbin/auditd</span><br><span class="line">dr-x------ 2 root root 0 Mar  7 15:03 fd</span><br><span class="line">dr-x------ 2 root root 0 May 25 10:09 fdinfo</span><br><span class="line">-rw-r--r-- 1 root root 0 May 30 16:54 gid_map</span><br><span class="line">-r-------- 1 root root 0 May 30 16:54 io</span><br><span class="line">-r--r--r-- 1 root root 0 May 30 16:54 limits</span><br><span class="line">-rw-r--r-- 1 root root 0 Mar  7 15:03 loginuid</span><br><span class="line">dr-x------ 2 root root 0 May 30 16:54 map_files</span><br><span class="line">-r--r--r-- 1 root root 0 May 30 16:54 maps</span><br></pre></td></tr></table></figure></p><p>可以看出,即可追踪服务地址<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lrwxrwxrwx 1 root root 0 Mar  7 15:03 exe -&gt; /usr/sbin/auditd</span><br></pre></td></tr></table></figure></p><h2 id="ps-aux"><a href="#ps-aux" class="headerlink" title="ps -aux"></a>ps -aux</h2><p>可查看详细信息<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root         1  0.0  0.1  41108  2924 ?        Ss   Mar07   6:02 /usr/lib/systemd/systemd --system --deserialize 25</span><br><span class="line">root         2  0.0  0.0      0     0 ?        S    Mar07   0:00 [kthreadd]</span><br><span class="line">root         3  0.0  0.0      0     0 ?        S    Mar07   1:28 [ksoftirqd/0]</span><br><span class="line">root         5  0.0  0.0      0     0 ?        S&lt;   Mar07   0:00 [kworker/0:0H]</span><br></pre></td></tr></table></figure></p><h1 id="查看文件夹容量"><a href="#查看文件夹容量" class="headerlink" title="查看文件夹容量"></a>查看文件夹容量</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@VM_0_12_centos data]# du -sh</span><br><span class="line">248M.</span><br></pre></td></tr></table></figure><h1 id="Liunx如何修改默认SSH端口"><a href="#Liunx如何修改默认SSH端口" class="headerlink" title="Liunx如何修改默认SSH端口"></a>Liunx如何修改默认SSH端口</h1><p>linux SSH默认端口是22，不修改的话存在一定的风险，要么是被人恶意扫描，要么会被人破解或者攻击，所以我们需要修改默认的SSH端口。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure></p><p>默认端口是22，并且已经被注释掉了，打开注释修改为其他未占用端口即可。</p><p>开启防火墙端口并重复服务即可。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart sshd.service</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;检验真理得决定性是实践。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;查看服务器内存信息&quot;&gt;&lt;a href=&quot;#查看服务器内存信息&quot; class=&quot;headerlink&quot; title=&quot;查看服务器内存信息&quot;&gt;&lt;/a&gt;查看服务器内存信息&lt;/h
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
      <category term="liunx" scheme="http://www.updatecg.xin/tags/liunx/"/>
    
  </entry>
  
  <entry>
    <title>docker命令大全</title>
    <link href="http://www.updatecg.xin/2019/05/20/docker%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/"/>
    <id>http://www.updatecg.xin/2019/05/20/docker命令大全/</id>
    <published>2019-05-20T09:16:00.000Z</published>
    <updated>2021-08-19T08:58:47.523Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>docker 必须掌握得命令</p></blockquote><h1 id="查看镜像"><a href="#查看镜像" class="headerlink" title="查看镜像"></a>查看镜像</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker images</td><td>列出所有镜像文件</td></tr><tr><td>docker images -a</td><td>列出所有得镜像文件-包括历史</td></tr><tr><td>docker rmi <image id></image></td><td>删除一个或多个镜像</td></tr></tbody></table><h1 id="查看容器"><a href="#查看容器" class="headerlink" title="查看容器"></a>查看容器</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker ps</td><td>列出当前所有正在运行得容器</td></tr><tr><td>docker ps -l</td><td>列出最近一次启动得容器</td></tr><tr><td>docker ps -a</td><td>列出所有容器（包括历史，即运行过得容器）</td></tr><tr><td>docker ps -q</td><td>列出最近一次运行得容器ID</td></tr></tbody></table><h1 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker start/stop/restart <container></container></td><td>开启/停止/重启container</td></tr><tr><td>docker start [container_id]</td><td>再次运行某个container （包括历史container）</td></tr><tr><td>docker attach [container_id]</td><td>连接一个正在运行的container实例（即实例必须为start状态，可以多个窗口同时attach 一个container实例）</td></tr><tr><td>docker exec -it &lt;container_id&gt; /bin/bash</td><td>进入容器</td></tr><tr><td>docker start -i <container></container></td><td>启动一个container并进入交互模式（相当于先start，在attach）</td></tr><tr><td>docker run -i -t <image> /bin/bash</image></td><td>使用image创建container并进入交互模式, login shell是/bin/bash</td></tr><tr><td>docker run -i -t -p &lt;host_port:contain_port&gt;</td><td>映射 HOST 端口到容器，方便外部访问容器内服务，host_port 可以省略，省略表示把 container_port 映射到一个动态端口。</td></tr></tbody></table><p>注：使用start是启动已经创建过得container，使用run则通过image开启一个新的container。</p><h1 id="如何在docker容器和宿主机之间复制文件"><a href="#如何在docker容器和宿主机之间复制文件" class="headerlink" title="如何在docker容器和宿主机之间复制文件"></a>如何在docker容器和宿主机之间复制文件</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>sudo docker cp host_path containerID:container_path</td><td>从主机复制到容器</td></tr><tr><td>sudo docker cp containerID:container_path host_path</td><td>从容器复制到主机</td></tr><tr><td>docker run –name cloud1 -h cloud1 -it jchubby/spark:1.0</td><td>利用镜像启用容器</td></tr></tbody></table><h1 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker rm &lt;container…&gt;</td><td>删除一个或多个container</td></tr><tr><td>docker rm <code>docker ps -a -q</code></td><td>删除所有的container</td></tr><tr><td>docker ps -a -q</td><td>xargs docker rm</td><td>同上, 删除所有的container</td></tr></tbody></table><h1 id="通过容器生成新的镜像"><a href="#通过容器生成新的镜像" class="headerlink" title="通过容器生成新的镜像"></a>通过容器生成新的镜像</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker commit <container-id> <image-name></image-name></container-id></td><td>把一个容器转变为一个新的镜像</td></tr></tbody></table><h1 id="持久化容器"><a href="#持久化容器" class="headerlink" title="持久化容器"></a>持久化容器</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker export <container id> &gt; /tmp/export.tar</container></td><td>export命令用于持久化容器</td></tr></tbody></table><h1 id="特殊命令"><a href="#特殊命令" class="headerlink" title="特殊命令"></a>特殊命令</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker logs $CONTAINER_ID</td><td>查看docker实例运行日志，确保正常运行</td></tr><tr><td>docker inspect $CONTAINER_ID docker inspect &lt;image或者container&gt;</td><td>查看image或container的底层信息</td></tr><tr><td>docker build <path></path></td><td>寻找path路径下名为的Dockerfile的配置文件，使用此配置生成新的image</td></tr><tr><td>docker build -t repo[:tag]</td><td>同上，可以指定repo和可选的tag</td></tr><tr><td>docker build -f <dockerfile></dockerfile></td><td>使用指定的dockerfile配置文件，docker以stdin方式获取内容，使用此配置生成新的image</td></tr><tr><td>docker port <container> <container port></container></container></td><td>查看本地哪个端口映射到container的指定端口，其实用docker ps 也可以看到</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;docker 必须掌握得命令&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;查看镜像&quot;&gt;&lt;a href=&quot;#查看镜像&quot; class=&quot;headerlink&quot; title=&quot;查看镜像&quot;&gt;&lt;/a&gt;查看镜像&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;

      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
  </entry>
  
  <entry>
    <title>Nginx参数配置说明</title>
    <link href="http://www.updatecg.xin/2019/04/15/Nginx%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/"/>
    <id>http://www.updatecg.xin/2019/04/15/Nginx参数配置说明/</id>
    <published>2019-04-15T09:02:00.000Z</published>
    <updated>2020-05-28T04:03:10.662Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Nginx详细配置</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#运行用户</span><br><span class="line">user nobody;</span><br><span class="line">#启动进程,通常设置成和cpu的数量相等</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">#全局错误日志及PID文件</span><br><span class="line">#error_log  logs/error.log;</span><br><span class="line">#error_log  logs/error.log  notice;</span><br><span class="line">#error_log  logs/error.log  info;</span><br><span class="line"></span><br><span class="line">#pid        logs/nginx.pid;</span><br><span class="line"></span><br><span class="line">#工作模式及连接数上限</span><br><span class="line">events &#123;</span><br><span class="line">    #epoll是多路复用IO(I/O Multiplexing)中的一种方式,</span><br><span class="line">    #仅用于linux2.6以上内核,可以大大提高nginx的性能</span><br><span class="line">    use   epoll;</span><br><span class="line"></span><br><span class="line">    #单个后台worker process进程的最大并发链接数    </span><br><span class="line">    worker_connections  1024;</span><br><span class="line"></span><br><span class="line">    # 并发总数是 worker_processes 和 worker_connections 的乘积</span><br><span class="line">    # 即 max_clients = worker_processes * worker_connections</span><br><span class="line">    # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4  为什么</span><br><span class="line">    # 为什么上面反向代理要除以4，应该说是一个经验值</span><br><span class="line">    # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000</span><br><span class="line">    # worker_connections 值的设置跟物理内存大小有关</span><br><span class="line">    # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数</span><br><span class="line">    # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右</span><br><span class="line">    # 我们来看看360M内存的VPS可以打开的文件句柄数是多少：</span><br><span class="line">    # $ cat /proc/sys/fs/file-max</span><br><span class="line">    # 输出 34336</span><br><span class="line">    # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内</span><br><span class="line">    # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置</span><br><span class="line">    # 使得并发总数小于操作系统可以打开的最大文件数目</span><br><span class="line">    # 其实质也就是根据主机的物理CPU和内存进行配置</span><br><span class="line">    # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。</span><br><span class="line">    # ulimit -SHn 65535</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    #设定mime类型,类型由mime.type文件定义</span><br><span class="line">    include    mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    #设定日志格式</span><br><span class="line">    log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line">                      &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">                      &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;</span><br><span class="line"></span><br><span class="line">    access_log  logs/access.log  main;</span><br><span class="line"></span><br><span class="line">    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，</span><br><span class="line">    #对于普通应用，必须设为 on,</span><br><span class="line">    #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，</span><br><span class="line">    #以平衡磁盘与网络I/O处理速度，降低系统的uptime.</span><br><span class="line">    sendfile     on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    #连接超时时间</span><br><span class="line">    #keepalive_timeout  0;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line">    tcp_nodelay     on;</span><br><span class="line"></span><br><span class="line">    #开启gzip压缩</span><br><span class="line">    gzip  on;</span><br><span class="line">    gzip_disable &quot;MSIE [1-6].&quot;;</span><br><span class="line"></span><br><span class="line">    #设定请求缓冲</span><br><span class="line">    client_header_buffer_size    128k;</span><br><span class="line">    large_client_header_buffers  4 128k;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #设定虚拟主机配置</span><br><span class="line">    server &#123;</span><br><span class="line">        #侦听80端口</span><br><span class="line">        listen    80;</span><br><span class="line">        #定义使用 www.nginx.cn访问</span><br><span class="line">        server_name  www.nginx.cn;</span><br><span class="line"></span><br><span class="line">        #定义服务器的默认网站根目录位置</span><br><span class="line">        root html;</span><br><span class="line"></span><br><span class="line">        #设定本虚拟主机的访问日志</span><br><span class="line">        access_log  logs/nginx.access.log  main;</span><br><span class="line"></span><br><span class="line">        #默认请求</span><br><span class="line">        location / &#123;</span><br><span class="line"></span><br><span class="line">            #定义首页索引文件的名称</span><br><span class="line">            index index.php index.html index.htm;   </span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        # 定义错误提示页面</span><br><span class="line">        error_page   500 502 503 504 /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        #静态文件，nginx自己处理</span><br><span class="line">        location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123;</span><br><span class="line"></span><br><span class="line">            #过期30天，静态文件不怎么更新，过期可以设大一点，</span><br><span class="line">            #如果频繁更新，则可以设置得小一点。</span><br><span class="line">            expires 30d;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.</span><br><span class="line">        location ~ .php$ &#123;</span><br><span class="line">            fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">            fastcgi_index index.php;</span><br><span class="line">            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;</span><br><span class="line">            include fastcgi_params;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        #禁止访问 .htxxx 文件</span><br><span class="line">            location ~ /.ht &#123;</span><br><span class="line">            deny all;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Nginx详细配置&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;#运行用户&lt;/span&gt;
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="Nginx" scheme="http://www.updatecg.xin/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>为什么我们做分布式使用Redis</title>
    <link href="http://www.updatecg.xin/2019/03/29/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%BB%AC%E5%81%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%BD%BF%E7%94%A8Redis/"/>
    <id>http://www.updatecg.xin/2019/03/29/为什么我们做分布式使用Redis/</id>
    <published>2019-03-29T03:01:00.000Z</published>
    <updated>2020-05-28T04:03:11.087Z</updated>
    
    <content type="html"><![CDATA[<p>绝大部分写业务的程序员，在实际开发中使用 Redis 的时候，只会 Set Value 和 Get Value 两个操作，对 Redis 整体缺乏一个认知。这里对 Redis 常见问题做一个总结，解决大家的知识盲点。</p><h2 id="1、为什么使用-Redis"><a href="#1、为什么使用-Redis" class="headerlink" title="1、为什么使用 Redis"></a>1、为什么使用 Redis</h2><p>在项目中使用 Redis，主要考虑两个角度：性能和并发。如果只是为了分布式锁这些其他功能，还有其他中间件 Zookpeer 等代替，并非一定要使用 Redis。</p><h3 id="性能："><a href="#性能：" class="headerlink" title="性能："></a>性能：</h3><p>如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的 SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。</p><p>特别是在秒杀系统，在同一时间，几乎所有人都在点，都在下单。。。执行的是同一操作———向数据库查数据。</p><p><img alt="输入图片说明" title="屏幕截图.png" data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/090927_1b0c4b61_87650.png" class="lozad"></p><p>根据交互效果的不同，响应时间没有固定标准。在理想状态下，我们的页面跳转需要在瞬间解决，对于页内操作则需要在刹那间解决。</p><h3 id="并发："><a href="#并发：" class="headerlink" title="并发："></a>并发：</h3><p>如下图所示，在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用 Redis 做一个缓冲操作，让请求先访问到 Redis，而不是直接访问数据库。</p><p> <img alt="输入图片说明" title="屏幕截图.png" data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/090934_f875e978_87650.png" class="lozad"></p><h3 id="使用-Redis-的常见问题"><a href="#使用-Redis-的常见问题" class="headerlink" title="使用 Redis 的常见问题"></a>使用 Redis 的常见问题</h3><ul><li><p>缓存和数据库双写一致性问题</p></li><li><p>缓存雪崩问题</p></li><li><p>缓存击穿问题</p></li><li><p>缓存的并发竞争问题</p></li></ul><h2 id="2、单线程的-Redis-为什么这么快"><a href="#2、单线程的-Redis-为什么这么快" class="headerlink" title="2、单线程的 Redis 为什么这么快"></a>2、单线程的 Redis 为什么这么快</h2><p>这个问题是对 Redis 内部机制的一个考察。很多人都不知道 Redis 是单线程工作模型。</p><h3 id="原因主要是以下三点："><a href="#原因主要是以下三点：" class="headerlink" title="原因主要是以下三点："></a>原因主要是以下三点：</h3><p>纯内存操作</p><p>单线程操作，避免了频繁的上下文切换</p><p>采用了非阻塞 I/O 多路复用机制</p><p>仔细说一说 I/O 多路复用机制，打一个比方：小名在 A 城开了一家快餐店店，负责同城快餐服务。小明因为资金限制，雇佣了一批配送员，然后小曲发现资金不够了，只够买一辆车送快递。</p><h3 id="经营方式一"><a href="#经营方式一" class="headerlink" title="经营方式一"></a>经营方式一</h3><p>客户每下一份订单，小明就让一个配送员盯着，然后让人开车去送。慢慢的小曲就发现了这种经营方式存在下述问题：</p><p>时间都花在了抢车上了，大部分配送员都处在闲置状态，抢到车才能去送。</p><p>随着下单的增多，配送员也越来越多，小明发现快递店里越来越挤，没办法雇佣新的配送员了。</p><p>配送员之间的协调很花时间。</p><p>综合上述缺点，小明痛定思痛，提出了经营方式二。</p><h3 id="经营方式二"><a href="#经营方式二" class="headerlink" title="经营方式二"></a>经营方式二</h3><p>小明只雇佣一个配送员。当客户下单，小明按送达地点标注好，依次放在一个地方。最后，让配送员依次开着车去送，送好了就回来拿下一个。上述两种经营方式对比，很明显第二种效率更高。</p><p>在上述比喻中：</p><p>每个配送员→每个线程</p><p>每个订单→每个 Socket(I/O 流)</p><p>订单的送达地点→Socket 的不同状态</p><p>客户送餐请求→来自客户端的请求</p><p>明曲的经营方式→服务端运行的代码</p><p>一辆车→CPU 的核数</p><p>于是有了如下结论：</p><p>经营方式一就是传统的并发模型，每个 I/O 流(订单)都有一个新的线程(配送员)管理。</p><p>经营方式二就是 I/O 多路复用。只有单个线程(一个配送员)，通过跟踪每个 I/O 流的状态(每个配送员的送达地点)，来管理多个 I/O 流。</p><p>下面类比到真实的 Redis 线程模型，如图所示：</p><p><img alt="输入图片说明" title="屏幕截图.png" data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/090949_68d6f98f_87650.png" class="lozad"></p><p>Redis-client 在操作的时候，会产生具有不同事件类型的 Socket。在服务端，有一段 I/O 多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。</p><h2 id="3、Redis-的数据类型及使用场景"><a href="#3、Redis-的数据类型及使用场景" class="headerlink" title="3、Redis 的数据类型及使用场景"></a>3、Redis 的数据类型及使用场景</h2><p>一个合格的程序员，这五种类型都会用到。</p><p>String</p><p>最常规的 set/get 操作，Value 可以是 String 也可以是数字。一般做一些复杂的计数功能的缓存。</p><p>Hash</p><p>这里 Value 存放的是结构化的对象，比较方便的就是操作其中的某个字段。我在做单点登录的时候，就是用这种数据结构存储用户信息，以 CookieId 作为 Key，设置 30 分钟为缓存过期时间，能很好的模拟出类似 Session 的效果。</p><p>List</p><p>使用 List 的数据结构，可以做简单的消息队列的功能。另外，可以利用 lrange 命令，做基于 Redis 的分页功能，性能极佳，用户体验好。</p><p>Set</p><p>因为 Set 堆放的是一堆不重复值的集合。所以可以做全局去重的功能。我们的系统一般都是集群部署，使用 JVM 自带的 Set 比较麻烦。另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。</p><p>Sorted Set</p><p>Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。可以做排行榜应用，取 TOP N 操作。Sorted Set 可以用来做延时任务。</p><h2 id="4、Redis-的过期策略和内存淘汰机制"><a href="#4、Redis-的过期策略和内存淘汰机制" class="headerlink" title="4、Redis 的过期策略和内存淘汰机制"></a>4、Redis 的过期策略和内存淘汰机制</h2><p>Redis 是否用到家，从这就能看出来。比如你 Redis 只能存 5G 数据，可是你写了 10G，那会删 5G 的数据。怎么删的，这个问题思考过么？</p><p>正解：Redis 采用的是定期删除+惰性删除策略。</p><p>为什么不用定时删除策略</p><p>定时删除，用一个定时器来负责监视 Key，过期则自动删除。虽然内存及时释放，但是十分消耗 CPU 资源。在大并发请求下，CPU 要将时间应用在处理请求，而不是删除 Key，因此没有采用这一策略。</p><p>定期删除+惰性删除如何工作</p><p>定期删除，Redis 默认每个 100ms 检查，有过期 Key 则删除。需要说明的是，Redis 不是每个 100ms 将所有的 Key 检查一次，而是随机抽取进行检查。如果只采用定期删除策略，会导致很多 Key 到时间没有删除。于是，惰性删除派上用场。</p><p>采用定期删除+惰性删除就没其他问题了么</p><p>不是的，如果定期删除没删除掉 Key。并且你也没及时去请求 Key，也就是说惰性删除也没生效。这样，Redis 的内存会越来越高。那么就应该采用内存淘汰机制。</p><p>在 redis.conf 中有一行配置：</p><h1 id="maxmemory-policy-volatile-lru"><a href="#maxmemory-policy-volatile-lru" class="headerlink" title="maxmemory-policy volatile-lru"></a>maxmemory-policy volatile-lru</h1><p>该配置就是配内存淘汰策略的：</p><ul><li><p>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。</p></li><li><p>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。（推荐使用，目前项目在用这种）(最近最久使用算法)</p></li><li><p>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。（应该也没人用吧，你不删最少使用 Key，去随机删）</p></li><li><p>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。（不推荐）</p></li><li><p>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。（依然不推荐）</p></li><li><p>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。（不推荐）</p></li></ul><h2 id="5、Redis-和数据库双写一致性问题"><a href="#5、Redis-和数据库双写一致性问题" class="headerlink" title="5、Redis 和数据库双写一致性问题"></a>5、Redis 和数据库双写一致性问题</h2><p>一致性问题还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。前提是如果对数据有强一致性要求，不能放缓存。我们所做的一切，只能保证最终一致性。</p><p>另外，我们所做的方案从根本上来说，只能降低不一致发生的概率。因此，有强一致性要求的数据，不能放缓存。首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。</p><h2 id="6、如何应对缓存穿透和缓存雪崩问题"><a href="#6、如何应对缓存穿透和缓存雪崩问题" class="headerlink" title="6、如何应对缓存穿透和缓存雪崩问题"></a>6、如何应对缓存穿透和缓存雪崩问题</h2><p>这两个问题，一般中小型传统软件企业很难碰到。如果有大并发的项目，流量有几百万左右，这两个问题一定要深刻考虑。缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。</p><h3 id="缓存穿透解决方案："><a href="#缓存穿透解决方案：" class="headerlink" title="缓存穿透解决方案："></a>缓存穿透解决方案：</h3><ul><li><p>利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。</p></li><li><p>采用异步更新策略，无论 Key 是否取到值，都直接返回。Value 值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。</p></li><li><p>提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的 Key。迅速判断出，请求所携带的 Key 是否合法有效。如果不合法，则直接返回。</p></li><li><p>缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。</p></li></ul><h3 id="缓存雪崩解决方案："><a href="#缓存雪崩解决方案：" class="headerlink" title="缓存雪崩解决方案："></a>缓存雪崩解决方案：</h3><ul><li><p>给缓存的失效时间，加上一个随机值，避免集体失效。</p></li><li><p>使用互斥锁，但是该方案吞吐量明显下降了。</p></li><li><p>双缓存。我们有两个缓存，缓存 A 和缓存 B。缓存 A 的失效时间为 20 分钟，缓存 B 不设失效时间。自己做缓存预热操作。</p></li><li><p>然后细分以下几个小点：从缓存 A 读数据库，有则直接返回；A 没有数据，直接从 B 读数据，直接返回，并且异步启动一个更新线程，更新线程同时更新缓存 A 和缓存 B。</p></li></ul><h2 id="7、如何解决-Redis-的并发竞争-Key-问题"><a href="#7、如何解决-Redis-的并发竞争-Key-问题" class="headerlink" title="7、如何解决 Redis 的并发竞争 Key 问题"></a>7、如何解决 Redis 的并发竞争 Key 问题</h2><p>这个问题大致就是，同时有多个子系统去 Set 一个 Key。这个时候要注意什么呢？大家基本都是推荐用 Redis 事务机制。</p><p>但是我并不推荐使用 Redis 的事务机制。因为我们的生产环境，基本都是 Redis 集群环境，做了数据分片操作。你一个事务中有涉及到多个 Key 操作的时候，这多个 Key 不一定都存储在同一个 redis-server 上。因此，Redis 的事务机制，十分鸡肋。</p><h3 id="如果对这个-Key-操作，不要求顺序"><a href="#如果对这个-Key-操作，不要求顺序" class="headerlink" title="如果对这个 Key 操作，不要求顺序"></a>如果对这个 Key 操作，不要求顺序</h3><p>这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做 set 操作即可，比较简单。</p><h3 id="如果对这个-Key-操作，要求顺序"><a href="#如果对这个-Key-操作，要求顺序" class="headerlink" title="如果对这个 Key 操作，要求顺序"></a>如果对这个 Key 操作，要求顺序</h3><p>假设有一个 key1，系统 A 需要将 key1 设置为 valueA，系统 B 需要将 key1 设置为 valueB，系统 C 需要将 key1 设置为 valueC。</p><p>期望按照 key1 的 value 值按照 valueA &gt; valueB &gt; valueC 的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。</p><h3 id="假设时间戳如下："><a href="#假设时间戳如下：" class="headerlink" title="假设时间戳如下："></a>假设时间戳如下：</h3><p>系统 A key 1 {valueA  3:00}<br>系统 B key 1 {valueB  3:05}<br>系统 C key 1 {valueC  3:10}</p><p>那么，假设系统 B 先抢到锁，将 key1 设置为{valueB 3:05}。接下来系统 A 抢到锁，发现自己的 valueA 的时间戳早于缓存中的时间戳，那就不做 set 操作了，以此类推。其他方法，比如利用队列，将 set 方法变成串行访问也可以。</p><h2 id="8、总结"><a href="#8、总结" class="headerlink" title="8、总结"></a>8、总结</h2><p>Redis 在国内各大公司都能看到其身影，比如我们熟悉的新浪，阿里，腾讯，百度，美团，小米等。学习 Redis，这几方面尤其重要：Redis 客户端、Redis 高级功能、Redis 持久化和开发运维常用问题探讨、Redis 复制的原理和优化策略、Redis 分布式解决方案等。</p><p>转自：<a href="https://www.cnblogs.com/yaodengyan/p/9717080.html" target="_blank" rel="noopener">https://www.cnblogs.com/yaodengyan/p/9717080.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;绝大部分写业务的程序员，在实际开发中使用 Redis 的时候，只会 Set Value 和 Get Value 两个操作，对 Redis 整体缺乏一个认知。这里对 Redis 常见问题做一个总结，解决大家的知识盲点。&lt;/p&gt;
&lt;h2 id=&quot;1、为什么使用-Redis&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="Redis" scheme="http://www.updatecg.xin/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>大数据案例之HDFS-HIVE-Spark</title>
    <link href="http://www.updatecg.xin/2019/03/21/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B%E4%B9%8BHDFS-HIVE-Spark/"/>
    <id>http://www.updatecg.xin/2019/03/21/大数据案例之HDFS-HIVE-Spark/</id>
    <published>2019-03-21T03:16:00.000Z</published>
    <updated>2020-05-28T04:03:10.744Z</updated>
    
    <content type="html"><![CDATA[<blockquote><ul><li>发现Hive后台使用MapReduce作为执行引擎，实在是有点慢.几十万数据查询了10+秒，上千万数据查询了100+秒。</li><li>还是单纯查询没有附加任何条件。Hive作为数据仓库是不错的选择，单表支持几十亿数据库存储。</li><li>对于查询来说，我想就需要考虑其他的MapReduce查询方式了。这里考虑学习SparkSql。</li><li>原因的话就让我们一起来学习，认识吧。</li></ul></blockquote><h2 id="推荐管理Hive数据库软件-Aginity-Workbench-for-Hadoop"><a href="#推荐管理Hive数据库软件-Aginity-Workbench-for-Hadoop" class="headerlink" title="推荐管理Hive数据库软件 Aginity Workbench for Hadoop"></a>推荐管理Hive数据库软件 <code>Aginity Workbench for Hadoop</code></h2><blockquote><p>可视化管理HIVE数据、支持远程连接Hadoop根据dfs创建hive外部映射表。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;发现Hive后台使用MapReduce作为执行引擎，实在是有点慢.几十万数据查询了10+秒，上千万数据查询了100+秒。&lt;/li&gt;
&lt;li&gt;还是单纯查询没有附加任何条件。Hive作为数据仓库是不错的选择，单表支持几十亿数据库存储。&lt;/l
      
    
    </summary>
    
      <category term="大数据" scheme="http://www.updatecg.xin/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="http://www.updatecg.xin/tags/Hadoop/"/>
    
      <category term="Hive" scheme="http://www.updatecg.xin/tags/Hive/"/>
    
      <category term="Spark" scheme="http://www.updatecg.xin/tags/Spark/"/>
    
      <category term="Aginity" scheme="http://www.updatecg.xin/tags/Aginity/"/>
    
  </entry>
  
  <entry>
    <title>大数据案例之HDFS-HIVE</title>
    <link href="http://www.updatecg.xin/2019/03/13/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B%E4%B9%8BHDFS-HIVE/"/>
    <id>http://www.updatecg.xin/2019/03/13/大数据案例之HDFS-HIVE/</id>
    <published>2019-03-13T07:42:00.000Z</published>
    <updated>2020-05-28T04:03:09.916Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>基于Hdfs、hive、mysql数据处理案例，闲时自玩项目</p></blockquote><h2 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h2><blockquote><p>数据采集方式有很多种，一般在项目中采用数据上报方式。本地为了方便测试则采用读取csv文件。后续python自动抓取数据。</p></blockquote><p>链接: <a href="https://pan.baidu.com/s/1cOCe1GXAxtkXCUbvY0MWFw" target="_blank" rel="noopener">https://pan.baidu.com/s/1cOCe1GXAxtkXCUbvY0MWFw</a> 提取码: r23c<br>数据量不多，侧重于功能</p><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><blockquote><p>清洗数据,统计分析数据，结果存储HDFS ,加载至HIVE, Sqoop至MYSQL</p></blockquote><h3 id="CSV-数据加载入Hadoop-部分代码"><a href="#CSV-数据加载入Hadoop-部分代码" class="headerlink" title="CSV 数据加载入Hadoop  部分代码"></a>CSV 数据加载入Hadoop  部分代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public String transfer(File file, String folderPath, String fileName) throws Exception &#123;</span><br><span class="line">  if (!opened) &#123;</span><br><span class="line">      throw new Exception(&quot;FileSystem was not opened!&quot;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  boolean folderCreated = fs.mkdirs(new Path(folderPath));</span><br><span class="line"></span><br><span class="line">  Path filePath = new Path(folderPath, StrUtils.isEmpty(fileName) ? file.getName() : fileName);</span><br><span class="line">  boolean fileCreated = fs.createNewFile(filePath);</span><br><span class="line"></span><br><span class="line">  FSDataOutputStream append = fs.append(filePath);</span><br><span class="line">  byte[] bytes = new byte[COPY_BUFFERSIZE];</span><br><span class="line">  int size = 0;</span><br><span class="line">  FileInputStream fileInputStream = new FileInputStream(file);</span><br><span class="line">  while ((size = fileInputStream.read(bytes)) &gt; 0) &#123;</span><br><span class="line">      append.write(bytes, 0, size);</span><br><span class="line">  &#125;</span><br><span class="line">  fileInputStream.close();</span><br><span class="line">  return filePath.toUri().toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="将dfs文件加载入hive-部分代码"><a href="#将dfs文件加载入hive-部分代码" class="headerlink" title="将dfs文件加载入hive 部分代码"></a>将dfs文件加载入hive 部分代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  //表</span><br><span class="line">  String yyyyMMdd = hiveTable + DateUtil.formatDate(new Date(), &quot;yyyyMMdd&quot;);</span><br><span class="line">  //参数</span><br><span class="line">  Map&lt;String, String&gt; map = new HashMap&lt;&gt;();</span><br><span class="line">  map.put(&quot;title&quot;, &quot;STRING&quot;);</span><br><span class="line">  map.put(&quot;discountPrice&quot;, &quot;STRING&quot;);</span><br><span class="line">  map.put(&quot;price&quot;, &quot;STRING&quot;);</span><br><span class="line">  map.put(&quot;address&quot;, &quot;STRING&quot;);</span><br><span class="line">  map.put(&quot;count&quot;, &quot;STRING&quot;);</span><br><span class="line"></span><br><span class="line">  //创建表 按天分表</span><br><span class="line">  hiveDataService.createHiveTable(yyyyMMdd, map);</span><br><span class="line">  //将dfs数据加载到hive表</span><br><span class="line">  hiveDataService.loadHiveIntoTable(fs.getDfsPath(), yyyyMMdd);</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">  * @param tableName     hive表名</span><br><span class="line">  * @param parametersMap 表字段值/类型</span><br><span class="line">  */</span><br><span class="line"> @Override</span><br><span class="line"> public void createHiveTable(String tableName, Map&lt;String, String&gt; parametersMap) &#123;</span><br><span class="line">     StringBuffer sql = new StringBuffer(&quot;CREATE TABLE IF NOT EXISTS &quot;);</span><br><span class="line">     sql.append(&quot;&quot; + tableName + &quot;&quot;);</span><br><span class="line">     StringBuffer sb = new StringBuffer();</span><br><span class="line">     parametersMap.forEach((k, v) -&gt; &#123;</span><br><span class="line">         sb.append(k + &quot; &quot; + v + &quot;,&quot;);</span><br><span class="line">     &#125;);</span><br><span class="line">     sql.append(&quot;(&quot; + sb.deleteCharAt(sb.length() - 1) + &quot;)&quot;);</span><br><span class="line">     sql.append(&quot;ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; LINES TERMINATED BY &apos;\n&apos; &quot;); // 定义分隔符</span><br><span class="line">     sql.append(&quot;STORED AS TEXTFILE&quot;); // 作为文本存储</span><br><span class="line"></span><br><span class="line">     Log.info(&quot;Create table [&quot; + tableName + &quot;] successfully...&quot;);</span><br><span class="line">     try &#123;</span><br><span class="line">         hiveJdbcTemplate.execute(sql.toString());</span><br><span class="line">     &#125; catch (DataAccessException dae) &#123;</span><br><span class="line">         Log.error(dae.fillInStackTrace());</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * @param filePath  dfs文件路径</span><br><span class="line"> * @param tableName 表名</span><br><span class="line"> */</span><br><span class="line">@Override</span><br><span class="line">public void loadHiveIntoTable(String filePath, String tableName) &#123;</span><br><span class="line">    StringBuffer sql = new StringBuffer(&quot;load data inpath &quot;);</span><br><span class="line">    sql.append(&quot;&apos;&quot; + filePath + &quot;&apos;into table &quot; + tableName);</span><br><span class="line">    Log.info(&quot;Load data into table successfully...&quot;);</span><br><span class="line">    try &#123;</span><br><span class="line">        hiveJdbcTemplate.execute(sql.toString());</span><br><span class="line">    &#125; catch (DataAccessException dae) &#123;</span><br><span class="line">        Log.error(dae.fillInStackTrace());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="利用外部表加载dfs数据至分区表"><a href="#利用外部表加载dfs数据至分区表" class="headerlink" title="利用外部表加载dfs数据至分区表"></a>利用外部表加载dfs数据至分区表</h4><blockquote><p>上述代码中有一步为load data 至hive。在于朋友交流中，他提醒可以直接利用<code>外部加载数据</code>，自此代码如下：</p></blockquote><h5 id="外部表好处"><a href="#外部表好处" class="headerlink" title="外部表好处"></a><code>外部表</code>好处</h5><ul><li>hive创建外部表时,仅记录数据所在的路径,不对数据的位置做任何改变</li><li>删除表的时候,外部表只删除元数据,不删除数据</li><li>内部表drop表会把元数据删除</li></ul><h5 id="Hive创建外部表"><a href="#Hive创建外部表" class="headerlink" title="Hive创建外部表"></a>Hive创建外部表</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---------------------------------java代码-----------------------------------------</span><br><span class="line">    /**</span><br><span class="line">     * 利用外部表加载数据   </span><br><span class="line">     *</span><br><span class="line">     * @param tableName     hive表名</span><br><span class="line">     * @param parametersMap 表字段值/类型</span><br><span class="line">     * @param dfsUrl        dfs文件地址</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public synchronized void createOuterHiveTable(String tableName, Map&lt;String, String&gt; parametersMap, String dfsUrl) &#123;</span><br><span class="line">        StringBuffer sql = new StringBuffer(&quot;CREATE EXTERNAL TABLE IF NOT EXISTS &quot;);</span><br><span class="line">        sql.append(&quot;&quot; + tableName + &quot;&quot;);</span><br><span class="line">        StringBuffer sb = new StringBuffer();</span><br><span class="line">        parametersMap.forEach((k, v) -&gt; &#123;</span><br><span class="line">            sb.append(k + &quot; &quot; + v + &quot;,&quot;);</span><br><span class="line">        &#125;);</span><br><span class="line">        sql.append(&quot;(&quot; + sb.deleteCharAt(sb.length() - 1) + &quot;)&quot;);</span><br><span class="line">        sql.append(&quot; PARTITIONED BY (day STRING)&quot;);</span><br><span class="line">        sql.append(&quot; ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; &quot; +</span><br><span class="line">                &quot; COLLECTION ITEMS TERMINATED BY &apos;\\002&apos;&quot; +</span><br><span class="line">                &quot; MAP KEYS TERMINATED BY &apos;\\003&apos;&quot; +</span><br><span class="line">                &quot; LINES TERMINATED BY &apos;\n&apos; &quot;); // 定义分隔符</span><br><span class="line">        sql.append(&quot;LOCATION &apos;&quot; + dfsUrl + &quot;&apos;&quot;); // 外部表加载hdfs数据目录</span><br><span class="line"></span><br><span class="line">        Log.info(&quot;Create EXTERNAL table [&quot; + tableName + &quot;] successfully...&quot;);</span><br><span class="line">        try &#123;</span><br><span class="line">            hiveJdbcTemplate.execute(sql.toString());</span><br><span class="line">        &#125; catch (DataAccessException dae) &#123;</span><br><span class="line">            Log.error(dae.fillInStackTrace());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">------------------------------------Sql---------------------------------------------</span><br><span class="line">    CREATE EXTERNAL TABLE IF NOT EXISTS  xx_outer_partitioned</span><br><span class="line">    (</span><br><span class="line">    affiliatedbasenum STRING,</span><br><span class="line">    locationid STRING,</span><br><span class="line">    pickupdate</span><br><span class="line">    dispatchingbasenum STRING</span><br><span class="line">    )</span><br><span class="line">    PARTITIONED BY (day STRING)</span><br><span class="line">    ROW FORMAT DELIMITED</span><br><span class="line">    FIELDS TERMINATED BY &apos;,&apos;</span><br><span class="line">    COLLECTION ITEMS TERMINATED BY &apos;\002&apos;</span><br><span class="line">    MAP KEYS TERMINATED BY &apos;\003&apos;</span><br><span class="line">    LINES TERMINATED BY &apos;\n&apos;</span><br><span class="line">    LOCATION &apos;/data/outerClientSummary/&apos;;</span><br></pre></td></tr></table></figure><h3 id="HIVE分析数据"><a href="#HIVE分析数据" class="headerlink" title="HIVE分析数据"></a>HIVE分析数据</h3><blockquote><p>hive支持sql操作（支持连表操作、排序），支持分区（此功能特别实用，比如数据量庞大时一般会按照天分表，此时就可以利用按天分区）</p></blockquote><h4 id="案列-：统计服装制造商主要城市分布-（因为hive字段与值对应错乱，但是导入至mysql不会错乱）"><a href="#案列-：统计服装制造商主要城市分布-（因为hive字段与值对应错乱，但是导入至mysql不会错乱）" class="headerlink" title="案列 ：统计服装制造商主要城市分布 （因为hive字段与值对应错乱，但是导入至mysql不会错乱）"></a><code>案列</code> ：统计服装制造商主要城市分布 （因为hive字段与值对应错乱，但是导入至mysql不会错乱）</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select count as addr,count(count)  from commodity20190315 GROUP BY count;</span><br><span class="line">广东广州361</span><br><span class="line">浙江杭州94</span><br><span class="line">广东深圳87</span><br><span class="line">上海76</span><br><span class="line">广东东莞74</span><br><span class="line">江苏苏州52</span><br><span class="line">浙江嘉兴24</span><br><span class="line">广东佛山22</span><br><span class="line">福建泉州15</span><br><span class="line">北京14</span><br><span class="line">天津13</span><br><span class="line">四川成都12</span><br><span class="line"></span><br><span class="line">....... 省略</span><br></pre></td></tr></table></figure><p><code>结果</code>：这是对一千多条的抽样调查，由此可见我们平时的衣物制造商地点<code>广东广州</code>居多。</p><h3 id="Sqoop-将分析后HIVE数据导出至MYSQL-主要思想："><a href="#Sqoop-将分析后HIVE数据导出至MYSQL-主要思想：" class="headerlink" title="Sqoop 将分析后HIVE数据导出至MYSQL 主要思想："></a>Sqoop 将分析后HIVE数据导出至MYSQL <code>主要思想</code>：</h3><blockquote><p>sqoop export –connect jdbc:mysql://IP地址:3306/mall –username root  –password 123456 –table commodity20190315 –export-dir /hivedata/warehouse/hive.db/commodity20190314 –input-fields-terminated-by ‘,’ –input-null-string ‘\N’ –input-null-non-string ‘\N’</p></blockquote><blockquote><p>此命令是经过一下错误原因完善出来的。</p></blockquote><p><code>--export-dir</code>：代表dfs文件目录，则是hive存储数据的地方<br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/dfs1.jpg" class="lozad"></p><p><code>错误原因1</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">19/03/15 09:20:25 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Error parsing arguments for export:</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Unrecognized argument: –input-null-string</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Unrecognized argument: \N</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Unrecognized argument: –input-null-non-string</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Unrecognized argument: \N</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Unrecognized argument: –input-fields-terminated-by</span><br></pre></td></tr></table></figure></p><p><code>解决方式</code> ：命令输入错误，注意“-connect”应该是“–connect”杠</p><p><code>错误原因2</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">19/03/15 09:41:47 ERROR mapreduce.TextExportMapper: Exception:</span><br><span class="line">java.lang.RuntimeException: Can&apos;t parse input data: &apos;2019春季新款chic条纹套头毛衣女装学生韩版宽松显瘦百搭长袖上衣,39.98,42.98,广东 广州,350&apos;</span><br><span class="line">at commodity20190314.__loadFromFields(commodity20190314.java:487)</span><br><span class="line">at commodity20190314.parse(commodity20190314.java:386)</span><br><span class="line">at org.apache.sqoop.mapreduce.TextExportMapper.map(TextExportMapper.java:89)</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.Exception: java.io.IOException: Can&apos;t export data, please check failed map task logs</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)</span><br><span class="line">Caused by: java.io.IOException: Can&apos;t export data, please check failed map task logs</span><br><span class="line">at org.apache.sqoop.mapreduce.TextExportMapper.map(TextExportMapper.java:122)</span><br><span class="line">at org.apache.sqoop.mapreduce.TextExportMapper.map(TextExportMapper.java:39)</span><br><span class="line">at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)</span><br><span class="line">at org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)</span><br><span class="line">at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)</span><br><span class="line">at java.lang.Thread.run(Thread.java:745)</span><br></pre></td></tr></table></figure><p><code>解决方式</code> ：检查数据是否包含“ ”空格，去掉空格，hive默认分割符–input-fields-terminated-by ‘,’，后续发现mysql表多了id，hive没有导致转码出错。</p><p><code>成功将HIVE数据导入MYSQL</code><br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/hiveToMysql.jpg" class="lozad"></p><h2 id="统计-分析"><a href="#统计-分析" class="headerlink" title="统计/分析"></a>统计/分析</h2><blockquote><p>因数据量较小，则想利用python爬取数据，数据量偏少。则通过第三方地址下载。</p></blockquote><h3 id="爬取今日头条"><a href="#爬取今日头条" class="headerlink" title="爬取今日头条"></a>爬取今日头条</h3><blockquote><p>今日头条每天新闻信息在100条左右，最多抓取5天之内的数据。数据量极少。</p></blockquote><p><img data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/%E5%A4%B4%E6%9D%A1.jpg" class="lozad"></p><h3 id="HIVE数据分析"><a href="#HIVE数据分析" class="headerlink" title="HIVE数据分析"></a>HIVE数据分析</h3><p><code>数据集资源来源</code>:<a href="http://dataju.cn/Dataju/web/home" target="_blank" rel="noopener">http://dataju.cn/Dataju/web/home</a> 里面包含各种类数据集M-T级文件不等。是一个自娱自玩数据来源的好地址。</p><blockquote><p>总条数 <code>14270481</code> 条</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select count(*) from commodity20190320;</span><br><span class="line">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Query ID = root_20190320095041_1829fe55-336b-4481-a869-0b24ea274854</span><br><span class="line">Total jobs = 1</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks determined at compile time: 1</span><br><span class="line">In order to change the average load for a reducer (in bytes):</span><br><span class="line">set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line">In order to limit the maximum number of reducers:</span><br><span class="line">set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line">In order to set a constant number of reducers:</span><br><span class="line">set mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Job running in-process (local Hadoop)</span><br><span class="line">2019-03-20 09:50:43,908 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2019-03-20 09:50:45,926 Stage-1 map = 100%,  reduce = 0%</span><br><span class="line">2019-03-20 09:50:46,936 Stage-1 map = 100%,  reduce = 100%</span><br><span class="line">Ended Job = job_local1948148359_0001</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage-Stage-1:  HDFS Read: 4150522476 HDFS Write: 0 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 0 msec</span><br><span class="line">OK</span><br><span class="line">14270481</span><br><span class="line">Time taken: 6.276 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure><h4 id="按时间动态分区"><a href="#按时间动态分区" class="headerlink" title="按时间动态分区"></a>按时间动态分区</h4><blockquote><p><code>commodity20190320</code> 此表是通过csv导入的全量数据，包含了时间段。</p></blockquote><p><code>使用动态分区需要注意设定以下参数</code>：</p><ul><li>hive.exec.dynamic.partition  <ul><li><code>默认值</code>：false  </li><li><code>是否开启动态分区功能</code>: 默认false关闭</li></ul></li><li>hive.exec.dynamic.partition.mode  <ul><li><code>默认值</code>：strict  </li><li><code>动态分区的模式</code>，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。</li></ul></li><li>hive.exec.max.dynamic.partitions.pernode  <ul><li><code>默认值</code>：100</li><li>在每个执行MR的节点上，最大可以创建多少个动态分区。</li><li>该参数需要根据实际的数据来设定。</li><li>比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</li></ul></li><li>hive.exec.max.dynamic.partitions<ul><li><code>默认值</code>：1000</li><li>在所有执行MR的节点上，最大一共可以创建多少个动态分区。</li></ul></li><li>hive.exec.max.created.files<ul><li><code>默认值</code>：100000</li><li>整个MR Job中，最大可以创建多少个HDFS文件。</li><li>一般默认值足够了，除非你的数据量非常大，需要创建的文件数大于100000，可根据实际情况加以调整。</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//查看表结构</span><br><span class="line">    hive&gt; desc commodity20190320;</span><br><span class="line">    OK</span><br><span class="line">    affiliatedbasenum   string                                  </span><br><span class="line">    locationid          string                                  </span><br><span class="line">    pickupdate          string                                  </span><br><span class="line">    dispatchingbasenum  string                                  </span><br><span class="line">    Time taken: 0.044 seconds, Fetched: 4 row(s)</span><br><span class="line"></span><br><span class="line">//创建按月按天分区表</span><br><span class="line">    hive&gt; CREATE TABLE commodity_partitioned (</span><br><span class="line">        &gt; affiliatedbasenum STRING,</span><br><span class="line">        &gt; locationid STRING,</span><br><span class="line">        &gt; dispatchingbasenum STRING</span><br><span class="line">        &gt; ) PARTITIONED BY (month STRING,day STRING)</span><br><span class="line">        &gt; stored AS textfile;</span><br><span class="line">    OK</span><br><span class="line">    Time taken: 0.238 seconds</span><br><span class="line"></span><br><span class="line">//设置动态分区属性</span><br><span class="line">    hive&gt; SET hive.exec.dynamic.partition=true;  </span><br><span class="line">    hive&gt; SET hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line">    hive&gt; SET hive.exec.max.dynamic.partitions.pernode = 1000;</span><br><span class="line">    hive&gt; SET hive.exec.max.dynamic.partitions=1000;</span><br><span class="line"></span><br><span class="line">//时间格式 pickupdate = &quot;5/31/2014 23:59:00&quot; 按天分区则获取年月日即可。利用substr函数：substr(affiliatedbasenum,2,1) AS month,substr(affiliatedbasenum,2,9) AS day</span><br><span class="line">//向分区添加数据</span><br><span class="line">    hive&gt; INSERT overwrite TABLE commodity_partitioned PARTITION (month,day)</span><br><span class="line">        &gt; SELECT locationid,pickupdate,dispatchingbasenum,substr(affiliatedbasenum,2,1) AS month,substr(affiliatedbasenum,2,9) AS day</span><br><span class="line">        &gt; FROM commodity20190320;</span><br></pre></td></tr></table></figure><p><img data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/hive_partitions.gif" class="lozad"></p><h4 id="为外部表挂载分区"><a href="#为外部表挂载分区" class="headerlink" title="为外部表挂载分区"></a>为外部表挂载分区</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---------------------------------java代码-----------------------------------------</span><br><span class="line">    /**</span><br><span class="line">     * @param tableName 外部表名</span><br><span class="line">     * @param yyyyMMdd  分区标识</span><br><span class="line">     * @param dfsUrl    dfs地址</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void loadOuterHiveDataPartitions(String tableName, String yyyyMMdd, String dfsUrl) &#123;</span><br><span class="line">        StringBuffer sql = new StringBuffer(&quot;alter table &quot; + tableName);</span><br><span class="line">        sql.append(&quot; add partition (day=&apos;&quot; + yyyyMMdd + &quot;&apos;) location &apos;&quot; + dfsUrl + yyyyMMdd + &quot;/&apos;&quot;);</span><br><span class="line">        Log.info(&quot;Load data into OuterHiveDataPartitions successfully...&quot;);</span><br><span class="line">        try &#123;</span><br><span class="line">            hiveJdbcTemplate.execute(sql.toString());</span><br><span class="line">        &#125; catch (DataAccessException dae) &#123;</span><br><span class="line">            Log.error(dae.fillInStackTrace());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">---------------------------------Sql-----------------------------------------</span><br><span class="line">  alter table uber_outer_partitioned add partition (day=&apos;2019-03-21&apos;) location &apos;/data/outerClientSummary/2019-03-21&apos;</span><br></pre></td></tr></table></figure><p><img data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/hive_outer_partitions.jpg" class="lozad"></p><p><code>注意</code>：分区数据支持sql查询</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对于大数据初学者的我，这才是我的第一步，都说万事开头难，坚持吧。</p><ul><li>知道如何把已有的数据采集到HDFS上，包括离线采集和实时采集；</li><li>知道sqoop是HDFS和其他数据源之间的数据交换工具,支持把数据在HDFS\HIVE\MYSQL互相传输；</li><li>知道Hadoop的MRV1与Yarn(MRV2)的区别，最主要的单点故障以及性能大大提升。<ul><li>JobTracker被RescourceManager替换</li><li>每一个节点的TaskTacker被NodeManager替换</li><li>Yarn大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗。</li><li>监测每一个 Job 子任务 (tasks) 状态的程序分布式化了</li></ul></li><li>Hive外部表被删除时，不会删除元数据，可以直接在外部表基础啊上创建分区表。</li><li>Hive一般作为数据仓库，几乎不会被用作与OLAP操作<ul><li>原因则在于hive数据量庞大时查询速度太慢.<code>下一章则会着重介绍</code>.</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;基于Hdfs、hive、mysql数据处理案例，闲时自玩项目&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;数据采集&quot;&gt;&lt;a href=&quot;#数据采集&quot; class=&quot;headerlink&quot; title=&quot;数据采集&quot;&gt;&lt;/a&gt;数据采集&lt;/h2&gt;
      
    
    </summary>
    
      <category term="大数据" scheme="http://www.updatecg.xin/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="http://www.updatecg.xin/tags/Hadoop/"/>
    
      <category term="Sqoop" scheme="http://www.updatecg.xin/tags/Sqoop/"/>
    
      <category term="Hive" scheme="http://www.updatecg.xin/tags/Hive/"/>
    
      <category term="Python" scheme="http://www.updatecg.xin/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>sqoop安装部署问题事项</title>
    <link href="http://www.updatecg.xin/2019/03/13/sqoop%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E9%97%AE%E9%A2%98%E4%BA%8B%E9%A1%B9/"/>
    <id>http://www.updatecg.xin/2019/03/13/sqoop安装部署问题事项/</id>
    <published>2019-03-13T03:02:00.000Z</published>
    <updated>2020-05-28T04:03:09.174Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中</p></blockquote><blockquote><p>sqoop主要有两个版本：1.4.x、1.99.x ; sqoop1和sqoop2两个版本。</p></blockquote><h2 id="环境变量配置无问题。-【以下问题是1-99-6版本，经过多方尝试，仍报错】"><a href="#环境变量配置无问题。-【以下问题是1-99-6版本，经过多方尝试，仍报错】" class="headerlink" title="环境变量配置无问题。 【以下问题是1.99.6版本，经过多方尝试，仍报错】"></a>环境变量配置无问题。 <spane style="color:red">【以下问题是1.99.6版本，经过多方尝试，仍报错】</spane></h2><blockquote><p>报错</p></blockquote><p>【-bash: sqoop: command not found】</p><ul><li>sqoop2中已经没有sqoop command指令了…sqoop指令是适用与sqoop1的</li></ul><h2 id="进入sqoop-sh-client，使用show-job-等。"><a href="#进入sqoop-sh-client，使用show-job-等。" class="headerlink" title="进入sqoop.sh client，使用show job 等。"></a>进入sqoop.sh client，使用show job 等。</h2><blockquote><p>报错</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop:000&gt; show job</span><br><span class="line">Exception has occurred during processing command</span><br><span class="line">Exception: org.apache.sqoop.common.SqoopException Message: CLIENT_0000:An unknown error has occurred</span><br></pre></td></tr></table></figure><ul><li><p>原因是没有指定服务端，需设置 set server –host 主机名或IP地址</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop:000&gt; set server --host 主机名或IP地址</span><br><span class="line">Server is set successfully</span><br></pre></td></tr></table></figure></li><li><p>可通过设置,查看错误原因</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop:000&gt; set option --name verbose --value true</span><br><span class="line">Verbose option was changed to true</span><br></pre></td></tr></table></figure></li></ul><h2 id="尝试利用sqoop2-1-99-7版本"><a href="#尝试利用sqoop2-1-99-7版本" class="headerlink" title="尝试利用sqoop2 1.99.7版本"></a>尝试利用sqoop2 1.99.7版本</h2><h2 id="下载地址-https-mirrors-tuna-tsinghua-edu-cn-apache-sqoop"><a href="#下载地址-https-mirrors-tuna-tsinghua-edu-cn-apache-sqoop" class="headerlink" title="下载地址 [https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/]"></a>下载地址 <a href="https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/" target="_blank" rel="noopener">[https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/]</a></h2><h3 id="配置好环境变量"><a href="#配置好环境变量" class="headerlink" title="配置好环境变量"></a>配置好环境变量</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export SQOOP2_HOME=/usr/local/sqoop/</span><br><span class="line">export PATH=$PATH:$SQOOP2_HOME/bin</span><br><span class="line">export CATALINA_BASE=$SQOOP2_HOME/server</span><br></pre></td></tr></table></figure><h3 id="修改-SQOOP2-HOME-conf-sqoop-properties"><a href="#修改-SQOOP2-HOME-conf-sqoop-properties" class="headerlink" title="修改 $SQOOP2_HOME/conf/sqoop.properties"></a>修改 $SQOOP2_HOME/conf/sqoop.properties</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.apache.sqoop.submission.engine.mapreduce.configuration.directory=/usr/local/hadoop-2.7.7/etc/hadoop</span><br><span class="line">org.apache.sqoop.security.authentication.type=SIMPLE</span><br><span class="line">org.apache.sqoop.security.authentication.handler=org.apache.sqoop.security.authentication.SimpleAuthenticationHandler</span><br><span class="line">org.apache.sqoop.security.authentication.anonymous=true</span><br><span class="line"># Number of milliseconds, submissions created before this limit will be removed, default is one day     //锁定提交的job时间，锁定时间内不能删除</span><br><span class="line">org.apache.sqoop.submission.purge.threshold=300000</span><br><span class="line"># JDBC repository provider configuration    //jdbc配置目录</span><br><span class="line">org.apache.sqoop.repository.jdbc.url=jdbc:derby:/usr/local/sqoop/logs/repository/db;create=true</span><br><span class="line">org.apache.sqoop.log4j.appender.file.File=/usr/local/sqoop/logs/sqoop.log                         //sqoop2日志文件目录</span><br><span class="line">org.apache.sqoop.repository.sysprop.derby.stream.error.file=/usr/local/sqoop/logs/derbyrepo.log   //错误日志文件目录</span><br></pre></td></tr></table></figure><h3 id="启动服务端-SQOOP2-HOME-bin-sqoop2-server-start"><a href="#启动服务端-SQOOP2-HOME-bin-sqoop2-server-start" class="headerlink" title="启动服务端 $SQOOP2_HOME/bin/sqoop2-server start"></a>启动服务端 $SQOOP2_HOME/bin/sqoop2-server start</h3><blockquote><p>报错</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Setting conf dir: /usr/local/sqoop/bin/../conf</span><br><span class="line">Sqoop home directory: /usr/local/sqoop</span><br><span class="line">Can&apos;t load the Hadoop related java lib, please check the setting for the following environment variables:</span><br><span class="line">HADOOP_COMMON_HOME, HADOOP_HDFS_HOME, HADOOP_MAPRED_HOME, HADOOP_YARN_HOME</span><br></pre></td></tr></table></figure><blockquote><p>检查Hadoop环境是否配置正确</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export HADOOP_HOME=/usr/local/hadoop-2.7.7</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin;</span><br></pre></td></tr></table></figure><p><span style="color:red"><code>注意</code></span>：配置这个变量主要是让Sqoop能找到以下目录的jar文件和Hadoop配置文件：</p><ul><li>$HADOOP_HOME/share/hadoop/common</li><li>$HADOOP_HOME/share/hadoop/hdfs</li><li>$HADOOP_HOME/share/hadoop/mapreduce</li><li>$HADOOP_HOME/share/hadoop/yarn</li></ul><p><span style="color:red"><br>官网上说名了可以单独对各个组建进行配置，使用以下变量：<br>$HADOOP_COMMON_HOME, $HADOOP_HDFS_HOME,  $HADOOP_MAPRED_HOME, $HADOOP_YARN_HOME<br>若$HADOOP_HOME已经配置了，最好不要再配置下面的变量，可能会有些莫名错误。<br></span></p><h4 id="查看是否启动成功方式有三种"><a href="#查看是否启动成功方式有三种" class="headerlink" title="查看是否启动成功方式有三种"></a>查看是否启动成功方式有三种</h4><ul><li><p>第一种查看日志</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# sqoop2-server start</span><br><span class="line">Setting conf dir: /usr/local/sqoop/bin/../conf</span><br><span class="line">Sqoop home directory: /usr/local/sqoop</span><br><span class="line">Starting the Sqoop2 server...</span><br><span class="line">0    [main] INFO  org.apache.sqoop.core.SqoopServer  - Initializing Sqoop server.</span><br><span class="line">5    [main] INFO  org.apache.sqoop.core.PropertiesConfigurationProvider  - Starting config file poller thread</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/usr/local/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">Sqoop2 server started.</span><br></pre></td></tr></table></figure></li><li><p>第二种执行访问 <a href="http://IP地址:12000/sqoop/version" target="_blank" rel="noopener">http://IP地址:12000/sqoop/version</a></p></li><li>第三种执行JPS命令查看进程：Bootstrap、SqoopJettyServer<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# jps</span><br><span class="line">22402 RunJar</span><br><span class="line">5861 Jps</span><br><span class="line">11848 NamesrvStartup</span><br><span class="line">2936 DataNode</span><br><span class="line">3513 jenkins.war</span><br><span class="line">5561 SqoopJettyServer</span><br><span class="line">2060 NameNode</span><br><span class="line">22317 RunJar</span><br><span class="line">12285 JswLauncher</span><br><span class="line">12686 NodeManager</span><br><span class="line">12399 ResourceManager</span><br><span class="line">5135 Bootstrap</span><br></pre></td></tr></table></figure></li></ul><h3 id="启动客户端-SQOOP2-HOME-bin-sqoop2-shell"><a href="#启动客户端-SQOOP2-HOME-bin-sqoop2-shell" class="headerlink" title="启动客户端 $SQOOP2_HOME/bin/sqoop2-shell"></a>启动客户端 $SQOOP2_HOME/bin/sqoop2-shell</h3><blockquote><p>再次尝试 show job、show connector 没有报错 这说明安装部署成功</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop:000&gt; show connector</span><br><span class="line">0    [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">+------------------------+---------+------------------------------------------------------------+----------------------+</span><br><span class="line">|          Name          | Version |                           Class                            | Supported Directions |</span><br><span class="line">+------------------------+---------+------------------------------------------------------------+----------------------+</span><br><span class="line">| generic-jdbc-connector | 1.99.7  | org.apache.sqoop.connector.jdbc.GenericJdbcConnector       | FROM/TO              |</span><br><span class="line">| kite-connector         | 1.99.7  | org.apache.sqoop.connector.kite.KiteConnector              | FROM/TO              |</span><br><span class="line">| oracle-jdbc-connector  | 1.99.7  | org.apache.sqoop.connector.jdbc.oracle.OracleJdbcConnector | FROM/TO              |</span><br><span class="line">| ftp-connector          | 1.99.7  | org.apache.sqoop.connector.ftp.FtpConnector                | TO                   |</span><br><span class="line">| hdfs-connector         | 1.99.7  | org.apache.sqoop.connector.hdfs.HdfsConnector              | FROM/TO              |</span><br><span class="line">| kafka-connector        | 1.99.7  | org.apache.sqoop.connector.kafka.KafkaConnector            | TO                   |</span><br><span class="line">| sftp-connector         | 1.99.7  | org.apache.sqoop.connector.sftp.SftpConnector              | TO                   |</span><br><span class="line">+------------------------+---------+------------------------------------------------------------+----------------------+</span><br><span class="line">sqoop:000&gt; show job</span><br><span class="line">+----+------+----------------+--------------+---------+</span><br><span class="line">| Id | Name | From Connector | To Connector | Enabled |</span><br><span class="line">+----+------+----------------+--------------+---------+</span><br><span class="line">+----+------+----------------+--------------+---------+</span><br></pre></td></tr></table></figure><h3 id="尝试后"><a href="#尝试后" class="headerlink" title="尝试后"></a>尝试后</h3><blockquote><p>我想要的功能是将hive数据移入mysql，经对sqoop2的使用发现，sqoop2并不支持。遗憾。接下来将尝试sqoop1。</p></blockquote><h3 id="区别在于"><a href="#区别在于" class="headerlink" title="区别在于"></a>区别在于</h3><table><thead><tr><th>功能</th><th>Sqoop 1</th><th>Sqoop 2</th></tr></thead><tbody><tr><td>用于所有主要 RDBMS 的连接器</td><td>支持</td><td>不支持  解决办法： 使用已在以下数据库上执行测试的通用 JDBC 连接器： Microsoft SQL Server 、 PostgreSQL 、 MySQL 和 Oracle 。 此连接器应在任何其它符合 JDBC 要求的数据库上运行。但是，性能可能无法与 Sqoop 中的专用连接器相比</td></tr><tr><td>Kerberos 安全集成</td><td>支持</td><td>不支持</td></tr><tr><td>数据从 RDBMS 传输至 Hive 或 HBase</td><td>支持</td><td>不支持 解决办法： 按照此两步方法操作。 将数据从 RDBMS 导入 HDFS 在 Hive 中使用相应的工具和命令（例如 LOAD DATA 语句），手动将数据载入 Hive 或 HBase</td></tr><tr><td>数据从 Hive 或 HBase 传输至 RDBMS</td><td>不支持 解决办法： 按照此两步方法操作。 从 Hive 或 HBase 将数据提取至 HDFS （作为文本或 Avro 文件） 使用 Sqoop 将上一步的输出导出至 RDBMS</td><td>不支持 按照与 Sqoop 1 相同的解决方法操作</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数
      
    
    </summary>
    
      <category term="大数据" scheme="http://www.updatecg.xin/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Sqoop" scheme="http://www.updatecg.xin/tags/Sqoop/"/>
    
      <category term="Hive" scheme="http://www.updatecg.xin/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>性能调优参数</title>
    <link href="http://www.updatecg.xin/2019/01/24/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0/"/>
    <id>http://www.updatecg.xin/2019/01/24/性能调优参数/</id>
    <published>2019-01-24T01:00:00.000Z</published>
    <updated>2020-05-28T04:03:09.590Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>堆内存性能、垃圾回收性能</p></blockquote><h1 id="堆内存性能优化参数"><a href="#堆内存性能优化参数" class="headerlink" title="堆内存性能优化参数"></a>堆内存性能优化参数</h1><table><thead><tr><th>参数</th><th style="text-align:right">含义</th><th style="text-align:center">案例</th></tr></thead><tbody><tr><td>-Xmx</td><td style="text-align:right">设置JVM 最大堆内存</td><td style="text-align:center">-Xmx3550m</td></tr><tr><td>-Xms</td><td style="text-align:right">设置JVM 初始堆内存,此值可以设置与-Xmx相同,以避免每次垃圾回收完成后JVM重新分配内存</td><td style="text-align:center">-Xms3550m</td></tr><tr><td>-Xss</td><td style="text-align:right">设置每个线程的栈大小.JDK5.0以后每个线程栈大小为1M，之前每个线程栈大小为256K应当根据应用的线程所需内存大小进行调整在相同物理内存下。减小这个值能生成更多的线程但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右需要注意的是：当这个值被设置的较大（例如&gt; 2MB）时将会在很大程度上降低系统的性能</td><td style="text-align:center">-Xss128k</td></tr><tr><td>-Xmn</td><td style="text-align:right">设置年轻代。大小为2G在整个堆内存大小确定的情况下，增大年轻代将会减小年老代，反之亦然此值关系到JVM垃圾回收，对系统性能影响较大，官方推荐配置为整个堆大小的3/8</td><td style="text-align:center">-Xmn2g</td></tr><tr><td>-XX</td><td style="text-align:right">设置年轻代初始值为1024M</td><td style="text-align:center">-XX</td></tr><tr><td>-XX：MaxNewSize</td><td style="text-align:right">设置年轻代最大值</td><td style="text-align:center">-XX：MaxNewSize = 1024</td></tr><tr><td>-XX：PermSize</td><td style="text-align:right">设置持久代初始值</td><td style="text-align:center">-XX：PermSize = 256</td></tr><tr><td>-XX：MaxPermSize</td><td style="text-align:right">设置持久代最大值</td><td style="text-align:center">-XX：MaxPermSize = 256</td></tr><tr><td>-XX：NewRatio</td><td style="text-align:right">设置年轻代（包括1个伊甸和2个幸存者区）与年老代的比值</td><td style="text-align:center">-XX：NewRatio = 4(表示1:4)</td></tr><tr><td>-XX：SurvivorRatio</td><td style="text-align:right">设置年轻代中伊甸区与幸存者区的比值。表示2个幸存者区（JVM堆内存年轻代中默认有2个大小相等的幸存者区）与1个伊甸区的比值为2:4，即1个幸存者区占整个年轻代大小的1/6</td><td style="text-align:center">-XX：SurvivorRatio = 4</td></tr><tr><td>-XX：MaxTenuringThreshold</td><td style="text-align:right">表示一个对象如果在幸存者区（救助空间）移动了7次还没有被垃圾回收就进入年老代如果设置为0的话，则年轻代对象不经过幸存者区，直接进入年老代，对于需要大量常驻内存的应用，这样做可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在幸存者区进行多次复制，这样可以增加对象在年轻代存活时间，增加对象在年轻代被垃圾回收的概率，减少Full GC的频率，这样做可以在某种程度上提高服务稳定性。</td><td style="text-align:center">-XX：MaxTenuringThreshold = 7</td></tr></tbody></table><h1 id="垃圾回收性能优化参数"><a href="#垃圾回收性能优化参数" class="headerlink" title="垃圾回收性能优化参数"></a>垃圾回收性能优化参数</h1><table><thead><tr><th>参数</th><th style="text-align:right">含义</th><th style="text-align:center">案例</th></tr></thead><tbody><tr><td>-XX：+ UseSerialGC</td><td style="text-align:right">设置串行收集器</td><td style="text-align:center">-XX：+ UseSerialGC</td></tr><tr><td>-XX：+ UseParallelGC</td><td style="text-align:right">置为并行收集器此配置仅对年轻代有效即年轻代使用并行收集，而年老代仍使用串行收集。</td><td style="text-align:center">-XX：+ UseParallelGC</td></tr><tr><td>-XX：ParallelGCThreads</td><td style="text-align:right">配置并行收集器的线程数，即：同时有多少个线程一起进行垃圾回收此值建议配置与CPU数目相等。</td><td style="text-align:center">-XX：ParallelGCThreads = 20</td></tr><tr><td>-XX：+ UseParallelOldGC</td><td style="text-align:right">配置年老代垃圾收集方式为并行收集.JDK6.0开始支持对年老代并行收集。</td><td style="text-align:center">-XX：+ UseParallelOldGC</td></tr><tr><td>-XX：MaxGCPauseMillis</td><td style="text-align:right">设置每次年轻代代垃圾回收的最长时间（单位毫秒）如果无法满足此时间，JVM会自动调整年轻代大小，以满足此时间。</td><td style="text-align:center">-XX：MaxGCPauseMillis = 100</td></tr><tr><td>-XX：+ UseAdaptiveSizePolicy</td><td style="text-align:right">设置此选项后，并行收集器会自动调整年轻代伊甸区大小和幸存者区大小的比例，以达成目标系统规定的最低响应时间或者收集频率等指标此参数建议在使用并行收集器时，一直打开。</td><td style="text-align:center">-XX：+ UseAdaptiveSizePolicy</td></tr><tr><td>-XX：+ UseConcMarkSweepGC</td><td style="text-align:right">即CMS收集，设置年老代为并发收集的.cms收集是JDK1.4后期版本开始引入的新GC算法它的主要适合场景是对响应时间的重要性需求大于对吞吐量的需求，能够承受垃圾回收线程和应用线程共享CPU资源，并且应用中存在比较多的长生命周期对象的的的.cms收集的目标是尽量减少应用的暂停时间，减少全GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存。</td><td style="text-align:center">-XX：+ UseConcMarkSweepGC</td></tr><tr><td>-XX：+ UseParNewGC</td><td style="text-align:right">设置年轻代为并发收集可与CMS收集同时使用.JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此参数。</td><td style="text-align:center">-XX：+ UseSerialGC</td></tr><tr><td>-XX：CMSFullGCsBeforeCompaction</td><td style="text-align:right">由于并发收集器不对内存空间进行压缩和整理，所以运行一段时间并行收集以后会产生内存碎片，内存使用效率降低。此参数设置运行0次Full GC后对内存空间进行压缩和整理，即每次Full GC后立刻开始压缩和整理内存。</td><td style="text-align:center">-XX：CMSFullGCsBeforeCompaction = 0</td></tr><tr><td>-XX：+ UseCMSCompactAtFullCollection</td><td style="text-align:right">打开内存空间的压缩和整理，在Full GC后执行。可能会影响性能，但可以消除内存碎片。</td><td style="text-align:center">-XX：+ UseCMSCompactAtFullCollection</td></tr><tr><td>-XX：+ CMSIncrementalMode</td><td style="text-align:right">设置为增量收集模式一般适用于单CPU情况。</td><td style="text-align:center">-XX：+ CMSIncrementalMode</td></tr><tr><td>-XX：CMSInitiatingOccupancyFraction</td><td style="text-align:right">表示年老代内存空间使用到70％时就开始执行CMS收集，以确保年老代有足够的空间接纳来自年代代的对象，避免Full GC的发生。</td><td style="text-align:center">-XX：CMSInitiatingOccupancyFraction = 70</td></tr></tbody></table><h1 id="JVM服务参数调优实战"><a href="#JVM服务参数调优实战" class="headerlink" title="JVM服务参数调优实战"></a>JVM服务参数调优实战</h1><p>服务器配置：8 CPU，8G MEM，JDK 1.6.X<br>参数方案：-server -Xmx3550m -Xms3550m -Xmn1256m -Xss128k -XX：SurvivorRatio = 6 -XX：MaxPermSize = 256m -XX：ParallelGCThreads = 8 -XX：MaxTenuringThreshold = 0 -XX：+ UseConcMarkSweepGC<br>调优说明：</p><ul><li>-Xmx与-Xms相同以避免JVM反复重新申请内存。-XMX的大小约等于系统内存大小的一半，即充分利用系统资源，又给予系统安全运行的空间。</li><li>-Xmn1256m设置年轻代大小为1256MB。此值对系统性能影响较大，太阳官方推荐配置年轻代大小为整个堆的3/8。</li><li>-Xss128k设置较小的线程栈以支持创建更多的线程，支持海量访问，并提升系统性能。</li><li>-XX：SurvivorRatio = 6设置年轻代中Eden区与Survivor区的比值。系统默认是8，根据经验设置为6，则2个幸存者区与1个Eden区的比值为2：6，一个幸存者区占整个年轻代的1/8。</li><li>-XX：ParallelGCThreads = 8配置并行收集器的线程数，即同时8个线程一起进行垃圾回收。此值一般配置为与CPU数目相等。</li><li>-XX：MaxTenuringThreshold = 0设置垃圾最大年龄（在年轻代的存活次数）。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，可以提高效率;如果将此值设置为一个较大值，则年轻代对象会在幸存者区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概率根据被海量访问的动态网络应用之特点，其内存要么被缓存起来以减少直接访问数据库，要么被快速回收以支持高并发海量请求，因此其内存对象在年轻代存活多次意义不大，可以直接进入年老代，根据实际应用效果，在这里设置此值为0。</li><li>-XX：+ UseConcMarkSweepGC设置年老代为并发收集.CMS（ConcMarkSweepGC）收集的目标是尽量减少应用的暂停时间，减少完全GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存，适用于应用中存在比较多的长生命周期对象的情况。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;堆内存性能、垃圾回收性能&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;堆内存性能优化参数&quot;&gt;&lt;a href=&quot;#堆内存性能优化参数&quot; class=&quot;headerlink&quot; title=&quot;堆内存性能优化参数&quot;&gt;&lt;/a&gt;堆内存性能优化参数&lt;/h
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
  </entry>
  
  <entry>
    <title>微信支付宝支付经验以及相关坑</title>
    <link href="http://www.updatecg.xin/2018/11/29/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98%E5%AE%9D%E6%94%AF%E4%BB%98%E7%BB%8F%E9%AA%8C%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%9D%91/"/>
    <id>http://www.updatecg.xin/2018/11/29/微信支付宝支付经验以及相关坑/</id>
    <published>2018-11-29T06:00:02.000Z</published>
    <updated>2020-05-28T04:03:10.560Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>此片文章介绍对接微信、支付宝所遇到的问题以及经验之谈。</p></blockquote><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><table><thead><tr><th>支付类型</th><th>文档</th><th>对接难易程度</th><th>文档地址</th></tr></thead><tbody><tr><td>支付宝</td><td>文档写的不错</td><td>易</td><td><a href="https://docs.open.alipay.com/api_1/alipay.trade.fastpay.refund.query" target="_blank" rel="noopener">https://docs.open.alipay.com/api_1/alipay.trade.fastpay.refund.query</a></td></tr><tr><td>微信</td><td>不想说了</td><td>难（也不能说难应该是坑）</td><td><a href="https://pay.weixin.qq.com/wiki/doc/api/app/app.php?chapter=8_1" target="_blank" rel="noopener">https://pay.weixin.qq.com/wiki/doc/api/app/app.php?chapter=8_1</a></td></tr></tbody></table><h3 id="熟悉支付流程"><a href="#熟悉支付流程" class="headerlink" title="熟悉支付流程"></a>熟悉支付流程</h3><h4 id="支付宝"><a href="#支付宝" class="headerlink" title="支付宝"></a>支付宝</h4><p><img data-src="/img/ali.jpg" class="lozad"><br><a href="https://docs.open.alipay.com/20160728150111277227/intro" target="_blank" rel="noopener">[详情文档请参考]</a></p><h4 id="微信"><a href="#微信" class="headerlink" title="微信"></a>微信</h4><p><img data-src="/img/wx.png" class="lozad"><br><a href="https://pay.weixin.qq.com/wiki/doc/api/app/app.php?chapter=8_3" target="_blank" rel="noopener">[详情文档请参考]</a></p><h2 id="有萝卜有坑"><a href="#有萝卜有坑" class="headerlink" title="有萝卜有坑"></a>有萝卜有坑</h2><table><thead><tr><th>序号</th><th>类型</th><th>问题描述</th></tr></thead><tbody><tr><td>No1</td><td>支付宝</td><td>支付宝秘钥使用pkcs8加密方式，以及相关参数key配置。</td></tr><tr><td>No2</td><td>微信</td><td>微信key值一定要使用微信支付的key，不要用平台key。</td></tr><tr><td>No3</td><td>微信</td><td>一直报签名错误，下面详细介绍。</td></tr><tr><td>No4</td><td>微信</td><td>得到的签名一定要转MD5，然后在将其转换成大写，并且生成MD5必须要以UTF-8的方式。</td></tr><tr><td>No5</td><td>微信</td><td>订单金额需要转换成以分为单位。</td></tr><tr><td>No6</td><td>微信</td><td>且值为空的参数不参与签名。</td></tr><tr><td>No7</td><td>微信</td><td>参数需按ASCII码从小到大排序。</td></tr><tr><td>No8</td><td>微信</td><td>第二次签名认证参数已消息的格式。</td></tr><tr><td>No9</td><td>微信</td><td>第二次签名参数package，需要赋值Sign=WXPay</td></tr></tbody></table><h2 id="一句签名错误概括全部错误信息，我就弱弱的问句错误码有用么？"><a href="#一句签名错误概括全部错误信息，我就弱弱的问句错误码有用么？" class="headerlink" title="一句签名错误概括全部错误信息，我就弱弱的问句错误码有用么？"></a>一句签名错误概括全部错误信息，我就弱弱的问句错误码有用么？</h2><p>“验证签名错误”第一反应肯定是检测签名是否正确，<a href="https://pay.weixin.qq.com/wiki/doc/api/app/app.php?chapter=20_1" target="_blank" rel="noopener">[官方验证签名地址]</a>。<br>然而，这才刚刚开始，签名正确了还是特么的报“验证签名错误”。特么的把以上几点全部检测了“有萝卜有坑”，然并卵。上面说了<span style="color:red">签名验证有两次，这是第二次验证错误</span>,最后发现<span style="color:red">【传入微信端的时间戳参数 ios需要32位 安卓需要10位】</span>，笑哭。首先看见“验证签名错误”，肯定是服务端问题，然而呢。。。</p><h2 id="签名两次重要参数"><a href="#签名两次重要参数" class="headerlink" title="签名两次重要参数"></a>签名两次重要参数</h2><h3 id="第一次签名参数"><a href="#第一次签名参数" class="headerlink" title="第一次签名参数"></a>第一次签名参数</h3><p>得到sign并赋值pay.setSign(sign) ；接下来就是将pay对象转换成xml，调用统一下单接口进行统一支付，并将统一支付返回的xml转换成bean。<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">notify_url //回调地址</span><br><span class="line">time_start //交易起始时间</span><br><span class="line">time_expire //交易结束时间</span><br><span class="line">spbill_create_ip //IP地址</span><br><span class="line">trade_type //交易类型</span><br><span class="line">limit_pay //no_credit--指定不能使用信用卡支付</span><br><span class="line">appid //微信开放平台审核通过的应用APPID</span><br><span class="line">mch_id //微信支付分配的商户号</span><br><span class="line">nonce_str //随机字符串，不长于32位。</span><br><span class="line">sign_type //签名类型，目前支持HMAC-SHA256和MD5，默认为MD5</span><br><span class="line">body //商品描述交易字段格式根据不同的应用场景按照以下格式：APP——需传入应用市场上的APP名字-实际商品名称，天天爱消除-游戏充值。</span><br><span class="line">out_trade_no //订单号</span><br><span class="line">total_fee //交易金额默认为人民币交易，接口中参数支付金额单位为【分】，参数值不能带小数。</span><br><span class="line">sign //根据以上数据生成签名</span><br></pre></td></tr></table></figure></p><h3 id="第二次签名参数"><a href="#第二次签名参数" class="headerlink" title="第二次签名参数"></a>第二次签名参数</h3><p>统一下单成功会返回微信预支付订单号prepay_id，我们需要根据这个prepay_id进行二次签名，二次签名所用参数如下（不包括paySign）。<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">noncestr //随机字符串</span><br><span class="line">appid //微信开放平台审核通过的应用APPID</span><br><span class="line">timestamp //就是这B,传入微信端的时间戳参数 ios需要32位 安卓需要10位</span><br><span class="line">partnerid //商户号</span><br><span class="line">package //Sign=WXPay</span><br><span class="line">prepayid //微信预支付订单号prepay_id</span><br><span class="line">sign //根据以上数据生成签名</span><br></pre></td></tr></table></figure></p><h3 id="实例代码后续上传GitHub"><a href="#实例代码后续上传GitHub" class="headerlink" title="实例代码后续上传GitHub"></a>实例代码后续上传GitHub</h3><p>第三方文档能不能写专业第一，之前和中兴、华为对接一样，特么的文档写的一塌糊涂。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;此片文章介绍对接微信、支付宝所遇到的问题以及经验之谈。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h2&gt;&lt;ta
      
    
    </summary>
    
      <category term="工作" scheme="http://www.updatecg.xin/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
      <category term="支付" scheme="http://www.updatecg.xin/tags/%E6%94%AF%E4%BB%98/"/>
    
  </entry>
  
  <entry>
    <title>SpringCloud服务多实例注入Consul挂掉问题</title>
    <link href="http://www.updatecg.xin/2018/09/07/SpringCloud%E6%9C%8D%E5%8A%A1%E5%A4%9A%E5%AE%9E%E4%BE%8B%E6%B3%A8%E5%85%A5Consul%E6%8C%82%E6%8E%89%E9%97%AE%E9%A2%98/"/>
    <id>http://www.updatecg.xin/2018/09/07/SpringCloud服务多实例注入Consul挂掉问题/</id>
    <published>2018-09-07T05:25:02.000Z</published>
    <updated>2020-05-28T04:03:11.208Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>相信大家在使用SpringCloud服务的发现与注册，都会对Eureka、Zookeeper、Consul熟悉吧。18年7月份爆出了Eureka2.0不在对外开源的消息。相信会有一部分程序猿逐渐往Consul发展。这其中也包含小生我。</p></blockquote><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>SpringCloud+1.2.x时候最严重的一个问题，就是多实例注册的问题.</p><h2 id="原因概述"><a href="#原因概述" class="headerlink" title="原因概述"></a>原因概述</h2><p>主要原因是SpringCloud中Consul在注册的时候实例名采用了：服务名-端口号{spring.application.name}-{server.port}）的值，可以看到这个实例名如果不改变端口号的情况下，实例名都是相同的。由于Consul对实例唯一性的判断标准也有改变，在老版本的Consul中，对于实例名相同，但是服务地址不同，依然会认为是不同的实例。在Consul 1.2.x中，服务实例名成为了集群中的唯一标识。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>通过配置 spring.cloud.consul.discovery.instance-id 参数来实例命令规则。利用随机数来控制实例名。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spring.cloud.consul.discovery.instance-id=$&#123;spring.application.name&#125;-$&#123;random.int[10000,99999]&#125;</span><br></pre></td></tr></table></figure></p><h2 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h2><p><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/consulpic.png" class="lozad"></p><p><span style="color:red;font-size:16px">! ! ! 效果图中的错误不必关注，那是因为外网问题</span></p><h2 id="SpringCloud注入与注册类别简单介绍"><a href="#SpringCloud注入与注册类别简单介绍" class="headerlink" title="SpringCloud注入与注册类别简单介绍"></a>SpringCloud注入与注册类别简单介绍</h2><table><thead><tr><th>Feature</th><th>Consul</th><th>zookeeper</th><th>euerka</th></tr></thead><tbody><tr><td>服务健康检查</td><td>服务状态，内存，硬盘等</td><td>(弱)长连接，keepalive</td><td>可配支持</td></tr><tr><td>多数据中心</td><td>支持</td><td>—</td><td>—</td></tr><tr><td>kv存储服务</td><td>支持</td><td>支持</td><td>—</td></tr><tr><td>一致性</td><td>raft</td><td>paxos</td><td>—</td></tr><tr><td>cap</td><td>ca</td><td>cp</td><td>ap</td></tr><tr><td>使用接口(多语言能力)</td><td>支持http和dns</td><td>客户端</td><td>http（sidecar）</td></tr><tr><td>watch支持</td><td>全量/支持long polling</td><td>支持</td><td>支持 long polling/大部分增量</td></tr><tr><td>自身监控</td><td>metrics</td><td>—</td><td>metrics</td></tr><tr><td>安全</td><td>acl /https</td><td>acl</td><td>—</td></tr><tr><td>spring cloud集成</td><td>已支持</td><td>已支持</td><td>已支持</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;相信大家在使用SpringCloud服务的发现与注册，都会对Eureka、Zookeeper、Consul熟悉吧。18年7月份爆出了Eureka2.0不在对外开源的消息。相信会有一部分程序猿逐渐往Consul发展。这其中也包含小生我。&lt;/p&gt;
&lt;/
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="SpringCloud" scheme="http://www.updatecg.xin/tags/SpringCloud/"/>
    
      <category term="Consul" scheme="http://www.updatecg.xin/tags/Consul/"/>
    
  </entry>
  
  <entry>
    <title>腾讯云IM支持JAVA Server</title>
    <link href="http://www.updatecg.xin/2018/07/13/%E8%85%BE%E8%AE%AF%E4%BA%91IM%E6%94%AF%E6%8C%81JAVA%20Server/"/>
    <id>http://www.updatecg.xin/2018/07/13/腾讯云IM支持JAVA Server/</id>
    <published>2018-07-13T03:27:02.000Z</published>
    <updated>2020-05-28T04:03:09.972Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>因阿里云IM服务不稳定，网易云太贵，现切换至腾讯云。</p></blockquote><h1 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h1><p>根据腾讯云官方文档利用Java编写Server，因腾讯云现不支持Java。<br>官方在后台服务中调用 REST API，本质上是发起 HTTPS POST 请求。云通信提供了 Server SDK 来封装对 REST API 的调用，开发者可以将其直接集成到您的服务端代码中。</p><ul><li>PHP Server SDK；</li><li>Node.js Server SDK；</li><li>Java Server SDK <del>敬请期待</del> (完善中)；</li><li>Golang Server SDK（敬请期待）。</li></ul><h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><p>现阶段完成内容如下：</p><ul><li>缓存identifier usersig 存入Redis。</li></ul><h2 id="账号管理"><a href="#账号管理" class="headerlink" title="账号管理"></a>账号管理</h2><ul><li>独立模式账号导入</li><li>独立模式账户批量导入</li><li>单发单聊消息</li></ul><h2 id="推送"><a href="#推送" class="headerlink" title="推送"></a>推送</h2><ul><li>获取推送报告</li><li>设置应用属性名称</li><li>获取应用属性名称</li><li>获取用户属性</li><li>设置用户属性</li></ul><h2 id="群组功能"><a href="#群组功能" class="headerlink" title="群组功能"></a>群组功能</h2><ul><li>获取APP中的所有群组</li><li>创建群组</li><li>获取群组详细资料</li><li>增加群组成员</li><li>删除群组成员</li><li>解散群组</li></ul><h2 id="持续更新…"><a href="#持续更新…" class="headerlink" title="持续更新…"></a>持续更新…</h2><h1 id="代码地址"><a href="#代码地址" class="headerlink" title="代码地址"></a>代码地址</h1><p>GitHub：<a href="https://github.com/UpdateCw/IMActionJar" target="_blank" rel="noopener">[https://github.com/UpdateCw/IMActionJar]</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;因阿里云IM服务不稳定，网易云太贵，现切换至腾讯云。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;起因&quot;&gt;&lt;a href=&quot;#起因&quot; class=&quot;headerlink&quot; title=&quot;起因&quot;&gt;&lt;/a&gt;起因&lt;/h1&gt;&lt;p&gt;根据腾讯云官方文档
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="IM" scheme="http://www.updatecg.xin/tags/IM/"/>
    
  </entry>
  
  <entry>
    <title>一台电脑利用秘钥绑定多个ssh-key账号</title>
    <link href="http://www.updatecg.xin/2018/07/02/%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E5%88%A9%E7%94%A8%E7%A7%98%E9%92%A5%E7%BB%91%E5%AE%9A%E5%A4%9A%E4%B8%AAssh-key%E8%B4%A6%E5%8F%B7/"/>
    <id>http://www.updatecg.xin/2018/07/02/一台电脑利用秘钥绑定多个ssh-key账号/</id>
    <published>2018-07-02T06:07:02.000Z</published>
    <updated>2020-05-28T04:03:09.574Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>因新环境利用内部邮箱创建git账账号管理项目，自己玩时有一个git账号。公司绑定gitLab，自己绑定了git.coding.net以及gitHub.com。从而两则在提交代码时发生了权限问题以及冲突。</p></blockquote><p>本文在windows环境下配置Git多账号支持SSH-KEY。配置github.com、git.coding.net 、gitLab的SSH-KEY.</p><p><span style="color:red">注意：因本已配置SSH-KEY，在此就不测试。发截图即可。</span></p><h1 id="生成gitHub-com以及gitLab对应的私钥公钥（目录一般存在于C-Users-ssh）"><a href="#生成gitHub-com以及gitLab对应的私钥公钥（目录一般存在于C-Users-ssh）" class="headerlink" title="生成gitHub.com以及gitLab对应的私钥公钥（目录一般存在于C:\Users.ssh）"></a>生成gitHub.com以及gitLab对应的私钥公钥（目录一般存在于C:\Users.ssh）</h1><h2 id="执行命令-ssh-keygen-t-rsa-C-email-创建github对应的sshkey，命名为id-rsa-github"><a href="#执行命令-ssh-keygen-t-rsa-C-email-创建github对应的sshkey，命名为id-rsa-github" class="headerlink" title="执行命令 ssh-keygen -t rsa -C email 创建github对应的sshkey，命名为id_rsa_github"></a>执行命令 ssh-keygen -t rsa -C email 创建github对应的sshkey，命名为id_rsa_github</h2><p><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/rsa_gitHub.png" class="lozad"></p><h2 id="gitHub-com与coding所用秘钥相同，id-rsa-pub属于gitLab，id-rsa-github属于gitHub，coding"><a href="#gitHub-com与coding所用秘钥相同，id-rsa-pub属于gitLab，id-rsa-github属于gitHub，coding" class="headerlink" title="gitHub.com与coding所用秘钥相同，id_rsa.pub属于gitLab，id_rsa_github属于gitHub，coding"></a>gitHub.com与coding所用秘钥相同，id_rsa.pub属于gitLab，id_rsa_github属于gitHub，coding</h2><p><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/ssh.png" class="lozad"></p><h1 id="把github对应的公钥和coding对应的公钥上传到服务器"><a href="#把github对应的公钥和coding对应的公钥上传到服务器" class="headerlink" title="把github对应的公钥和coding对应的公钥上传到服务器"></a>把github对应的公钥和coding对应的公钥上传到服务器</h1><h2 id="分别在gitHub、coding、以及gitLab配置SSH-KEYS"><a href="#分别在gitHub、coding、以及gitLab配置SSH-KEYS" class="headerlink" title="分别在gitHub、coding、以及gitLab配置SSH-KEYS"></a>分别在gitHub、coding、以及gitLab配置SSH-KEYS</h2><p>在此举例gitHub如下:<br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/gitHub_key5.png" class="lozad"></p><h1 id="在-ssh目录创建config文本文件并完成相关配置-最核心的地方"><a href="#在-ssh目录创建config文本文件并完成相关配置-最核心的地方" class="headerlink" title="在.ssh目录创建config文本文件并完成相关配置(最核心的地方)"></a>在.ssh目录创建config文本文件并完成相关配置(最核心的地方)</h1><p>每个账号单独配置一个Host，每个Host要取一个别名，每个Host主要配置HostName和IdentityFile、User属性即可</p><table><thead><tr><th>参数名</th><th>描述</th></tr></thead><tbody><tr><td>Host</td><td>设想名称</td></tr><tr><td>HostName</td><td>这个是真实的域名地址</td></tr><tr><td>IdentityFile</td><td>这里是id_rsa的地址</td></tr><tr><td>PreferredAuthentications</td><td>配置登录时用什么权限认证–可设为publickey,password publickey,keyboard-interactive等</td></tr><tr><td>User</td><td>配置使用用户名</td></tr></tbody></table><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"># gitLab                                                                       </span><br><span class="line">Host chenwu@meillie.com</span><br><span class="line">HostName chenwu@meillie.com</span><br><span class="line">User chenwu</span><br><span class="line">IdentityFile ~/.ssh/id_rsa</span><br><span class="line">PreferredAuthentications publickey</span><br><span class="line"></span><br><span class="line"># 配置github.com</span><br><span class="line">Host github.com                 </span><br><span class="line">HostName github.com</span><br><span class="line">IdentityFile ~/.ssh/id_ras_gitHub</span><br><span class="line">PreferredAuthentications publickey</span><br><span class="line">User UpdateCw</span><br><span class="line"></span><br><span class="line"># 配置coding.net</span><br><span class="line">Host git.coding.net</span><br><span class="line">HostName git.coding.net</span><br><span class="line">IdentityFile ~/.ssh/id_ras_gitHub</span><br><span class="line">PreferredAuthentications publickey</span><br><span class="line">User UpdateMe</span><br></pre></td></tr></table></figure><h1 id="打开Git-Bash客户端（管理员身份运行）执行测试命令测试是否配置成功（会自动在-ssh目录生成known-hosts文件把私钥配置进去）"><a href="#打开Git-Bash客户端（管理员身份运行）执行测试命令测试是否配置成功（会自动在-ssh目录生成known-hosts文件把私钥配置进去）" class="headerlink" title="打开Git Bash客户端（管理员身份运行）执行测试命令测试是否配置成功（会自动在.ssh目录生成known_hosts文件把私钥配置进去）"></a>打开Git Bash客户端（管理员身份运行）执行测试命令测试是否配置成功（会自动在.ssh目录生成known_hosts文件把私钥配置进去）</h1><p><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/test_ssh.png" class="lozad"></p><h1 id="学习心得"><a href="#学习心得" class="headerlink" title="学习心得"></a>学习心得</h1><p>实践才是检验真理的源头</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;因新环境利用内部邮箱创建git账账号管理项目，自己玩时有一个git账号。公司绑定gitLab，自己绑定了git.coding.net以及gitHub.com。从而两则在提交代码时发生了权限问题以及冲突。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="Git" scheme="http://www.updatecg.xin/tags/Git/"/>
    
  </entry>
  
</feed>
