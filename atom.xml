<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>我的学习记录</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.updatecg.xin/"/>
  <updated>2021-12-10T06:37:16.597Z</updated>
  <id>http://www.updatecg.xin/</id>
  
  <author>
    <name>陈 武</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>虚拟币-ETH(Ethereum)</title>
    <link href="http://www.updatecg.xin/2021/09/01/%E8%99%9A%E6%8B%9F%E5%B8%81-ETH/"/>
    <id>http://www.updatecg.xin/2021/09/01/虚拟币-ETH/</id>
    <published>2021-09-01T07:18:00.000Z</published>
    <updated>2021-12-10T06:37:16.597Z</updated>
    
    <content type="html"><![CDATA[<h1 id="以太坊简介"><a href="#以太坊简介" class="headerlink" title="以太坊简介"></a>以太坊简介</h1><blockquote><p>以太坊是一个为去中心化应用（DApp）而生的全球开源平台。</p><p>官方地址: <a href="https://ethereum.org/zh" target="_blank" rel="noopener">https://ethereum.org/zh</a></p><p>源码地址: <a href="https://github.com/ethereum/" target="_blank" rel="noopener">https://github.com/ethereum/</a></p></blockquote><p>以太坊主网于 2015 年上线，是世界领先的可编程区块链。和其它区块链一样，以太坊也拥有原生加密货币，叫作 Ether (ETH)。 ETH 是一种数字货币， 和比特币有许多相同的功能。</p><h1 id="以太坊历史"><a href="#以太坊历史" class="headerlink" title="以太坊历史"></a>以太坊历史</h1><table><thead><tr><th>年份</th><th>历史名</th><th>区块高度</th><th>价格</th><th>概述</th><th>改进提议EIP</th></tr></thead><tbody><tr><td>2013年11月27日</td><td>白皮书发布</td><td>0</td><td>$0</td><td>该项目在 2015 年启动。但早在 2013 年，以太坊的创始人 VitalikButerin维塔利克·巴特林(V神) 就发表了介绍性<a href="https://ethereum.org/zh/whitepaper/" target="_blank" rel="noopener">[文章]</a>。</td></tr><tr><td>2014年4月1日</td><td>黄皮书发布</td><td>0</td><td>$0</td><td>以太坊白皮书概要性地介绍了以太坊，以太坊黄皮书通过大量的定义和公式详细地描述了以太坊的技术实现的<a href="https://github.com/ethereum/yellowpaper" target="_blank" rel="noopener">[文章]</a>。</td></tr><tr><td>2014年7月22日 - 9月2日</td><td>公开招募</td><td>0</td><td>$0</td><td>以太币预售为期 42 天。 你可以使用比特币进行购买。<a href="https://blog.ethereum.org/2014/07/22/launching-the-ether-sale/" target="_blank" rel="noopener">[请阅读以太坊基金会公告]</a></td></tr><tr><td>2015-7月-30日</td><td>Frontier</td><td>0</td><td>$0</td><td>边境是以太坊的最初版本，但在上面能做的事情很少。 它是在 Olympic 测试阶段之后进行的。 它面向技术用户，特别是开发者。 每个区块有一个 gas 限制为 5,000。 这个“缓冲”期使矿工能够开始工作，并使早期采用者能够安装他们的客户端而不必“匆忙”。</td></tr><tr><td>2015-9月-7日</td><td>Frontier thawing</td><td>200000</td><td>$1.24 USD</td><td>Frontier thawing 分叉取消了每个区块 5,000 gas 的限制，并将默认的 gas 价格设置为 51 gwei。 这开启了交易功能——交易需要 21,000 gas。</td></tr><tr><td>2016-3月-14日</td><td>Homestead</td><td>1150000</td><td>$12.50 USD</td><td>展望未来的 Homestead 分叉。 其中包括若干协议修改和网络变更，使以太坊能够进一步进行网络升级。</td><td>EIP-2\EIP-7\EIP-8 <a href="https://ethereum.org/zh/eips/" target="_blank" rel="noopener">[EIP详情]</a></td></tr><tr><td>2016-7月-20日</td><td>DAO 分叉</td><td>1920000</td><td>$12.54 USD</td><td>DAO 分叉是为了解决 2016 DAO 攻击 ，当时一个不安全 DAO 合约被黑客盗走了超过 3 百万个 ETH。 这个分叉将资金从错误的合约转移到 这个只有 withDraw 方法的新合约。 任何损失资金的人都可以在他们的钱包中为每 100 个 DAO 代币提取 1 个 ETH。</td></tr><tr><td>2016-10月-18日</td><td>Tangerine Whistle</td><td>2463000</td><td>$12.50 USD</td><td>处理与价格低廉的操作代码有关的紧急网络健康问题</td><td>EIP-150\EIP-158</td></tr><tr><td>2016-11月-22日</td><td>Spurious Dragon</td><td>2675000</td><td>$9.84 USD</td><td>1、调整操作码的价格以防止今后对网络的攻击。 2、启用区块链状态的“区块链减重”。 3、添加重放攻击保护。</td><td>EIP-155\EIP-160\EIP-161\EIP-170</td></tr><tr><td>2017-10月-16日</td><td>Byzantium</td><td>4370000</td><td>$334.23 USD</td><td>拜占庭分叉: 1、将区块挖矿奖励从 5 ETH 减少到 3 ETH  2、将<a href="https://ethereum.org/zh/glossary/#difficulty-bomb" target="_blank" rel="noopener">[难度炸弹]</a>升级延迟一年 3、增加了调用其他合约的能力 4、添加加密算法以允许[第二层扩容]</td><td>EIP-140\EIP-658\EIP-196\EIP-197\EIP-198\EIP-211\EIP-214\EIP-100\EIP-649</td></tr><tr><td>2018-2月-28日</td><td>君士坦丁堡升级</td><td>7280000</td><td>$136.29 USD</td><td>君士坦丁堡分叉: 1、保证在 POS 实现前区块不会被冻结 2、优化 EVM 数据存储操作的 Gas 耗用量计量方式 3、添加了与尚未创建的地址进行交互的能力</td><td>EIP-145\EIP-1014\EIP-1052\EIP-1234</td></tr><tr><td>2019-9月-8日</td><td>伊斯坦布尔升级</td><td>9069000</td><td>$151.06 USD</td><td>伊斯坦布尔分叉: 1、优化 EVM 数据存储操作的 gas 耗用量计量方式。 2、提高拒绝服务（DoS）攻击的弹性 3、使基于 SNARK 和 STARK 的 二层扩容第二层方案性能更佳 4、使以太坊和 Zcash 能够互操作 5、让合约能够引入更有创造性的功能</td><td>EIP-152\EIP-1108\EIP-1344\EIP-1884\EIP-2028\EIP-2200</td></tr><tr><td>2020-1月-2日</td><td>缪尔冰川升级</td><td>9200000</td><td>$127.18 USD</td><td>缪尔冰川分叉将 难度炸弹 的启动延迟。 增加Pow 的区块难度可能会增加发送交易和使用数据库的等待时间，从而降低以太坊的可用性。</td><td>EIP-2384</td></tr><tr><td>2020-10月-14日</td><td>质押合约部署</td><td>11052984</td><td>$379.04 USD</td><td><a href="https://ethereum.org/zh/eth2/staking/" target="_blank" rel="noopener">[质押合约]</a>将质押引入以太坊生态系统。 虽然这只是一个 ETH1.0 主网 合约，但它直接影响了启动 信标链重要的 Eth2 升级。</td></tr><tr><td>2020-12月-1日</td><td>信标链的起源</td><td>1 (信标链区块高度)</td><td>$586.23 USD</td><td><a href="https://ethereum.org/zh/eth2/beacon-chain/" target="_blank" rel="noopener">[信标链]</a>需要 16384 个 ETH 并且每个节点拥有 32 个 ETH 来保证网络的安全。 2020 年 11 月 27 日确定规则，并且在 2020 年 12 月 1 日开始生产区块。 这是实现 Eth2.0 愿景的重要一步。</td></tr><tr><td>2021-8月-5日</td><td>伦敦升级</td><td>1296500</td><td>$3292.71 USD</td><td>「伦敦」升级顺利完成，作为以太坊2.0全面部署前的最后一次全网升级，「伦敦」重要性不言而喻，尤其是以太坊改进提案EIP-1559的激活，不仅消除了用户通过投标系统竞争区块包含的方法，更会从根本上改变以太坊交易机制和ETH供应量。</td></tr></tbody></table><p><a href="https://github.com/ethereum/EIPs/tree/master/EIPS" target="_blank" rel="noopener">[EIP详情地址]</a></p><p>总结：2014年实行预售，可以从2016年到2017年价格上涨，然后2020年到2021年价格上涨。每次升级都会影响价格的波动。2020年12月上线的信标链，只是以太坊2.0“阶段 0”迈出的第一步，「伦敦」升级之后将会进入到「阶段 1」（最初预计是2021年完成，但目前几乎可以肯定会延迟到2022年），而 ETH 1.0ETH 2.0 的完整升级则可能需要5-10年。个人觉得可以买币，放个几年。</p><h1 id="以太坊智能合约"><a href="#以太坊智能合约" class="headerlink" title="以太坊智能合约"></a>以太坊智能合约</h1><blockquote><p>以太坊的智能合约并非现实中常见的合同，而是存在区块链上，可以被触发执行的一段程序代码，这些代码实现了某种预定的规则，是存在于以太坊执行环境中的“自治代理”</p></blockquote><h2 id="智能合约是什么"><a href="#智能合约是什么" class="headerlink" title="智能合约是什么"></a>智能合约是什么</h2><p><img alt="智能合约" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210902141601.png" class="lozad"><br>以太坊的智能合约设计很简明。</p><ul><li>任何人都可以在以太坊区块链上开发智能合约，这些智能合约的代码是存在于以太坊的账户中的，这类存有代码的账户叫合约账户。对应地，由密钥控制的账户可称为外部账户。</li><li>以太坊的智能合约程序，是在以太坊虚拟机（Ethereum Virtual Machine,EVM）上运行的。</li><li>合约账户不能自己启动运行自己的智能合约。要运行一个智能合约，需要由外部账户对合约账户发起交易，从而启动其中的代码的执行。</li><li>智能合约的代码永远不能被修改。</li></ul><p>在以太坊，智能合约是可以处理资金的脚本，就是这么简单。</p><p>这些合约由我们称为“矿工”的参与方强制执行和证明。我们给这些矿工支付一种叫作 “Gas” 的东西，它是运行一份合约的成本。当你发布一份智能合约，或者执行一份智能合约，或者把钱转到另一个账户，你就要支付一些被转换成Gas的以太币。</p><h3 id="智能合约有什么用"><a href="#智能合约有什么用" class="headerlink" title="智能合约有什么用"></a>智能合约有什么用</h3><p>图2 是一个简明的图示，图示是一个典型的 ERC20 通证发行过程：一个项目通过智能合约创建通证，这个通证是实体资产或线上资产的价值表示物。投资者（用户）发起交易，向智能合约转入以太币（ETH），智能合约自动运转，在满足一定规则后，它向投资者账户转入相应数量的通证。<br><img alt="智能合约" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210902141936.png" class="lozad"></p><h3 id="为什么我们需要合约？"><a href="#为什么我们需要合约？" class="headerlink" title="为什么我们需要合约？"></a>为什么我们需要合约？</h3><p>在一个没有合约或货币的世界里，我们只能局限于同步的易货交易——你有一个苹果，我有一条面包，我可以当场用面包换你的苹果。 然而，我们交易的越多，就越有可能陷入经济学家所谓的需求的双重偶合（double coincidence of wants）问题：我们之间达成交易的前提必须是我们同时想要对方手里的东西，而这种情况不常出现。</p><p>货币是解决这个问题的一种方法。 我可以卖了面包换到钱，然后用钱换苹果或其他物品。通过钱，我们可以把双重需求减少成单一需求：我无需持有你想交易的东西；我可以通过后续交易获得苹果。这样时间限制就被削弱了。</p><p>合约的工作原理与货币类似，但它们能促进更多潜在的交易。 合约不要求同步交换价值，甚至不需要以货币作为中介。 我现在可以把一条面包卖出去，买方可以答应下个月付款给我。 这种能力从根本上扩展了我们可以进行的交易类型。</p><p>但仍有一个问题。 你怎么确定我会履行承诺付款给你？ 我们如何建立可信的约定？</p><h3 id="履行合约约定"><a href="#履行合约约定" class="headerlink" title="履行合约约定"></a>履行合约约定</h3><p>在点对点交易过程中，无论谁先履行合约都要承担对方违背合约的风险。 如果卖方先发货，买方可能不会付款；如果买方先付款，卖方可能不会发货。 </p><p>怎么来解决这个问题?</p><p>解决方案是使用多重签名的智能合约，在针对在线交易的多重签名合约中，可以要求至少获得三方（买方，卖方和中立的第三方）中任意两方的签名。 第三方可以是任何人（或任何事物！），只要能让我们相信 ta 能公正地解决争议即可。 特别要注意的是，第三方仲裁员的权力非常有限，ta 们只能在买卖双方出现争议的情况下，决定将钱汇给其中一方。 仲裁员不能私吞这笔钱或是将它汇给买卖双方以外的其他人。</p><h3 id="合约的风险"><a href="#合约的风险" class="headerlink" title="合约的风险"></a>合约的风险</h3><h4 id="事件1-Parity钱包"><a href="#事件1-Parity钱包" class="headerlink" title="事件1-Parity钱包"></a>事件1-Parity钱包</h4><p>在2016年6月，一名黑客企图转移一大笔众筹资金 （350 万个 ETH, 占当时ETH总数的15%）至他自己的子合约，这笔资金被锁定在该子合约中 28 天。</p><p>众多创业公司使用的多重签名钱包的逻辑大多通过库合约实现。每个钱包都包含一个轻量级的客户端合约，连接到这个单点故障。漏洞是一种叫做wallet.sol的多重签名合约出现bug导致的，问题在于其中一个初始化函数只能被调用一次。<br><img alt="parity多重签名钱包" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210902160647.png" class="lozad"></p><h3 id="预防措施"><a href="#预防措施" class="headerlink" title="预防措施"></a>预防措施</h3><ul><li>使用开放的资源与社区接受的库合约的实质标准 (de facto standards)，例如 Open Zeppelin’s contracts。</li><li>使用推荐的模式与最优操作指导手册，例如 Consensys 提供的。</li><li>考虑由信誉好的供应商审核您的智能合约。</li></ul><h1 id="以太坊地址"><a href="#以太坊地址" class="headerlink" title="以太坊地址"></a>以太坊地址</h1><h2 id="以太坊地址-1"><a href="#以太坊地址-1" class="headerlink" title="以太坊地址"></a>以太坊地址</h2><h3 id="以太坊地址生成过程-可以借鉴此-文章"><a href="#以太坊地址生成过程-可以借鉴此-文章" class="headerlink" title="以太坊地址生成过程 可以借鉴此[文章]"></a>以太坊地址生成过程 可以借鉴此<a href="https://blog.csdn.net/u013137970/article/details/87821243?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163063844116780271565572%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=163063844116780271565572&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~sobaiduend~default-1-87821243.pc_v2_rank_blog_default&amp;utm_term=%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%94%9F%E6%88%90%E5%9C%B0%E5%9D%80&amp;spm=1018.2226.3001.4450" target="_blank" rel="noopener">[文章]</a></h3><p>1、生成256位随机数作为私钥<br>2、将私钥转化为 secp256k1 非压缩格式的公钥，即 512 位的公钥。<br>3、使用散列算法 Keccak256 计算公钥的哈希值，转化为十六进制字符串。<br>4、取十六进制字符串的后 40 个字母，开头加上 0x 作为地址。</p><h3 id="以太坊地址生成实例"><a href="#以太坊地址生成实例" class="headerlink" title="以太坊地址生成实例"></a>以太坊地址生成实例</h3><ul><li>私钥：1f2b77<strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>*</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>6a7efaa065d20</li><li>公钥：04dfa1<strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>*</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>0bbf8865734252953c9884af787b2cadd45f92dff2b81e21cfdf98873e492e5fdc07e9eb67ca74d</li><li>地址：0xabcd<strong><strong><strong><strong><strong><strong><strong>**</strong></strong></strong></strong></strong></strong></strong>4A2d57</li></ul><h2 id="以太坊合约地址"><a href="#以太坊合约地址" class="headerlink" title="以太坊合约地址"></a>以太坊合约地址</h2><h3 id="以太坊合约地址生成过程-可借鉴此-文章"><a href="#以太坊合约地址生成过程-可借鉴此-文章" class="headerlink" title="以太坊合约地址生成过程 可借鉴此[文章]"></a>以太坊合约地址生成过程 可借鉴此<a href="https://gitee.com/updatecg_admin/ether-erc20-token/tree/master#https://cn.etherscan.com/token/0xdac17f958d2ee523a2206206994597c13d831ec7" target="_blank" rel="noopener">[文章]</a></h3><blockquote><p>利用发送代币生成合约地址</p></blockquote><p>利用Remix - Solidity IDE 网站来发布智能合约 <a href="http://remix.app.hubwiz.com/#optimize=false&amp;runs=200&amp;evmVersion=null&amp;version=soljson-v0.4.16+commit.d7661dd9.js" target="_blank" rel="noopener">[地址]</a></p><h3 id="发币过程"><a href="#发币过程" class="headerlink" title="发币过程"></a>发币过程</h3><h4 id="第一步：在-Chrome-插件商店搜索并安装-MetaMask"><a href="#第一步：在-Chrome-插件商店搜索并安装-MetaMask" class="headerlink" title="第一步：在 Chrome 插件商店搜索并安装 MetaMask"></a>第一步：在 Chrome 插件商店搜索并安装 MetaMask</h4><blockquote><p>MetaMask是钱包的一种，在chrome浏览器中，安装MetaMask插件即可，安装完成后，右上角会出现一个“狐狸头”的标志，点击该标志，打开钱包，第一步，创建账户，（创建账户只需要输入面密码即可，名称创建后可以随便改，该账户就是一个hash值，如何给自己创建的账户冲以太币呢，你可以通过在交易所买入一些ETH，然后转入即可）创建成功后，记住密码还有产生的几个随机单词（一定要记录下来）。<br><img alt="MetaMask" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210903163547.png" class="lozad"></p></blockquote><h4 id="第二步：编写合约代码"><a href="#第二步：编写合约代码" class="headerlink" title="第二步：编写合约代码"></a>第二步：编写合约代码</h4><p><img alt="智能合约代码" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210903120033.png" class="lozad"></p><p>注意事项：</p><ul><li><p>合约代码引用版本需要与编辑器所选版本匹配</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pragma solidity ^0.4.16;</span><br></pre></td></tr></table></figure></li><li><p>精度默认值decimals=18，就是小数点后18位。<br>BTC是8位，0.00000001 (Gwei) = 1(sat)<br>ERC20是18位，0.000000002578400219 (Ether) = 2.578400219 (Gwei)</p></li></ul><h4 id="第三步：注入环境、绑定合约、部署发币"><a href="#第三步：注入环境、绑定合约、部署发币" class="headerlink" title="第三步：注入环境、绑定合约、部署发币"></a>第三步：注入环境、绑定合约、部署发币</h4><p><img alt="发币" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/微信图片_20210903165727.png" class="lozad"></p><p>注意事项：</p><ul><li>以太币数量填写0，不然要报错</li></ul><h4 id="第四步：等待发币结果"><a href="#第四步：等待发币结果" class="headerlink" title="第四步：等待发币结果"></a>第四步：等待发币结果</h4><ul><li><p>MetaMask交易结果<br><img alt="小狐狸发币结果" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210903170041.png" class="lozad"></p></li><li><p>链上交易详情<a href="https://ropsten.etherscan.io/tx/0x1ff79a4e7690e2fffbc08a00eef2373e104c2f639d200ccb54cb225a2d428cc1" target="_blank" rel="noopener">[链上地址]</a><br><img alt="链上交易详情" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210903174023.png" class="lozad"></p></li></ul><p><em>注意：对于EIP-1559升级后，文章后面会详细讲解矿工费机制。</em></p><h1 id="以太坊参数（难度炸弹、出块速度、TPS、矿工费、Nonce）"><a href="#以太坊参数（难度炸弹、出块速度、TPS、矿工费、Nonce）" class="headerlink" title="以太坊参数（难度炸弹、出块速度、TPS、矿工费、Nonce）"></a>以太坊参数（难度炸弹、出块速度、TPS、矿工费、Nonce）</h1><h2 id="难度炸弹"><a href="#难度炸弹" class="headerlink" title="难度炸弹"></a>难度炸弹</h2><blockquote><p>指的是随着挖矿难度增加.<a href="https://eth.tokenview.com/" target="_blank" rel="noopener">[以太坊浏览器]</a></p></blockquote><h3 id="为什么要引入难度炸弹？"><a href="#为什么要引入难度炸弹？" class="headerlink" title="为什么要引入难度炸弹？"></a>为什么要引入难度炸弹？</h3><p><img alt="以太坊参数" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210907113202.png" class="lozad"><br>如图可以看出从20年中旬开始，<strong>难度指数上涨明显</strong>，这是因为<strong>ETH升级2.0</strong>造成的。</p><p>因为他们最终将希望矿工停止挖矿并开始验证工作。</p><p>以太坊（ETH）正试图通过将现有的工作量证明（PoW）共识算法切换为权益证明（PoS）共识算法来解决这个问题。挖矿的奖励将由参与者质押资金的大小决定，而非由现在的电力和资源密集型计算机算力决定。如果出现算法转变的情况，以太坊社区可能会选择通过硬分叉来完全移除或者延迟难度炸弹。</p><h2 id="出块速度"><a href="#出块速度" class="headerlink" title="出块速度"></a>出块速度</h2><blockquote><p><a href="https://www.qkl123.com/data/block_time/eth" target="_blank" rel="noopener">[参考地址]</a></p></blockquote><p><img alt="以太坊出块速度" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210907104205.png" class="lozad"><br>POW模式(接下来会讲)下ETH的出块速度<br>如图蓝色线是出块耗时时间，红色线是币价，黄色线是平均线（可以看出平均耗时在13.45秒）</p><h3 id="出块速度怎么计算的？"><a href="#出块速度怎么计算的？" class="headerlink" title="出块速度怎么计算的？"></a>出块速度怎么计算的？</h3><p><img alt="以太坊参数" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/v2-8e6efb654a51373f7f9fcd855a8a1704_r.jpg" class="lozad"></p><p>如图中蓝色线，以太坊的发行每年产量被限制在7200万以太币的25%（每年以太币的矿产量，不高于1800万。7200万为一次性crowdsale而发行的以太坊）</p><p><img alt="区块" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210907112621.png" class="lozad"><br><strong>按照这个总量来计算</strong></p><p><strong>区块奖励：</strong> 每挖一个区块奖励5个以太坊</p><p><strong>叔块奖励：</strong> 有些区块被挖得稍晚一些，因此不能称为主区块链的组成部分。比特币称这类区块为“孤块”，并且完全舍弃它们。但是，以太币称它们为“ uncles”，并且在之后的区块中，可以引用它们。如果uncles在之后的区块链中作为叔块被引用，每个叔块会为挖矿者产出大约4.375个以太坊。目前每天有大约500个叔块被创建，<strong>每年产量为70万以太坊</strong></p><p><strong>叔块引用奖励:</strong> 矿工每引用一个叔块，就得到了大约0.15个以太币（最多引用两个叔块）</p><p><strong>出块速度计算</strong></p><p><strong>一年</strong>3150万秒（365x24x60x60），每产生一个新区快就会奖励5个以太坊</p><p><strong>出块速度 :</strong> 3150万 / ( (1800万-70万) / 5) ≈ 9 s</p><p><strong>注：</strong> 这里的计算，忽略了叔块引用奖励，真实出块速度可能大于9s，目前真实平均在13.45秒。</p><h2 id="TPS"><a href="#TPS" class="headerlink" title="TPS"></a>TPS</h2><blockquote><p><a href="https://etherscan.io/chart/tx" target="_blank" rel="noopener">[eth的tps数据]</a></p></blockquote><p><strong>以最高的日期算:</strong>  2021年5月9日星期日的最高交易数的tps是1716600/24/60/60 ≈ 19.868055笔</p><p><strong>目前平均：</strong> 1250000/24/60/60 ≈ 14.4675笔</p><p><img alt="tps" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210907135630.png" class="lozad"></p><p><strong>TPS困扰区块链久矣</strong></p><p>很多区块链项目都面临着TPS性能不足的难题，区块链技术的鼻祖自然也不避免。一直以来比特币每个区块容量设置为1MB，平均每10分钟出一次块，在理想情况下TPS可以达到每秒7笔，但实际情况下只能达到每秒3到4笔。而且随着全网交易量走高，已经出现了拥堵的情况，很多交易无法上链，用户体验不好。如今比特币网络中未确认的交易数已经达到22000笔，将近60MB大小，也就是说平均要等待一小时的时间才可以确认。</p><h2 id="矿工费计算"><a href="#矿工费计算" class="headerlink" title="矿工费计算"></a>矿工费计算</h2><blockquote><p>伦敦升级(EIP-1559)升级后矿工费机制变更。</p></blockquote><p><img alt="矿工费" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210907162033.png" class="lozad"></p><h3 id="升级前的矿工费机制"><a href="#升级前的矿工费机制" class="headerlink" title="升级前的矿工费机制"></a>升级前的矿工费机制</h3><ul><li>矿工费 = GasPrice * GasUsed <ul><li>GasUsed（gas）：交易消耗的总 gas 数量。</li><li>GasPrice（gwei）：即对单位 gas 的定价，1 gwei= 10^(-9) eth。</li></ul></li><li>采用竞价机制，GasPrice 设置越高，交易处理速度越快。</li><li>交易由矿工处理，矿工费完全由矿工收取。</li></ul><p><em>GasPrice越多速度越快，web3j默认取得Average值</em></p><h3 id="升级后的费用机制"><a href="#升级后的费用机制" class="headerlink" title="升级后的费用机制"></a>升级后的费用机制</h3><ul><li>交易费用 = （baseFee + PriorityFee）* GasUsed</li></ul><p><strong>思考？</strong> 这里为什么叫交易费用，而非矿工费？</p><p>对比升级前后的公式，可以看出 EIP-1559 是将 GasPrice 拆分成了两个费率的组合：baseFee 和 PriorityFee。</p><h3 id="名词解析"><a href="#名词解析" class="headerlink" title="名词解析"></a>名词解析</h3><p><strong>baseFee（基础费用）</strong> </p><p>baseFee 会根据上一区块的空间利用率自动调整，如果利用率超过 50%，则提升当前区块的 baseFee；反之降低。</p><p>按照 baseFee 计算公式，相邻区块间的 baseFee 变化幅度在 ±12.5% 之间：</p><ul><li>如果上一区块空间利用率为 100%，则当前区块 baseFee 将自动提升 12.5%</li><li>如果上一区块空间利用率为 0%，则当前区块 baseFee 将自动降低 12.5%</li></ul><p>不同于原来的矿工费机制，EIP-1559 升级后，交易费用不完全由矿工收取，其中 baseFee 将被完全销毁。</p><p><strong>PriorityFee（小费）</strong></p><p>PriorityFee 表示给矿工的小费，延续了竞价设计。如果希望自己的交易在区块中被尽快打包，可通过设置 PriorityFee 激励矿工，矿工将优先处理 PriorityFee 高的交易。</p><p>同时，用户还可以自行设置 PriorityFee 的最高值，即付给矿工小费的上限，也叫 maxPriorityFee。</p><p><strong>maxFee（最高费用）</strong></p><p>maxFee 表示用户愿意对某笔交易可支付的最高交易费用。对应到公式中，maxFee = baseFee + maxPriorityFee，其中 maxFee 和 maxPriorityFee 都支持用户自行设置，baseFee 则由算法自动给出。</p><p><em>注：升级后「矿工费」的说法已经不合适了，因为费用中的 baseFee 是要销毁的，只有 PriorityFee 由矿工收取。或许 EIP-1559 升级后，我们应该在以太坊生态中弃用「矿工费」的说法了。</em></p><h3 id="EIP-1559-交易费用计算实例"><a href="#EIP-1559-交易费用计算实例" class="headerlink" title="EIP-1559 交易费用计算实例"></a>EIP-1559 交易费用计算实例</h3><ul><li>升级前<ul><li>矿工费 = GasPrice * GasUsed</li></ul></li><li>升级后<ul><li>交易费用 = （baseFee + PriorityFee）* GasUsed<br>maxFee &gt;= baseFee + maxPriorityFee</li></ul></li></ul><table><thead><tr><th>maxFee</th><th>maxPriorityFee</th><th>baseFee</th><th>销毁</th><th>PriorityFee（矿工小费）</th></tr></thead><tbody><tr><td>50</td><td>10</td><td>1</td><td>1</td><td>10</td></tr><tr><td>50</td><td>10</td><td>40</td><td>40</td><td>10</td></tr><tr><td>50</td><td>10</td><td>45</td><td>45</td><td>50-45=5</td></tr><tr><td>50</td><td>10</td><td>50</td><td>50</td><td>50-50=0</td></tr><tr><td>50</td><td>10</td><td>60</td><td></td><td>由于 maxFee 小于 baseFee，这笔交易无法进入当前区块，将继续排队</td></tr></tbody></table><p><em>注：如果交易失败，交易费用会退款给源地址，但是其中的PriorityFee矿工小费不会退还。</em></p><h2 id="Nonce"><a href="#Nonce" class="headerlink" title="Nonce"></a>Nonce</h2><blockquote><p>Nonce决定了交易顺序，以上述链上交易详情[链上地址]为例。</p></blockquote><p><img alt="val" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210907174751.png" class="lozad"></p><p>排除非本账号发送方交易</p><p><img alt="val" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210907175205.png" class="lozad"></p><p>可以看出同交易地址每交易一笔nonce则增加1，第一笔从O开始</p><p><img alt="val" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/微信图片_20210907175848.png" class="lozad"></p><h1 id="以太坊共识机制"><a href="#以太坊共识机制" class="headerlink" title="以太坊共识机制"></a>以太坊共识机制</h1><blockquote><p>共识机制（也称为共识协议或共识算法）允许分布式系统（计算机网络）协同工作并保持安全。</p></blockquote><h2 id="共识机制常见类型"><a href="#共识机制常见类型" class="headerlink" title="共识机制常见类型"></a>共识机制常见类型</h2><h3 id="工作量证明-POW"><a href="#工作量证明-POW" class="headerlink" title="工作量证明(POW)"></a>工作量证明(POW)</h3><blockquote><p>以太坊目前采用工作量证明 (PoW) 共识协议。这种机制允许以太坊网络的节点就以太坊区块链上记录的所有信息的状态达成共识，并防止某些产生经济影响的攻击。</p></blockquote><h4 id="什么是工作量证明-POW"><a href="#什么是工作量证明-POW" class="headerlink" title="什么是工作量证明 (POW)?"></a>什么是工作量证明 (POW)?</h4><p>工作量证明是一种允许去中心化的以太坊网络达成共识或者一致认可账号余额和交易顺序的机制，这个机制防止用户“双花”他们的货币。</p><p>名词解析：“双花”问题是指一笔数字现金在交易中被反复使用的现象。</p><h4 id="以太坊的工作量证明机制是如何运作的"><a href="#以太坊的工作量证明机制是如何运作的" class="headerlink" title="以太坊的工作量证明机制是如何运作的?"></a>以太坊的工作量证明机制是如何运作的?</h4><p>以太坊的交易被处理为区块。 每个区块有一个：</p><ul><li>区块的难度，例如：3,324,092,183,262,715</li><li>混合哈希（mixHash），例如：0x44bca881b07a6a09f83b130798072441705d9a665c5ac8bdf2f39a3cdf3bee29</li><li>nonce–例如：0xd3ee432b4fb3d26b</li></ul><p>区块的数据直接和 Pow 关联。</p><h5 id="工作量证明机制"><a href="#工作量证明机制" class="headerlink" title="工作量证明机制"></a>工作量证明机制</h5><blockquote><p>要求矿工经过激烈的试错竞赛，找到一个区块的 nonce。 只有具备有效 nonce 的区块才能被加入区块链中。</p></blockquote><p>当通过比赛创建一个区块时，矿工将反复放置一个数据集，只能通过数学函数从下载和运行完整链（像矿工那样）中获得数据集。 这是为了根据区块所声明的难度，生成一个低于目标 nonce 的混合哈希（mixHash）。 做到这些最好的方式是试错。</p><p>难度决定了这个哈希（mixHash）的指标。 目标越小，有效的哈希值的集合就越小。 一旦哈希值生成，对于其他矿工和客户来说，是很容易校验哈希值是否有效的。 </p><h5 id="终局性"><a href="#终局性" class="headerlink" title="终局性"></a>终局性</h5><p>由于矿工是分散的，两个有效的区块是可以同时开采的。 这就造成一个临时的分叉。 最后只要两条中一条支链通过先挖出下一个区块成为最长的支链，这条支链就会被添加到主链上。</p><p>但为了使情况更复杂， 临时分叉上被拒绝的交易将会被记录在公认的主链上。 这意味着区块是可逆的。 因此，终局性是需要你等待一段时间至交易不可逆。 以太坊推荐的时间是等待 6 个区块或者超过 1 分钟。 这样你才能确定这笔交易已经成功。</p><h4 id="POW总结"><a href="#POW总结" class="headerlink" title="POW总结"></a>POW总结</h4><p>简单来说，pow就是“按劳分配“一个矿工付出多少，提供多少工作证明就是能拿到多少报酬，这也是千百年来社会分配最公平的方式，自己购买显卡显然是有收益的，按照自己工作量获取报酬，多少矿机工作记录可以提供证明，就可以获取相应的报酬。</p><h3 id="权益证明机制-POS"><a href="#权益证明机制-POS" class="headerlink" title="权益证明机制(POS)"></a>权益证明机制(POS)</h3><blockquote><p>Eth升级到2.0，正在将其共识机制从工作量证明(POW)转变为权益证明(POS)</p></blockquote><h4 id="什么是权益证明？"><a href="#什么是权益证明？" class="headerlink" title="什么是权益证明？"></a>什么是权益证明？</h4><p>这将要求用户抵押他们的以太币从而成为网络中合法的验证者。 验证者有着与矿工在 工作量证明（pow）中相同的职责：将交易排序和创建新的区块，以便让所有的节点就网路状态达成一致。</p><p>权益证明相较于工作量证明系统有许多改进：</p><ul><li>提高能效——您不需要大量能源去挖掘区块</li><li>门槛降低，硬件要求减少——您不需要优秀的硬件从而获得建立新区块的机会</li><li>更强的去中心化——权益证明可以在网络中提供更多的节点。</li><li>更有力的支持分片链——一个得以扩展以太坊网络的关键升级</li></ul><h4 id="权益证明、权益质押和验证者"><a href="#权益证明、权益质押和验证者" class="headerlink" title="权益证明、权益质押和验证者"></a>权益证明、权益质押和验证者</h4><p>权益证明是一种用于激励验证者接受更多质押的基本机制。 就以太币而言，用户需要质押 32ETH 来获得作为验证者的资格。 验证者被随机选择去创建区块，并且负责检查和确认那些不是由他们创造的区块。 一个用户的权益也被用于激励良好的验证者行为的一种方式。 例如，用户可能会因为离线（验证失败）而损失一部分权益， 或因故意勾结而损失他们的全部权益。</p><h4 id="以太坊权益证明是如何运作的？"><a href="#以太坊权益证明是如何运作的？" class="headerlink" title="以太坊权益证明是如何运作的？"></a>以太坊权益证明是如何运作的？</h4><p>与工作量证明不同的是，验证者不需要使用大量的计算能力，因为它们是随机选择的，相互间没有竞争。 他们不需要开采区块，他们只需要在被选中的时候创建区块并且在没有被选中的时候验证他人提交的区块。 此验证被称为证明。 你可以认为证明是说“这个块在我看来没问题”。 验证者因提出新区块和证明他们已经看到的区块而获得奖励。</p><p>如果你为恶意区块提供证明，你就会失去你的股权。</p><h5 id="信标链"><a href="#信标链" class="headerlink" title="信标链"></a>信标链</h5><p>当以太坊用权益证明取代工作量证明时， <a href="https://ethereum.org/zh/eth2/" target="_blank" rel="noopener">[分片链]</a> 的复杂性会增加。这是需要验证者来处理交易和创建新区块的独立区块链。 计划中将有 64 个分片链，并且它们都需要对网络的当下状态有一个共同的理解。 所以这需要额外的协调工作，这将由信标链来完成。</p><h5 id="终局性-1"><a href="#终局性-1" class="headerlink" title="终局性"></a>终局性</h5><p>可以让验证者在某些检查点就一个区块的状态达成协议。 只要 2/3 的验证者同意，该区块就会被最终确定。 验证者如果试图稍后通过 51% 的攻击恢复，就会失去他们的全部权益。</p><h3 id="POS与POW对比总结-借鉴对话"><a href="#POS与POW对比总结-借鉴对话" class="headerlink" title="POS与POW对比总结  [借鉴对话]"></a>POS与POW对比总结  <a href="https://twitter.com/yulesa/status/1333506601291014148" target="_blank" rel="noopener">[借鉴对话]</a></h3><blockquote><p>现目前仍然是POW，还没有升级完，预计明年初，或者年末，应该有兼容版本行为。</p></blockquote><h4 id="POW"><a href="#POW" class="headerlink" title="POW"></a>POW</h4><ul><li>【人工】检查每个人的余额和交易是否检查出来，所以没有人会花费他们没有的硬币。这需要非常低的计算能力。|</li><li>【机器】矿工通过购买更多和最好的采矿设备来做到这一点。该硬件不会为网络做有用的计算工作，它只是为块奖励奖品抽奖。PoW 矿工本质上是在硬件设备上投入资金以获得更多回报。</li><li>如果矿工恶意行事，他们将失去区块奖励和运行钻机的运营成本，其中大部分是电费。恶意玩家损失的越多，区块链就越安全。所以钻机的运营成本和区块奖励必须尽可能高。这就是 PoW 在电力资源上如此浪费的原因。</li></ul><h4 id="POS"><a href="#POS" class="headerlink" title="POS"></a>POS</h4><ul><li>摆脱了这种“硬件设备”中介。你直接下注你的钱，你的投票权与你下注的数量成正比。随机选择一个人提出一个区块，其他人必须签署该区块是正确的。</li><li>PoS 运营成本非常低。相反，如果你恶意行事，除了失去奖励（正强化），你的赌注也会被烧毁（负强化）。</li><li>考虑到股权现在以网络货币计价，它可以更好地将激励措施与网络中的参与者保持一致。</li><li>由于你的股权表现不佳，如果你再次尝试不诚实，你的下一次攻击就不那么有效了，因为你的股权现在降低了，你的投票权也降低了。</li><li>由于不良行为者现在具有负强化，参与者不再那么狡猾，并且可以降低网络正强化以保持相同的安全水平。因此，网络可以减少块奖励。</li><li>由于运营成本低，更多的人可以参与网络共识。您无需靠近矿机分销渠道或获得较低的电力成本。网络以这种方式更加去中心化</li></ul><h1 id="测试网络"><a href="#测试网络" class="headerlink" title="测试网络"></a>测试网络</h1><blockquote><p>BTC只有一个测试网络，为什么ETH会有多个，让我们一起来探究吧！</p><p>以太坊可以搭建私有的测试网络，不过由于以太坊是一个去中心化的平台，需要较多节点共同运作才能得到 <strong>理想的测试效果</strong>，因此并不推荐自行搭建测试网络。</p></blockquote><h2 id="以小狐狸为例"><a href="#以小狐狸为例" class="headerlink" title="以小狐狸为例"></a>以小狐狸为例</h2><p><img alt="小狐狸" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210908103016.png" class="lozad"></p><table><thead><tr><th>测试网</th><th>共识机制</th><th>出块间隔(s)</th><th>提供方</th><th>上线时间</th><th>备注</th><th>状态</th></tr></thead><tbody><tr><td>Morden</td><td>PoW</td><td></td><td>以太坊官方</td><td>2015.7</td><td>因难度炸弹退出</td><td>stopped</td></tr><tr><td>Ropsten</td><td>PoW</td><td>30</td><td>以太坊官方</td><td>2016.11</td><td>接替Morden</td><td>running</td></tr><tr><td>Kovan</td><td>PoA</td><td>4</td><td>以太坊钱包Parity开发团队</td><td>2017.3</td><td>不支持geth</td><td>running</td></tr><tr><td>Rinkeby</td><td>PoA</td><td>15</td><td>以太坊官方</td><td>2017.4</td><td>最常用，只支持geth</td><td>running</td></tr><tr><td>Goerli</td><td>PoA</td><td>15</td><td>以太坊柏林社区</td><td>2018.9</td><td>首个以太坊2.0实验场</td><td>running</td></tr></tbody></table><p>上图可以看出以太坊有一个主网络，四个测试网络。</p><ul><li><strong>Morden(已退役)</strong></li></ul><p>Morden是以太坊官方提供的测试网络，自2015年7月开始运行。到2016年11月时，由于难度炸弹已经严重影响出块速度，不得不退役，重新开启一条新的区块链。Morden的共识机制为PoW。</p><ul><li><strong>Ropsten网络<a href="https://ropsten.etherscan.io/" target="_blank" rel="noopener">[区块链浏览器]</a></strong><blockquote><p>现目前项目采用的web3j-api，采用的Ropsten网络，也是最接近主网络的。</p></blockquote></li></ul><p>Ropsten也是以太坊官方提供的测试网络，是为了解决Morden难度炸弹问题而重新启动的一条区块链，目前仍在运行，共识机制为PoW。测试网络上的以太币并无实际价值，因此Ropsten的挖矿难度很低，目前在755M左右，仅仅只有主网络的0.07%。这样低的难度一方面使一台普通笔记本电脑的CPU也可以挖出区块，获得测试网络上的以太币，方便开发人员测试软件，但是却不能阻止攻击。</p><p>PoW共识机制要求有足够强大的算力保证没有人可以随意生成区块，这种共识机制只有在具有实际价值的主网络中才会有效。测试网络上的以太币没有价值，也就不会有强大的算力投入来维护测试网络的安全，这就导致了测试网络的挖矿难度很低，即使几块普通的显卡，也足以进行一次51%攻击，或者用垃圾交易阻塞区块链，攻击的成本及其低廉。</p><p>2017年2月，Ropsten便遭到了一次利用测试网络的低难度进行的攻击，攻击者发送了千万级的垃圾交易，并逐渐把区块Gas上限从正常的4,700,000提高到了90,000,000,000，在一段时间内，影响了测试网络的运行。攻击者发动这些攻击，并不能获得利益，仅仅是为了测试、炫耀、或者单纯觉得好玩儿。</p><ul><li><strong>Kovan网络<a href="https://kovan.etherscan.io/" target="_blank" rel="noopener">[区块链浏览器]</a></strong></li></ul><p>为了解决测试网络中PoW共识机制的问题，以太坊钱包Parity的开发团队发起了一个新的测试网络Kovan。Kovan使用了权威证明(Proof-of-Authority)的共识机制，简称PoA。</p><p>PoW是用工作量来获得生成区块的权利，必须完成一定次数的计算后，发现一个满足条件的谜题答案，才能够生成有效的区块。</p><p><strong>PoA是由若干个权威节点来生成区块，其他节点无权生成，这样也就不再需要挖矿。</strong> 由于测试网络上的以太币无价值，<strong>权威节点仅仅是用来防止区块被随意生成，造成测试网络拥堵，完全是义务劳动，不存在作恶的动机，因此这种机制在测试网络上是可行的。</strong></p><p><strong>Kovan与主网络使用不同的共识机制，影响的仅仅是谁有权来生成区块，以及验证区块是否有效的方式，权威节点可以根据开发人员的申请生成以太币，并不影响开发者测试智能合约和其他功能。</strong></p><blockquote><p><a href="https://app.mycrypto.com/faucet" target="_blank" rel="noopener">https://app.mycrypto.com/faucet</a> 使用时，注意体检切换你的metamask钱包网络。 它支持多个网络水龙头领币。</p></blockquote><ul><li><strong>Rinkeby测试网<a href="https://rinkeby.etherscan.io/" target="_blank" rel="noopener">[区块链浏览器]</a></strong></li></ul><p>Rinkeby也是以太坊官方提供的测试网络，使用PoA共识机制。与Kovan不同，以太坊团队提供了Rinkeby的PoA共识机制说明文档，理论上任何以太坊钱包都可以根据这个说明文档，支持Rinkeby测试网络，目前Rinkeby已经开始运行。</p><blockquote><p>目前开发人员最常用的测试网络是Rinkeby</p></blockquote><ul><li><strong>Goerli测试网<a href="https://goerli.etherscan.io/" target="_blank" rel="noopener">[区块链浏览器]</a></strong></li></ul><p>以太坊 2.0 是一个 PoS 网络，由质押代币的验证节点来生产区块并维持网络运行。因此，首先要解决的问题是如何将代币分配给验证节点以运行网络。</p><h2 id="水龙头地址"><a href="#水龙头地址" class="headerlink" title="水龙头地址"></a>水龙头地址</h2><ul><li><strong>Ropsten网络<a href="https://ropsten.etherscan.io/" target="_blank" rel="noopener">[区块链浏览器]</a></strong></li></ul><p>水龙头（需翻墙，亲测可用 5ETH）：<a href="https://faucet.dimensions.network/" target="_blank" rel="noopener">https://faucet.dimensions.network/</a><br>水龙头（需翻墙，亲测可用 1ETH）：<a href="https://app.mycrypto.com/faucet" target="_blank" rel="noopener">https://app.mycrypto.com/faucet</a><br>水龙头：<a href="https://faucet.ropsten.be/" target="_blank" rel="noopener">https://faucet.ropsten.be/</a></p><ul><li><strong>Kovan网络<a href="https://kovan.etherscan.io/" target="_blank" rel="noopener">[区块链浏览器]</a></strong></li></ul><p>水龙头（需翻墙，亲测可用 1ETH）：<a href="https://app.mycrypto.com/faucet" target="_blank" rel="noopener">https://app.mycrypto.com/faucet</a></p><ul><li><strong>Rinkeby测试网<a href="https://rinkeby.etherscan.io/" target="_blank" rel="noopener">[区块链浏览器]</a></strong></li></ul><p>水龙头： <a href="https://faucet.rinkeby.io/" target="_blank" rel="noopener">https://faucet.rinkeby.io/</a></p><h1 id="ETH节点客户端"><a href="#ETH节点客户端" class="headerlink" title="ETH节点客户端"></a>ETH节点客户端</h1><blockquote><p><a href="https://www.ethernodes.org/" target="_blank" rel="noopener">[参考地址]</a></p></blockquote><h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><table><thead><tr><th>名称</th><th>地址</th><th>语言</th><th>支持系统</th><th>磁盘容量(快速同步)</th><th>磁盘容量(完整归档)</th><th>备注</th></tr></thead><tbody><tr><td>geth</td><td><a href="https://github.com/ethereum/go-ethereum" target="_blank" rel="noopener">https://github.com/ethereum/go-ethereum</a></td><td>Go</td><td>windows、linux和OSX</td><td>400GB+</td><td>4.7TB+</td><td>最广泛的以太坊客户端</td></tr><tr><td>Open Ethereum</td><td><a href="https://github.com/openethereum/openethereum/" target="_blank" rel="noopener">https://github.com/openethereum/openethereum/</a></td><td>Rust</td><td>windows、linux和OSX</td><td>280GB</td><td>4.6TB+</td><td>最小内存和存储空间占用</td></tr><tr><td>nethermind</td><td><a href="https://github.com/NethermindEth/nethermind" target="_blank" rel="noopener">https://github.com/NethermindEth/nethermind</a></td><td>C#、.NET</td><td>Linux 、Mac  、 Windows</td><td>200GB+</td><td>3TB+</td><td>性能强劲的虚拟机</td></tr><tr><td>Parity</td><td><a href="https://github.com/paritytech/parity" target="_blank" rel="noopener">https://github.com/paritytech/parity</a></td><td>C++</td><td>Windows 、Linux、Mac</td><td></td><td></td><td>前面出问题的客户端</td></tr></tbody></table><h2 id="节点分布"><a href="#节点分布" class="headerlink" title="节点分布"></a>节点分布</h2><p><img alt="节点分布" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/微信图片_20210908145226.png" class="lozad"></p><p><strong>世界分布</strong></p><p><img alt="城市分布" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210908145403.png" class="lozad"></p><p><strong>中国分布</strong></p><p><img alt="城市分布" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210908145542.png" class="lozad"></p><h1 id="API-参考文章"><a href="#API-参考文章" class="headerlink" title="API [参考文章]"></a>API <a href="https://ethereum.org/zh/developers/docs/apis/backend/" target="_blank" rel="noopener">[参考文章]</a></h1><blockquote><p>以太坊官网开放了前段、后端相关的技术API文档。每个以太坊客户端都将履行 JSON-RPC 规范，因此我们有一个统一的端点组可供应用程序们依赖。</p></blockquote><p>以whateverPay使用api举例，采用了web3j库。<a href="https://docs.web3j.io/4.8.7/" target="_blank" rel="noopener">[参考文章]</a></p><ul><li>支持Java/Android/Kotlin/Scala语言。</li><li><a href="https://docs.web3j.io/4.8.7/javadoc-api/org/web3j/protocol/core/JsonRpc2_0Web3j.html" target="_blank" rel="noopener">[接口详情文档]</a></li></ul><h1 id="代币协议"><a href="#代币协议" class="headerlink" title="代币协议"></a>代币协议</h1><blockquote><p>在区块链上，数字加密货币分为原生币和代币两大类。代币之中又可分为同质化和非同质化两种</p></blockquote><h2 id="原生币"><a href="#原生币" class="headerlink" title="原生币"></a>原生币</h2><p>正如大家熟悉的比特币（BTC）、以太坊（ETH）等，拥有自己的主链，使用链上的交易来维护账本数据,交易手续费也是以原生币结算的。</p><h2 id="代币"><a href="#代币" class="headerlink" title="代币"></a>代币</h2><p>则是依附于现有的区块链，使用智能合约来进行账本的记录，如项目方依附于以太坊发布的token。最多的是以太坊（Ethereum）上的ERC20代币，部署一个ERC20的智能合约就可以发布一个token。</p><h2 id="同质化代币"><a href="#同质化代币" class="headerlink" title="同质化代币"></a>同质化代币</h2><p>即FT（Fungible Token），互相可以替代、可接近无限拆分的token。例如，你手里有一个ETH与我手里的一个ETH，可以拆分,1 ETH = 1 * 10^18 Wei,本质上没有任何区别，这就是同质化代币。</p><h2 id="非同质化"><a href="#非同质化" class="headerlink" title="非同质化"></a>非同质化</h2><blockquote><p>正如最近比较火：科比花55个以太坊(约18万美元，合人民币116万元)买下了一个猿猴头像。 孙宇晨韭菜王以1.2亿枚TRX购买NFT，价值约合1050万美元。有钱人的世界想象不到！</p></blockquote><p>同质化代币，即NFT（Non-Fungible Token）属于ERC721协议，则是唯一的、不可拆分的token，如加密猫、艺术家的油画等。NFT都是独一无二、不可分割的。这意味着当一件作品被铸成NFT之后，这个作品就成为了区块链上独一无二的数字资产。</p><h2 id="代币如何交易？"><a href="#代币如何交易？" class="headerlink" title="代币如何交易？"></a>代币如何交易？</h2><p>交易所的杠杆代币为ERC20代币，可直接在交易所的现货市场用USD进行交易。如果你有USDT的话，需要先在现货市场中使用USDT买入USD，然后再进行杠杆代币交易。需要注意的是，不管你在哪个交易所上交易他的杠杆代币，都会每天收取万三的持仓管理费，相较于其他交易所，管理费是最低的了。</p><h1 id="空想不如实践"><a href="#空想不如实践" class="headerlink" title="空想不如实践"></a>空想不如实践</h1><p>下载DAPP进行交易吧，实际操作，真实体验。输赢则在那一刹间，先给自己定一个小目标，先来一个亿。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;以太坊简介&quot;&gt;&lt;a href=&quot;#以太坊简介&quot; class=&quot;headerlink&quot; title=&quot;以太坊简介&quot;&gt;&lt;/a&gt;以太坊简介&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;以太坊是一个为去中心化应用（DApp）而生的全球开源平台。&lt;/p&gt;
&lt;p&gt;官方地址: &lt;a
      
    
    </summary>
    
      <category term="虚拟币" scheme="http://www.updatecg.xin/categories/%E8%99%9A%E6%8B%9F%E5%B8%81/"/>
    
    
      <category term="ETH" scheme="http://www.updatecg.xin/tags/ETH/"/>
    
      <category term="虚拟币" scheme="http://www.updatecg.xin/tags/%E8%99%9A%E6%8B%9F%E5%B8%81/"/>
    
  </entry>
  
  <entry>
    <title>K8s管理应用生命周期-Deployment</title>
    <link href="http://www.updatecg.xin/2021/08/27/K8s%E7%AE%A1%E7%90%86%E5%BA%94%E7%94%A8%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F-Deployment/"/>
    <id>http://www.updatecg.xin/2021/08/27/K8s管理应用生命周期-Deployment/</id>
    <published>2021-08-27T07:18:00.000Z</published>
    <updated>2021-12-29T03:05:09.571Z</updated>
    
    <content type="html"><![CDATA[<h2 id="在Kubernetes部署应用程序流程"><a href="#在Kubernetes部署应用程序流程" class="headerlink" title="在Kubernetes部署应用程序流程"></a>在Kubernetes部署应用程序流程</h2><p><img alt="kubernetes" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210827114906.png" class="lozad"></p><h2 id="使用Deployment部署Java应用"><a href="#使用Deployment部署Java应用" class="headerlink" title="使用Deployment部署Java应用"></a>使用Deployment部署Java应用</h2><ul><li>制作镜像利用镜像部署</li><li><p>使用Deployment控制器部署镜像</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl create deployment web --image=镜像地址</span><br><span class="line">kubectl get deployment,pods</span><br></pre></td></tr></table></figure></li><li><p>使用Service发布Pod</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl expose deployment web --port80 --type=NodePort --target-port=8080 --name=web</span><br><span class="line">kubectl get service</span><br></pre></td></tr></table></figure></li></ul><h2 id="服务编排"><a href="#服务编排" class="headerlink" title="服务编排"></a>服务编排</h2><h3 id="YAML文件格式说明"><a href="#YAML文件格式说明" class="headerlink" title="YAML文件格式说明"></a>YAML文件格式说明</h3><blockquote><p>K8s是一个容器编排引擎，使用YAML文件编排要部署应用，因此在学习之前，应先了解YAML语法格式：</p><ul><li>缩进表示层级关系</li><li>不支持制表符”tab”缩进，需使用空格缩进</li><li>通常开头缩进2个空格</li><li>字符后缩进1个空格，如冒号、逗号等</li><li>“—“ 表示YAML格式，一个文件的开始</li><li>“#” 注释</li></ul></blockquote><h3 id="YAML文件创建资源对象"><a href="#YAML文件创建资源对象" class="headerlink" title="YAML文件创建资源对象"></a>YAML文件创建资源对象</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">    replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">    selector:</span></span><br><span class="line"><span class="attr">      matchLabels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">    template:</span></span><br><span class="line"><span class="attr">      metadata:</span></span><br><span class="line"><span class="attr">        labels:</span></span><br><span class="line"><span class="attr">          app:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">      spec:</span></span><br><span class="line"><span class="attr">        containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">         image:</span> <span class="string">镜像地址</span></span><br></pre></td></tr></table></figure><p>等同于：kubectl create deployment web –image=镜像地址 –replicas=3 -n default</p><h4 id="标签描述："><a href="#标签描述：" class="headerlink" title="标签描述："></a>标签描述：</h4><table><thead><tr><th>标签key</th><th>含义</th></tr></thead><tbody><tr><td>apiVersion</td><td>API版本</td></tr><tr><td>kind</td><td>资源类型</td></tr><tr><td>metadata</td><td>资源元数据</td></tr><tr><td>spec</td><td>资源规格</td></tr><tr><td>replicas</td><td>副本数</td></tr><tr><td>selector</td><td>标签选择器，下面metadata.labels保持一致</td></tr><tr><td>template</td><td>Pod模板</td></tr><tr><td>metadata</td><td>Pod元数据</td></tr><tr><td>spec</td><td>pod规格</td></tr><tr><td>containers</td><td>容器配置</td></tr></tbody></table><h4 id="部署卸载"><a href="#部署卸载" class="headerlink" title="部署卸载"></a>部署卸载</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">部署: kubectl apply -f xxx.yaml</span><br><span class="line">卸载: kubectl delete -f xxx.yaml</span><br></pre></td></tr></table></figure><h3 id="资源字段太多，记不住怎么办？"><a href="#资源字段太多，记不住怎么办？" class="headerlink" title="资源字段太多，记不住怎么办？"></a>资源字段太多，记不住怎么办？</h3><ul><li><p>用get命令导出</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get deployment nginx -o yaml &gt; my-deploy.yaml</span><br></pre></td></tr></table></figure></li><li><p>Pod容器的字段拼写忘记了</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl explain pods.spec.containers</span><br><span class="line">kubectl explain deployment</span><br></pre></td></tr></table></figure></li></ul><h2 id="Deployment介绍"><a href="#Deployment介绍" class="headerlink" title="Deployment介绍"></a>Deployment介绍</h2><blockquote><p>Deployment是最常用的K8s工作负载控制器（Workload Controllers），是K8s的一个抽象概念，用于更高级层次对象，部署和管理Pod。其他控制器还有DaemonSet、StatefulSet等。</p></blockquote><h3 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h3><ul><li>管理Pod和ReplicaSet</li><li>具体上线部署、副本设定、滚动升级、回滚等功能</li><li>提供声明式更新、例如只更新一个新的Image</li></ul><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><blockquote><p>网站、API、微服务</p></blockquote><h3 id="应用生命周期管理流程"><a href="#应用生命周期管理流程" class="headerlink" title="应用生命周期管理流程"></a>应用生命周期管理流程</h3><p><img alt="kubernetes" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210827164349.png" class="lozad">多少钱</p><h4 id="第一步》部署应用"><a href="#第一步》部署应用" class="headerlink" title="第一步》部署应用"></a>第一步》部署应用</h4><blockquote><p>利用创建nginx为模板，创建nginx.yaml文件<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">nginx:1.16</span></span><br></pre></td></tr></table></figure></p></blockquote><p>执行创建yaml命令<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f nginx.yaml</span><br></pre></td></tr></table></figure></p><p>不使用yaml文件创建<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl create deployment web --image=nginx:1.16 --replicas=3</span><br></pre></td></tr></table></figure></p><h4 id="第二步》滚动升级"><a href="#第二步》滚动升级" class="headerlink" title="第二步》滚动升级"></a>第二步》滚动升级</h4><p><img alt="kubernetes" data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/QQ截图20210827165215.png" class="lozad"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;在Kubernetes部署应用程序流程&quot;&gt;&lt;a href=&quot;#在Kubernetes部署应用程序流程&quot; class=&quot;headerlink&quot; title=&quot;在Kubernetes部署应用程序流程&quot;&gt;&lt;/a&gt;在Kubernetes部署应用程序流程&lt;/h2&gt;&lt;p&gt;&lt;i
      
    
    </summary>
    
      <category term="K8S" scheme="http://www.updatecg.xin/categories/K8S/"/>
    
    
      <category term="devOps" scheme="http://www.updatecg.xin/tags/devOps/"/>
    
      <category term="K8S" scheme="http://www.updatecg.xin/tags/K8S/"/>
    
  </entry>
  
  <entry>
    <title>带你认识K8S</title>
    <link href="http://www.updatecg.xin/2021/08/27/%E5%B8%A6%E4%BD%A0%E8%AE%A4%E8%AF%86K8S/"/>
    <id>http://www.updatecg.xin/2021/08/27/带你认识K8S/</id>
    <published>2021-08-27T07:18:00.000Z</published>
    <updated>2021-12-20T09:55:14.228Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、了解基本知识"><a href="#一、了解基本知识" class="headerlink" title="一、了解基本知识"></a>一、了解基本知识</h1><h2 id="官方网站"><a href="#官方网站" class="headerlink" title="官方网站"></a>官方网站</h2><p><a href="https://kubernetes.io/" target="_blank" rel="noopener">https://kubernetes.io/</a></p><h2 id="官网中文地址"><a href="#官网中文地址" class="headerlink" title="官网中文地址"></a>官网中文地址</h2><p><a href="https://kubernetes.io/zh/docs/home/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/home/</a></p><h1 id="二、安装部署"><a href="#二、安装部署" class="headerlink" title="二、安装部署"></a>二、安装部署</h1><p>自己动手安装部署，先通过命令简单熟悉下，尽量自己建立虚拟机进行安装部署。</p><h2 id="官方安装步骤："><a href="#官方安装步骤：" class="headerlink" title="官方安装步骤："></a>官方安装步骤：</h2><p><a href="https://kubernetes.io/zh/docs/tasks/tools/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/tasks/tools/</a></p><h2 id="总结的安装步骤："><a href="#总结的安装步骤：" class="headerlink" title="总结的安装步骤："></a>总结的安装步骤：</h2><p><a href="https://www.updatecg.xin/2021/08/19/%E9%83%A8%E7%BD%B2%E4%B8%80%E5%A5%97%E5%8D%95Master%E7%9A%84K8s%E9%9B%86%E7%BE%A4/">https://www.updatecg.xin/2021/08/19/%E9%83%A8%E7%BD%B2%E4%B8%80%E5%A5%97%E5%8D%95Master%E7%9A%84K8s%E9%9B%86%E7%BE%A4/</a></p><h1 id="三、Kubernetes-核心概念"><a href="#三、Kubernetes-核心概念" class="headerlink" title="三、Kubernetes 核心概念"></a>三、Kubernetes 核心概念</h1><ul><li>有了Docker，为什么还用Kubernetes？</li><li>Kubernetes是什么 ？</li><li>Kubernetes集群架构与组件 ？</li><li>Kubernetes基本概念 ？<h2 id="一、有了Docker，为什么还用Kubernetes？"><a href="#一、有了Docker，为什么还用Kubernetes？" class="headerlink" title="一、有了Docker，为什么还用Kubernetes？"></a>一、有了Docker，为什么还用Kubernetes？</h2>企业需求：为提高业务并发和高可用，会使用多台服务器</li><li>多容器跨主机提供服务</li><li>多容器分布节点部署</li><li>多容器怎么升级</li><li>高效管理这些容器</li></ul><p><img alt data-src="https://cdn.nlark.com/yuque/0/2021/png/22225794/1639993776141-2e7036f1-ffd9-4e94-bf30-60a2649ab8d2.png#clientId=u996f0f4d-7cea-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ua04fa171&amp;margin=%5Bobject%20Object%5D&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uda34d4f8-7c22-4e79-a30b-a3b0162e309&amp;title=" class="lozad"><br><img alt data-src="https://cdn.nlark.com/yuque/0/2021/png/22225794/1639993776159-b1531f2c-5b51-41ad-b5e8-0f374174d734.png#clientId=u996f0f4d-7cea-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u060c4e9a&amp;margin=%5Bobject%20Object%5D&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uef2751cd-a563-4af1-af22-de5193b57a0&amp;title=" class="lozad"></p><h2 id="二、Kubernetes是什么-？"><a href="#二、Kubernetes是什么-？" class="headerlink" title="二、Kubernetes是什么 ？"></a>二、Kubernetes是什么 ？</h2><ul><li>Kubernetes是Google在2014年开源的一个容器集群管理系统，Kubernetes简称K8S。</li><li><p>Kubernetes用于容器化应用程序的部署，扩展和管理，目标是让部署容器化应用简单高效。</p><h2 id="三、Kubernetes集群架构与重要组件-？"><a href="#三、Kubernetes集群架构与重要组件-？" class="headerlink" title="三、Kubernetes集群架构与重要组件 ？"></a>三、Kubernetes集群架构与重要组件 ？</h2><p><img alt data-src="https://cdn.nlark.com/yuque/0/2021/png/22225794/1639993776287-3f376bdf-3ec5-47b6-811c-cee39f2d0d03.png#clientId=u996f0f4d-7cea-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ua89e6b12&amp;margin=%5Bobject%20Object%5D&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u91ad86e3-63e0-408d-bebc-46917413ad0&amp;title=" class="lozad"><br><img alt data-src="https://cdn.nlark.com/yuque/0/2021/png/22225794/1639993776311-8f0a9ef0-d88b-4398-a759-c1362e393be4.png#clientId=u996f0f4d-7cea-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=ufc4e8708&amp;margin=%5Bobject%20Object%5D&amp;originHeight=476&amp;originWidth=614&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u1eaf91f6-e7b4-4ec8-8f8f-eb6d7bff7dd&amp;title=" class="lozad"></p><h3 id="综合理解"><a href="#综合理解" class="headerlink" title="综合理解"></a>综合理解</h3><h4 id="Master组件"><a href="#Master组件" class="headerlink" title="Master组件"></a>Master组件</h4></li><li><p>kube-apiserver</p></li></ul><p>Kubernetes API，集群的统一入口，各组件协调者，以RESTful API提供接口服务，所有对象资源的增删改查和监听操作都交给 APIServer处理后再提交给Etcd存储。</p><ul><li>kube-controller-manager</li></ul><p>处理集群中常规后台任务，一个资源对应一个控制器，而 ControllerManager就是负责管理这些控制器的。</p><ul><li>kube-scheduler</li></ul><p>根据调度算法为新创建的Pod选择一个Node节点，可以任意部署, 可以部署在同一个节点上,也可以部署在不同的节点上。</p><ul><li>etcd</li></ul><p>分布式键值存储系统。用于保存集群状态数据，比如Pod、Service 等对象信息。</p><h4 id="Node组件"><a href="#Node组件" class="headerlink" title="Node组件"></a>Node组件</h4><ul><li>kubelet</li></ul><p>kubelet是Master在Node节点上的Agent，管理本机运行容器的生命周 期，比如创建容器、Pod挂载数据卷、下载secret、获取容器和节点状态 等工作。kubelet将每个Pod转换成一组容器。</p><ul><li>kube-proxy</li></ul><p>在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作。</p><ul><li>docker或rocket</li></ul><p>容器引擎，运行容器。</p><h3 id="官方介绍"><a href="#官方介绍" class="headerlink" title="官方介绍"></a>官方介绍</h3><h4 id="kubelet简介"><a href="#kubelet简介" class="headerlink" title="kubelet简介"></a>kubelet简介</h4><p><a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kubelet/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kubelet/</a></p><h4 id="kube-apiserver简介"><a href="#kube-apiserver简介" class="headerlink" title="kube-apiserver简介"></a>kube-apiserver简介</h4><p><a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/</a></p><h4 id="kube-controller-manager简介"><a href="#kube-controller-manager简介" class="headerlink" title="kube-controller-manager简介"></a>kube-controller-manager简介</h4><p><a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-controller-manager/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-controller-manager/</a></p><h4 id="kube-proxy简介"><a href="#kube-proxy简介" class="headerlink" title="kube-proxy简介"></a>kube-proxy简介</h4><p><a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-proxy/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-proxy/</a></p><h4 id="kube-scheduler简介"><a href="#kube-scheduler简介" class="headerlink" title="kube-scheduler简介"></a>kube-scheduler简介</h4><p><a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-scheduler/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-scheduler/</a></p><h1 id="四、-Kubernetes将弃用Docker！"><a href="#四、-Kubernetes将弃用Docker！" class="headerlink" title="四、 Kubernetes将弃用Docker！"></a>四、 Kubernetes将弃用Docker！</h1><p>Kubernetes 计划弃用就是kubelet中dockershim。<br>即 Kubernetes kubelet 实现中的组件之一，它通过CRI（gRPC server服务）与 Docker Engine 进行通信。<br><img alt data-src="https://cdn.nlark.com/yuque/0/2021/png/22225794/1639993776152-f47ef4c0-dc16-4888-9ad9-d23260f331bf.png#clientId=u996f0f4d-7cea-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u06819e87&amp;margin=%5Bobject%20Object%5D&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u7bb83afe-cba1-40c9-b98b-08c5495ec6f&amp;title=" class="lozad"></p><h2 id="为什么这么做！"><a href="#为什么这么做！" class="headerlink" title="为什么这么做！"></a>为什么这么做！</h2><ul><li>Docker内部调用链比较复杂，多层封装和调用，导致性能降低、提升故障率、不易排查</li><li>Docker还会在宿主机创建网络规则、存储卷，也带来了安全隐患</li><li><p>说白了就是docker与kubernetes两家没有谈好合作</p><h2 id="如何应对？"><a href="#如何应对？" class="headerlink" title="如何应对？"></a>如何应对？</h2><p>利用containerd替换docker。<br>docker由 docker-client ,dockerd,containerd,docker-shim,runc组成，所以containerd是docker的基础组件之一。<br>下面是从containerd引过来的一张图<br><img alt data-src="https://cdn.nlark.com/yuque/0/2021/png/22225794/1639993776536-edc7af03-21d1-4201-b310-93c045558c75.png#clientId=u996f0f4d-7cea-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u3bf3cd12&amp;margin=%5Bobject%20Object%5D&amp;originHeight=1080&amp;originWidth=1782&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u568c4461-4585-4b9f-983a-6acf6d8bb8a&amp;title=" class="lozad"><br>从k8s的角度看，可以选择 containerd 或 docker 作为运行时组件：Containerd 调用链更短，组件更少，更稳定，占用节点资源更少，调用链：<br>Docker 作为 k8s 容器运行时，调用关系如下：<br>kubelet –&gt; docker shim （在 kubelet 进程中） –&gt; dockerd –&gt; containerd<br>Containerd 作为 k8s 容器运行时，调用关系如下：<br>kubelet –&gt; cri plugin（在 containerd 进程中） –&gt; containerd</p><h1 id="五、K8s-CNI网络模型"><a href="#五、K8s-CNI网络模型" class="headerlink" title="五、K8s CNI网络模型"></a>五、K8s CNI网络模型</h1><h2 id="两台Docker主机如何实现容器互通？"><a href="#两台Docker主机如何实现容器互通？" class="headerlink" title="两台Docker主机如何实现容器互通？"></a>两台Docker主机如何实现容器互通？</h2><p><img alt data-src="https://cdn.nlark.com/yuque/0/2021/png/22225794/1639993776595-9ad0d9fb-2258-4bc2-a366-4e80b87369c7.png#clientId=u996f0f4d-7cea-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;id=u90905945&amp;margin=%5Bobject%20Object%5D&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u67e794e0-1f03-48bb-9d84-e136b344335&amp;title=" class="lozad"><br><strong>K8s是一个扁平化网络。 </strong><br>即所有部署的网络组件都必须满足如下要求：</p></li><li><p>一个Pod一个IP</p></li><li>所有的 Pod 可以与任何其他 Pod 直接通信</li><li>所有节点可以与所有 Pod 直接通信</li><li>Pod 内部获取到的 IP 地址与其他 Pod 或节点与其通信时的 IP 地址是同一个</li></ul><p>主流网络组件有：<a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/networking/" target="_blank" rel="noopener">Flannel</a><a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/networking/" target="_blank" rel="noopener">、</a><a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/networking/" target="_blank" rel="noopener">Calico</a></p><h1 id="六、kubeconfig配置文件"><a href="#六、kubeconfig配置文件" class="headerlink" title="六、kubeconfig配置文件"></a>六、kubeconfig配置文件</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">deployment.kubernetes.io/revision:</span> <span class="string">"3"</span></span><br><span class="line">    <span class="string">field.cattle.io/creatorId:</span> <span class="string">user-m7jrz</span></span><br><span class="line">    <span class="string">field.cattle.io/publicEndpoints:</span> <span class="string">'[&#123;"addresses":["127.0.0.1"],"port":31006,"protocol":"TCP","serviceName":"test-namespace:monitor-server-nodeport","allNodes":true&#125;,&#123;"nodeName":"c-9fjs4:m-f8701cf4bd4f","addresses":["127.0.0.1"],"port":9095,"protocol":"TCP","podName":"test-namespace:monitor-server-6474776d76-4xxqm","allNodes":false&#125;]'</span></span><br><span class="line"><span class="attr">  creationTimestamp:</span> <span class="string">"2021-11-24T07:34:50Z"</span></span><br><span class="line"><span class="attr">  generation:</span> <span class="number">9</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">cattle.io/creator:</span> <span class="string">norman</span></span><br><span class="line">    <span class="string">workload.user.cattle.io/workloadselector:</span> <span class="string">deployment-test-namespace-monitor-server</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">monitor-server</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">test-namespace</span></span><br><span class="line"><span class="attr">  resourceVersion:</span> <span class="string">"16407952"</span></span><br><span class="line"><span class="attr">  selfLink:</span> <span class="string">/apis/apps/v1/namespaces/test-namespace/deployments/monitor-server</span></span><br><span class="line"><span class="attr">  uid:</span> <span class="number">11</span><span class="string">f6d174-9286-4eb8-855b-ec6039eccb85</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  progressDeadlineSeconds:</span> <span class="number">600</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  revisionHistoryLimit:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line">      <span class="string">workload.user.cattle.io/workloadselector:</span> <span class="string">deployment-test-namespace-monitor-server</span></span><br><span class="line"><span class="attr">  strategy:</span></span><br><span class="line"><span class="attr">    type:</span> <span class="string">Recreate</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line">        <span class="string">cattle.io/timestamp:</span> <span class="string">"2021-12-14T10:20:06Z"</span></span><br><span class="line">        <span class="string">field.cattle.io/ports:</span> <span class="string">'[[&#123;"containerPort":9095,"dnsName":"monitor-server-nodeport","hostPort":0,"kind":"NodePort","name":"monitor-server","protocol":"TCP","sourcePort":31006&#125;]]'</span></span><br><span class="line">        <span class="string">workload.cattle.io/state:</span> <span class="string">'&#123;"azhzLW1hc3Rlci0xNzIuMzEuMjAuMTcy":"c-9fjs4:m-f8701cf4bd4f"&#125;'</span></span><br><span class="line"><span class="attr">      creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line">        <span class="string">workload.user.cattle.io/workloadselector:</span> <span class="string">deployment-test-namespace-monitor-server</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - image:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:18089/whatever_pay/test/monitor:11</span></span><br><span class="line"><span class="attr">          imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">monitor-server</span></span><br><span class="line"><span class="attr">          ports:</span></span><br><span class="line"><span class="attr">            - containerPort:</span> <span class="number">9095</span></span><br><span class="line"><span class="attr">              hostPort:</span> <span class="number">9095</span></span><br><span class="line"><span class="attr">              name:</span> <span class="string">monitor-server</span></span><br><span class="line"><span class="attr">              protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">          resources:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">          securityContext:</span></span><br><span class="line"><span class="attr">            allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">            privileged:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">            readOnlyRootFilesystem:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">            runAsNonRoot:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">          stdin:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">          terminationMessagePath:</span> <span class="string">/dev/termination-log</span></span><br><span class="line"><span class="attr">          terminationMessagePolicy:</span> <span class="string">File</span></span><br><span class="line"><span class="attr">          tty:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">          volumeMounts:</span></span><br><span class="line"><span class="attr">            - mountPath:</span> <span class="string">/logs</span></span><br><span class="line"><span class="attr">              name:</span> <span class="string">vol1</span></span><br><span class="line"><span class="attr">      dnsConfig:</span></span><br><span class="line"><span class="attr">        nameservers:</span></span><br><span class="line"><span class="bullet">          -</span> <span class="number">8.8</span><span class="number">.8</span><span class="number">.8</span></span><br><span class="line"><span class="bullet">          -</span> <span class="number">144.144</span><span class="number">.144</span><span class="number">.144</span></span><br><span class="line"><span class="attr">      dnsPolicy:</span> <span class="string">ClusterFirst</span></span><br><span class="line"><span class="attr">      hostAliases:</span></span><br><span class="line"><span class="attr">        - hostnames:</span></span><br><span class="line"><span class="bullet">            -</span> <span class="string">k8s-master</span></span><br><span class="line"><span class="attr">          ip:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">      hostNetwork:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      nodeName:</span> <span class="string">k8s-master-127.0.0.1</span></span><br><span class="line"><span class="attr">      restartPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">      schedulerName:</span> <span class="string">default-scheduler</span></span><br><span class="line"><span class="attr">      securityContext:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - hostPath:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/datalogs/monitor-server</span></span><br><span class="line"><span class="attr">            type:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">vol1</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line"><span class="attr">  availableReplicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  conditions:</span></span><br><span class="line"><span class="attr">    - lastTransitionTime:</span> <span class="string">"2021-12-14T02:20:47Z"</span></span><br><span class="line"><span class="attr">      lastUpdateTime:</span> <span class="string">"2021-12-14T02:20:47Z"</span></span><br><span class="line"><span class="attr">      message:</span> <span class="string">Deployment</span> <span class="string">has</span> <span class="string">minimum</span> <span class="string">availability.</span></span><br><span class="line"><span class="attr">      reason:</span> <span class="string">MinimumReplicasAvailable</span></span><br><span class="line"><span class="attr">      status:</span> <span class="string">"True"</span></span><br><span class="line"><span class="attr">      type:</span> <span class="string">Available</span></span><br><span class="line"><span class="attr">    - lastTransitionTime:</span> <span class="string">"2021-11-24T07:34:50Z"</span></span><br><span class="line"><span class="attr">      lastUpdateTime:</span> <span class="string">"2021-12-14T02:20:47Z"</span></span><br><span class="line"><span class="attr">      message:</span> <span class="string">ReplicaSet</span> <span class="string">"monitor-server-6474776d76"</span> <span class="string">has</span> <span class="string">successfully</span> <span class="string">progressed.</span></span><br><span class="line"><span class="attr">      reason:</span> <span class="string">NewReplicaSetAvailable</span></span><br><span class="line"><span class="attr">      status:</span> <span class="string">"True"</span></span><br><span class="line"><span class="attr">      type:</span> <span class="string">Progressing</span></span><br><span class="line"><span class="attr">  observedGeneration:</span> <span class="number">9</span></span><br><span class="line"><span class="attr">  readyReplicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  updatedReplicas:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><h1 id="七、基本资源概念"><a href="#七、基本资源概念" class="headerlink" title="七、基本资源概念"></a>七、基本资源概念</h1><p><strong>Pod</strong>：K8s最小部署单元，一组容器的集合<br><strong>Deployment</strong>：最常见的控制器，用于更高级别部署和管理Pod<br><strong>Service</strong>：为一组Pod提供负载均衡，对外提供统一访问入口<br><strong>Label</strong> ：标签，附加到某个资源上，用于关联对象、查询和筛选<br><strong>Namespaces</strong> ：命名空间，将对象逻辑上隔离，也利于权限控制 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、了解基本知识&quot;&gt;&lt;a href=&quot;#一、了解基本知识&quot; class=&quot;headerlink&quot; title=&quot;一、了解基本知识&quot;&gt;&lt;/a&gt;一、了解基本知识&lt;/h1&gt;&lt;h2 id=&quot;官方网站&quot;&gt;&lt;a href=&quot;#官方网站&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="K8S" scheme="http://www.updatecg.xin/categories/K8S/"/>
    
    
      <category term="devOps" scheme="http://www.updatecg.xin/tags/devOps/"/>
    
      <category term="K8S" scheme="http://www.updatecg.xin/tags/K8S/"/>
    
  </entry>
  
  <entry>
    <title>部署一套单Master的K8s集群</title>
    <link href="http://www.updatecg.xin/2021/08/19/%E9%83%A8%E7%BD%B2%E4%B8%80%E5%A5%97%E5%8D%95Master%E7%9A%84K8s%E9%9B%86%E7%BE%A4/"/>
    <id>http://www.updatecg.xin/2021/08/19/部署一套单Master的K8s集群/</id>
    <published>2021-08-19T07:18:00.000Z</published>
    <updated>2021-12-29T03:06:08.635Z</updated>
    
    <content type="html"><![CDATA[<p>kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。</p><h2 id="安装要求"><a href="#安装要求" class="headerlink" title="安装要求"></a>安装要求</h2><p>在开始之前，部署Kubernetes集群机器需要满足以下几个条件：</p><ul><li>一台或多台机器，操作系统 CentOS7.x-86_x64</li><li>硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多</li><li>集群中所有机器之间网络互通</li><li>可以访问外网，需要拉取镜像</li><li>禁止swap分区</li></ul><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><p><img alt="kubernetes" data-src="https://blog-1252881505.cos.ap-beijing.myqcloud.com/k8s/single-master.jpg" class="lozad"></p><table><thead><tr><th>角色</th><th>IP</th></tr></thead><tbody><tr><td>k8s-master</td><td>192.168.31.61</td></tr><tr><td>k8s-node1</td><td>192.168.31.62</td></tr><tr><td>k8s-node2</td><td>192.168.31.63</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">关闭防火墙：</span><br><span class="line">$ systemctl stop firewalld</span><br><span class="line">$ systemctl disable firewalld</span><br><span class="line"></span><br><span class="line">关闭selinux：</span><br><span class="line">$ sed -i &apos;s/enforcing/disabled/&apos; /etc/selinux/config  # 永久</span><br><span class="line">$ setenforce 0  # 临时</span><br><span class="line"></span><br><span class="line">关闭swap：</span><br><span class="line">$ swapoff -a  # 临时</span><br><span class="line">$ sed -i &apos;/swap/s/^\(.*\)$/#\1/g&apos; /etc/fstab # 永久</span><br><span class="line"></span><br><span class="line">设置主机名：</span><br><span class="line">$ hostnamectl set-hostname &lt;hostname&gt;</span><br><span class="line"></span><br><span class="line">在master添加hosts：</span><br><span class="line">$ cat &gt;&gt; /etc/hosts &lt;&lt; EOF</span><br><span class="line">192.168.31.61 k8s-master</span><br><span class="line">192.168.31.62 k8s-node1</span><br><span class="line">192.168.31.63 k8s-node2</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">将桥接的IPv4流量传递到iptables的链：</span><br><span class="line">$ cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">$ sysctl --system  # 生效</span><br><span class="line"></span><br><span class="line">时间同步：</span><br><span class="line">$ yum install ntpdate -y</span><br><span class="line">$ ntpdate time.windows.com</span><br></pre></td></tr></table></figure><h2 id="安装Docker-kubeadm-kubelet【所有节点】"><a href="#安装Docker-kubeadm-kubelet【所有节点】" class="headerlink" title="安装Docker/kubeadm/kubelet【所有节点】"></a>安装Docker/kubeadm/kubelet【所有节点】</h2><p>Kubernetes默认CRI（容器运行时）为Docker，因此先安装Docker。</p><h3 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">$ yum -y install docker-ce</span><br><span class="line">$ systemctl enable docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure><p>配置镜像下载加速器：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat &gt; /etc/docker/daemon.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">$ systemctl restart docker</span><br><span class="line">$ docker info</span><br></pre></td></tr></table></figure><h3 id="添加阿里云YUM软件源"><a href="#添加阿里云YUM软件源" class="headerlink" title="添加阿里云YUM软件源"></a>添加阿里云YUM软件源</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="安装kubeadm，kubelet和kubectl"><a href="#安装kubeadm，kubelet和kubectl" class="headerlink" title="安装kubeadm，kubelet和kubectl"></a>安装kubeadm，kubelet和kubectl</h3><p>由于版本更新频繁，这里指定版本号部署：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ yum install -y kubelet-1.20.0 kubeadm-1.20.0 kubectl-1.20.0</span><br><span class="line">$ systemctl enable kubelet</span><br></pre></td></tr></table></figure><h2 id="部署Kubernetes-Master"><a href="#部署Kubernetes-Master" class="headerlink" title="部署Kubernetes Master"></a>部署Kubernetes Master</h2><p><a href="https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file</a></p><p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#initializing-your-control-plane-node" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#initializing-your-control-plane-node</a></p><p>在192.168.31.61（Master）执行。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubeadm init \</span><br><span class="line">  --apiserver-advertise-address=192.168.31.61 \</span><br><span class="line">  --image-repository registry.aliyuncs.com/google_containers \</span><br><span class="line">  --kubernetes-version v1.20.0 \</span><br><span class="line">  --service-cidr=10.96.0.0/12 \</span><br><span class="line">  --pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">  --ignore-preflight-errors=all</span><br></pre></td></tr></table></figure><ul><li>–apiserver-advertise-address 集群通告地址</li><li>–image-repository  由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址</li><li>–kubernetes-version K8s版本，与上面安装的一致</li><li>–service-cidr 集群内部虚拟网络，Pod统一访问入口</li><li>–pod-network-cidr Pod网络，，与下面部署的CNI网络组件yaml中保持一致</li></ul><p>或者使用配置文件引导：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ vi kubeadm.conf</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1.20.0</span><br><span class="line">imageRepository: registry.aliyuncs.com/google_containers </span><br><span class="line">networking:</span><br><span class="line">  podSubnet: 10.244.0.0/16 </span><br><span class="line">  serviceSubnet: 10.96.0.0/12 </span><br><span class="line"></span><br><span class="line">$ kubeadm init --config kubeadm.conf --ignore-preflight-errors=all</span><br></pre></td></tr></table></figure><p>拷贝kubectl使用的连接k8s认证文件到默认路径：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get nodes</span><br><span class="line">NAME               STATUS     ROLES            AGE   VERSION</span><br><span class="line">localhost.localdomain   NotReady   control-plane,master   20s   v1.20.0</span><br></pre></td></tr></table></figure><h2 id="加入Kubernetes-Node"><a href="#加入Kubernetes-Node" class="headerlink" title="加入Kubernetes Node"></a>加入Kubernetes Node</h2><p>在192.168.31.62/63（Node）执行。</p><p>向集群添加新节点，执行在kubeadm init输出的kubeadm join命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubeadm join 192.168.31.61:6443 --token 7gqt13.kncw9hg5085iwclx \</span><br><span class="line">--discovery-token-ca-cert-hash sha256:66fbfcf18649a5841474c2dc4b9ff90c02fc05de0798ed690e1754437be35a01</span><br></pre></td></tr></table></figure><p>默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，可以直接使用命令快捷生成：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure><p><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-join/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-join/</a></p><h2 id="部署容器网络（CNI）"><a href="#部署容器网络（CNI）" class="headerlink" title="部署容器网络（CNI）"></a>部署容器网络（CNI）</h2><p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network</a></p><p>注意：只需要部署下面其中一个，推荐Calico。</p><p>Calico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等。</p><p>Calico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。</p><p>此外，Calico  项目还实现了 Kubernetes 网络策略，提供ACL功能。</p><p><a href="https://docs.projectcalico.org/getting-started/kubernetes/quickstart" target="_blank" rel="noopener">https://docs.projectcalico.org/getting-started/kubernetes/quickstart</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ wget https://docs.projectcalico.org/manifests/calico.yaml</span><br></pre></td></tr></table></figure><p>下载完后还需要修改里面定义Pod网络（CALICO_IPV4POOL_CIDR），与前面kubeadm init指定的一样</p><p>修改完后应用清单：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl apply -f calico.yaml</span><br><span class="line">$ kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure><h2 id="测试kubernetes集群"><a href="#测试kubernetes集群" class="headerlink" title="测试kubernetes集群"></a>测试kubernetes集群</h2><ul><li>验证Pod工作</li><li>验证Pod网络通信</li><li>验证DNS解析</li></ul><p>在Kubernetes集群中创建一个pod，验证是否正常运行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl create deployment nginx --image=nginx</span><br><span class="line">$ kubectl expose deployment nginx --port=80 --type=NodePort</span><br><span class="line">$ kubectl get pod,svc</span><br></pre></td></tr></table></figure><p>访问地址：<a href="http://NodeIP:Port" target="_blank" rel="noopener">http://NodeIP:Port</a></p><h2 id="部署-Dashboard"><a href="#部署-Dashboard" class="headerlink" title="部署 Dashboard"></a>部署 Dashboard</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure><p>默认Dashboard只能集群内部访问，修改Service为NodePort类型，暴露到外部：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ vi recommended.yaml</span><br><span class="line">...</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">      nodePort: 30001</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">$ kubectl apply -f recommended.yaml</span><br><span class="line">$ kubectl get pods -n kubernetes-dashboard</span><br><span class="line">NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">dashboard-metrics-scraper-6b4884c9d5-gl8nr   1/1     Running   0          13m</span><br><span class="line">kubernetes-dashboard-7f99b75bf4-89cds        1/1     Running   0          13m</span><br></pre></td></tr></table></figure><p>访问地址：<a href="https://NodeIP:30001" target="_blank" rel="noopener">https://NodeIP:30001</a></p><p>创建service account并绑定默认cluster-admin管理员集群角色：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建用户</span><br><span class="line">$ kubectl create serviceaccount dashboard-admin -n kube-system</span><br><span class="line"># 用户授权</span><br><span class="line">$ kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin</span><br><span class="line"># 获取用户Token</span><br><span class="line">$ kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk &apos;/dashboard-admin/&#123;print $1&#125;&apos;)</span><br></pre></td></tr></table></figure><p>使用输出的token登录Dashboard。</p><h2 id="切换容器引擎为Containerd"><a href="#切换容器引擎为Containerd" class="headerlink" title="切换容器引擎为Containerd"></a>切换容器引擎为Containerd</h2><p><a href="https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#containerd" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#containerd</a></p><p>1、配置先决条件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo modprobe overlay</span><br><span class="line">sudo modprobe br_netfilter</span><br><span class="line"></span><br><span class="line"># 设置必需的 sysctl 参数，这些参数在重新启动后仍然存在。</span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># Apply sysctl params without reboot</span><br><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure><p>2、安装containerd</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">yum update -y &amp;&amp; sudo yum install -y containerd.io</span><br><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | sudo tee /etc/containerd/config.toml</span><br><span class="line">systemctl restart containerd</span><br></pre></td></tr></table></figure><p>3、修改配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi /etc/containerd/config.toml</span><br><span class="line">   [plugins.&quot;io.containerd.grpc.v1.cri&quot;]</span><br><span class="line">      sandbox_image = &quot;registry.aliyuncs.com/google_containers/pause:3.2&quot;  </span><br><span class="line">         ...</span><br><span class="line">         [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">             SystemdCgroup = true</span><br><span class="line">             ...</span><br><span class="line">        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;docker.io&quot;]</span><br><span class="line">          endpoint = [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span><br><span class="line">          </span><br><span class="line">systemctl restart containerd</span><br></pre></td></tr></table></figure><p>4、配置kubelet使用containerd</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi /etc/sysconfig/kubelet </span><br><span class="line">KUBELET_EXTRA_ARGS=--container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock --cgroup-driver=systemd</span><br><span class="line"></span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure><p>5、验证</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get node -o wide</span><br><span class="line"></span><br><span class="line">k8s-node1  xxx  containerd://1.4.4</span><br></pre></td></tr></table></figure><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">怎么查看容器日志？</span><br><span class="line">kubectl logs &lt;容器名称&gt; -n kube-system</span><br><span class="line"></span><br><span class="line">怎么查看容器事件？</span><br><span class="line">kubectl describe pod &lt;容器名称&gt; -n kube-system</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">calico无法拉取镜像解决办法？</span><br><span class="line"></span><br><span class="line">grep image calico.yaml</span><br><span class="line"></span><br><span class="line">image: calico/cni:v3.15.1</span><br><span class="line">image: calico/pod2daemon-flexvol:v3.15.1</span><br><span class="line">image: calico/node:v3.15.1</span><br><span class="line"></span><br><span class="line">docker pull xxx</span><br><span class="line">docker save calico/cni:v3.15.1 &gt; cni.tar</span><br><span class="line">docker load &lt; cni.tar</span><br><span class="line">kubectl delete -f calico.yaml</span><br><span class="line">kubectl apply -f calico.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">init失败或者情况环境可以使用：</span><br><span class="line">kubeadm reset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">为什么部署网络组件？</span><br><span class="line">Q1：每个docker主机创建的容器ip可能冲突?</span><br><span class="line">Q2：容器1访问容器2，容器1怎么知道容器2在哪个docker主机？</span><br><span class="line">Q3：容器1访问容器2数据包怎么传输过去？</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1、k8s现在可以使用docker嘛？</span><br><span class="line">可以。</span><br><span class="line">2、dockershim什么时候被移除？</span><br><span class="line">预计1.23版本。</span><br><span class="line">3、docker还值的学习嘛？</span><br><span class="line">值得。</span><br><span class="line"></span><br><span class="line">kubectl get pods --show-labels  # 查看资源标签</span><br><span class="line">kubectl get pod -l app=web  # 根据标签筛选资源</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。&lt;/p&gt;
&lt;h2 id=&quot;安装要求&quot;&gt;&lt;a href=&quot;#安装要求&quot; class=&quot;headerlink&quot; title=&quot;安装要求&quot;&gt;&lt;/a&gt;安装要求&lt;/h2&gt;&lt;p&gt;在开始之前，部署Kuberne
      
    
    </summary>
    
      <category term="K8S" scheme="http://www.updatecg.xin/categories/K8S/"/>
    
    
      <category term="devOps" scheme="http://www.updatecg.xin/tags/devOps/"/>
    
      <category term="K8S" scheme="http://www.updatecg.xin/tags/K8S/"/>
    
  </entry>
  
  <entry>
    <title>服务器load average异常</title>
    <link href="http://www.updatecg.xin/2021/08/06/%E6%9C%8D%E5%8A%A1%E5%99%A8load%20average%E5%BC%82%E5%B8%B8/"/>
    <id>http://www.updatecg.xin/2021/08/06/服务器load average异常/</id>
    <published>2021-08-06T07:18:00.000Z</published>
    <updated>2021-12-29T02:10:22.072Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>4核16G的设备，正常load average不大于4，表示系统一直处在负载状态，程序有异常。</p></blockquote><h2 id="每日服务器性能邮件告警"><a href="#每日服务器性能邮件告警" class="headerlink" title="每日服务器性能邮件告警"></a>每日服务器性能邮件告警</h2><p>4核16G的服务器，load率达到了 6.97, 6.70, 4.87.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">信息总览:</span><br><span class="line"></span><br><span class="line">CPU 内核：4核</span><br><span class="line"></span><br><span class="line">CPU load率： 6.97, 6.70, 4.87</span><br><span class="line"></span><br><span class="line">总内存：15.3 GiB    使用内存：4.7 GiB    剩余内存：10.600000000000001GiB</span><br><span class="line"></span><br><span class="line">TOP前5:</span><br><span class="line">     PID         %CPU    %MEM    VSZ          RSS             Name</span><br><span class="line">    2805176      59.9      6.3       7.6 GiB     986.2 MiB     java</span><br><span class="line">    2901828      13.1      5.4       4.1 GiB     847.4 MiB     java</span><br><span class="line">    3532650       4.5      4.7       3.9 GiB     740.9 MiB     java</span><br><span class="line">    3769112       3.0      4.2       5.5 GiB     657.7 MiB     java</span><br><span class="line">    1619371       0.7      1.3       6.6 GiB     204.8 MiB     java</span><br></pre></td></tr></table></figure></p><p>注意：CPU load率： 6.97, 6.70, 4.87。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。</p><h2 id="load高可能的一些原因"><a href="#load高可能的一些原因" class="headerlink" title="load高可能的一些原因"></a>load高可能的一些原因</h2><blockquote><p>系统load高通常都是由于某段发布的代码有bug或者引入某些第三方jar而又使用不合理导致的，因此注意首先区分load高，是由于cpu高导致的还是io高导致的，根据不同的场景采取不同定位问题的方式。</p><ul><li>死循环或者不合理的大量循环操作，如果不是循环操作，按照现代cpu的处理速度来说处理一大段代码也就一会会儿的事，基本对能力无消耗</li><li>频繁的YoungGC</li><li>频繁的FullGC</li><li>高磁盘IO</li><li>高网络IO</li></ul></blockquote><p>当束手无策时，jmap打印堆栈文件多分析分析吧，或许能灵光一现能找到错误原因。</p><h2 id="发现YongGC块，FullGC也快，注定有问题"><a href="#发现YongGC块，FullGC也快，注定有问题" class="headerlink" title="发现YongGC块，FullGC也快，注定有问题"></a>发现YongGC块，FullGC也快，注定有问题</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jstat -gcutil pid 100</span><br></pre></td></tr></table></figure><p><img alt data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/load_4.png" class="lozad"></p><p>可以看出行O也一直在增加，几乎99，速度很快，老年代一下就满了，立马执行了YongGC,然后进入FGC的速度也快，2天就525了。</p><h2 id="进一步排查获取dump文件"><a href="#进一步排查获取dump文件" class="headerlink" title="进一步排查获取dump文件"></a>进一步排查获取dump文件</h2><p>通过命令抓取dump文件，进行分析。<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jmap -dump:format=b,file=1.hprof pid</span><br></pre></td></tr></table></figure></p><h2 id="分析dump文件"><a href="#分析dump文件" class="headerlink" title="分析dump文件"></a>分析dump文件</h2><blockquote><p>通过JProfiler分析1.hprof文件</p></blockquote><p><img alt data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/load_average_hprof.jpg" class="lozad"><br><img alt data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/load_2.jpg" class="lozad"><br><img alt data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/load_3.jpg" class="lozad"><br>上述分析结果可以直观的看出，创建的对象线程非常多，并且一直在加，释放很慢。</p><h2 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h2><blockquote><p>发现程序确实有类似代码<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Provide a new ScheduledExecutorService instance.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;A shutdown hook is created to terminate the thread pool on application termination.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> new ScheduledExecutorService</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ScheduledExecutorService <span class="title">defaultExecutorService</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ScheduledExecutorService scheduledExecutorService =</span><br><span class="line">            Executors.newScheduledThreadPool(getCpuCount());</span><br><span class="line"></span><br><span class="line">    Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread(() -&gt; shutdown(scheduledExecutorService)));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> scheduledExecutorService;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><p>因为此方法是通过一个业务定时器在轮序，2秒一次，每次都去执行了一次，所以造成了内存不足，load值增加，系统负载增加。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><h3 id="代码解决"><a href="#代码解决" class="headerlink" title="代码解决"></a>代码解决</h3><p>程序改用单例模式，静态方法，执行一次就行。</p><h3 id="jvm调优优化"><a href="#jvm调优优化" class="headerlink" title="jvm调优优化"></a>jvm调优优化</h3><ul><li>-XX：MaxTenuringThreshold</li><li>-XX：+ UseConcMarkSweepGC</li><li>-XX：CMSFullGCsBeforeCompaction<br>具体参数详情请参考<a href="http://www.updatecg.xin/2019/01/24/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0/#%E5%A0%86%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%8F%82%E6%95%B0">[性能调优参数]</a></li></ul><h4 id="调优案例"><a href="#调优案例" class="headerlink" title="调优案例"></a>调优案例</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-XX:MaxTenuringThreshold=0 -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=0</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;4核16G的设备，正常load average不大于4，表示系统一直处在负载状态，程序有异常。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;每日服务器性能邮件告警&quot;&gt;&lt;a href=&quot;#每日服务器性能邮件告警&quot; class=&quot;headerl
      
    
    </summary>
    
      <category term="现网" scheme="http://www.updatecg.xin/categories/%E7%8E%B0%E7%BD%91/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
      <category term="JVM" scheme="http://www.updatecg.xin/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>服务无缘无故宕机</title>
    <link href="http://www.updatecg.xin/2020/06/20/%E6%9C%8D%E5%8A%A1%E6%97%A0%E7%BC%98%E6%97%A0%E6%95%85%E5%AE%95%E6%9C%BA/"/>
    <id>http://www.updatecg.xin/2020/06/20/服务无缘无故宕机/</id>
    <published>2020-06-20T07:18:00.000Z</published>
    <updated>2021-08-19T08:56:30.681Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>定时服务无缘无故宕机了，服务相关日志没有任何错误日志。<br>首先报告领导<br>恢复业务<br>排查问题<br>监控服务</p></blockquote><h2 id="服务宕机了"><a href="#服务宕机了" class="headerlink" title="服务宕机了"></a>服务宕机了</h2><p>因服务没有监控，导致服务宕机没有发现，还是通过统计数据异常发现问题，立马去查看log日志。。。<br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/20200601.png" class="lozad"></p><ul><li>很奇怪项目日志没有任何error日志，大大的加深了问题排查。</li></ul><h2 id="查看jvm错误日志hs-err-pid-log，JVM-crash信息，我们可以通过分析该文件定位到导致-JVM-Crash-的原因，从而修复保证系统稳定"><a href="#查看jvm错误日志hs-err-pid-log，JVM-crash信息，我们可以通过分析该文件定位到导致-JVM-Crash-的原因，从而修复保证系统稳定" class="headerlink" title="查看jvm错误日志hs_err_pid*.log，JVM crash信息，我们可以通过分析该文件定位到导致 JVM Crash 的原因，从而修复保证系统稳定"></a>查看jvm错误日志hs_err_pid<strong>*</strong>.log，JVM crash信息，我们可以通过分析该文件定位到导致 JVM Crash 的原因，从而修复保证系统稳定</h2><h3 id="日志头"><a href="#日志头" class="headerlink" title="日志头"></a>日志头</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#</span><br><span class="line"># There is insufficient memory for the Java Runtime Environment to continue.</span><br><span class="line"># Native memory allocation (mmap) failed to map 12288 bytes for committing reserved memory.</span><br><span class="line"># Possible reasons:</span><br><span class="line">#   The system is out of physical RAM or swap space</span><br><span class="line">#   In 32 bit mode, the process size limit was hit</span><br><span class="line"># Possible solutions:</span><br><span class="line">#   Reduce memory load on the system</span><br><span class="line">#   Increase physical memory or swap space</span><br><span class="line">#   Check if swap backing store is full</span><br><span class="line">#   Use 64 bit Java on a 64 bit OS</span><br><span class="line">#   Decrease Java heap size (-Xmx/-Xms)</span><br><span class="line">#   Decrease number of Java threads</span><br><span class="line">#   Decrease Java thread stack sizes (-Xss)</span><br><span class="line">#   Set larger code cache with -XX:ReservedCodeCacheSize=</span><br><span class="line"># This output file may be truncated or incomplete.</span><br><span class="line">#</span><br><span class="line">#  Out of Memory Error (os_linux.cpp:2640), pid=114181, tid=0x00007f9340e91700</span><br><span class="line">#</span><br><span class="line"># JRE version: Java(TM) SE Runtime Environment (8.0_171-b11) (build 1.8.0_171-b11)</span><br><span class="line"># Java VM: Java HotSpot(TM) 64-Bit Server VM (25.171-b11 mixed mode linux-amd64 compressed oops)</span><br><span class="line"># Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again</span><br><span class="line">#</span><br></pre></td></tr></table></figure><ul><li>Native memory allocation (mmap) failed to map 12288 bytes for committing reserved memory.<ul><li>减小thread stack的大小</li><li>线程数在3000~5000左右需要注意，JVM默认thread stack（-Xss）的大小为1024,这样当线程多时导致Native virtual memory被耗尽，实际上当thread stack的大小为128K 或 256K时是足够的，所以我们如果明确指定thread stack为128K 或 256K即可，具体使用-Xss</li></ul></li><li>Out of Memory Error (os_linux.cpp:2640), pid=114181, tid=0x00007f9340e91700<ul><li>日志头可清晰看出<span style="font-weight:bold;color:red">Out of Memory Error</span>-内存不足。</li><li>liunx64位解决优化方案<ul><li>减少Java堆大小（-Xmx / -Xms）</li><li>减少Java线程数（从业务出发）</li><li>减少Java线程堆栈大小（-Xss）</li><li>使用-XX：ReservedCodeCacheSize =设置更大的代码缓存</li></ul></li></ul></li></ul><h3 id="堆栈信息"><a href="#堆栈信息" class="headerlink" title="堆栈信息"></a>堆栈信息</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---------------  P R O C E S S  ---------------</span><br><span class="line"></span><br><span class="line">Java Threads: ( =&gt; current thread )</span><br><span class="line">=&gt;0x00007f9b9447d800 JavaThread &quot;pool-32458-thread-1&quot; [_thread_new, id=2337, stack(0x00007f9340d91000,0x00007f9340e92000)]</span><br><span class="line">  0x00007f9b8c471000 JavaThread &quot;pool-32456-thread-1&quot; [_thread_blocked, id=2336, stack(0x00007f932a62b000,0x00007f932a72c000)]</span><br><span class="line">  0x00007f9ba44a4000 JavaThread &quot;pool-32455-thread-1&quot; [_thread_blocked, id=2330, stack(0x00007f932a72c000,0x00007f932a82d000)]</span><br><span class="line">  0x00007f9b745ed800 JavaThread &quot;pool-32454-thread-1&quot; [_thread_blocked, id=2319, stack(0x00007f932a82d000,0x00007f932a92e000)]</span><br><span class="line">  0x00007f9b7862a000 JavaThread &quot;pool-32453-thread-1&quot; [_thread_blocked, id=2318, stack(0x00007f932a92e000,0x00007f932aa2f000)]</span><br><span class="line">  0x00007f9b6c5cd800 JavaThread &quot;pool-32452-thread-1&quot; [_thread_blocked, id=2302, stack(0x00007f932aa2f000,0x00007f932ab30000)]</span><br><span class="line">  0x00007f9b98bf0000 JavaThread &quot;pool-32451-thread-1&quot; [_thread_blocked, id=2297, stack(0x00007f932ab30000,0x00007f932ac31000)]</span><br><span class="line">  0x00007f9b44633000 JavaThread &quot;Keep-Alive-Timer&quot; daemon [_thread_blocked, id=2285, stack(0x00007f9330e93000,0x00007f9330f94000)]</span><br><span class="line">  0x00007f9b6450b000 JavaThread &quot;pool-32450-thread-1&quot; [_thread_blocked, id=2187, stack(0x00007f932ac31000,0x00007f932ad32000)]</span><br><span class="line">  0x00007f9b9447b000 JavaThread &quot;pool-32449-thread-1&quot; [_thread_blocked, id=2159, stack(0x00007f932ad32000,0x00007f932ae33000)]</span><br><span class="line">  0x00007f9b8c46f000 JavaThread &quot;pool-32448-thread-1&quot; [_thread_blocked, id=2100, stack(0x00007f932ae33000,0x00007f932af34000)]</span><br><span class="line">  0x00007f9b8059b800 JavaThread &quot;pool-32447-thread-1&quot; [_thread_blocked, id=2068, stack(0x00007f932af34000,0x00007f932b035000)]</span><br><span class="line">  0x00007f9ba44a2000 JavaThread &quot;pool-32446-thread-1&quot; [_thread_blocked, id=1895, stack(0x00007f932b035000,0x00007f932b136000)]</span><br><span class="line">  0x00007f9b745eb000 JavaThread &quot;pool-32445-thread-1&quot; [_thread_blocked, id=1865, stack(0x00007f932b136000,0x00007f932b237000)]</span><br><span class="line">  0x00007f9b78628000 JavaThread &quot;pool-32444-thread-1&quot; [_thread_blocked, id=1864, stack(0x00007f932b237000,0x00007f932b338000)]</span><br><span class="line">  0x00007f9b6c5cb800 JavaThread &quot;pool-32443-thread-1&quot; [_thread_blocked, id=1854, stack(0x00007f932b338000,0x00007f932b439000)]</span><br><span class="line">  0x00007f9b98bed800 JavaThread &quot;pool-32442-thread-1&quot; [_thread_blocked, id=1850, stack(0x00007f932b439000,0x00007f932b53a000)]</span><br><span class="line">  0x00007f9b64508800 JavaThread &quot;pool-32441-thread-1&quot; [_thread_blocked, id=1849, stack(0x00007f932b53a000,0x00007f932b63b000)]</span><br><span class="line">  0x00007f9b94479000 JavaThread &quot;pool-32440-thread-1&quot; [_thread_blocked, id=1835, stack(0x00007f932b63b000,0x00007f932b73c000)]</span><br><span class="line">  0x00007f9b8c46d000 JavaThread &quot;pool-32439-thread-1&quot; [_thread_blocked, id=1832, stack(0x00007f932b73c000,0x00007f932b83d000)]</span><br><span class="line">  0x00007f9b80599000 JavaThread &quot;pool-32438-thread-1&quot; [_thread_blocked, id=1729, stack(0x00007f932b83d000,0x00007f932b93e000)]</span><br><span class="line">  0x00007f9ba449f800 JavaThread &quot;pool-32437-thread-1&quot; [_thread_blocked, id=1657, stack(0x00007f932b93e000,0x00007f932ba3f000)]</span><br><span class="line">  0x00007f9b78625800 JavaThread &quot;pool-32436-thread-1&quot; [_thread_blocked, id=1412, stack(0x00007f932ba3f000,0x00007f932bb40000)]</span><br><span class="line">  0x00007f9b54782000 JavaThread &quot;pool-32435-thread-1&quot; [_thread_blocked, id=1183, stack(0x00007f932bb40000,0x00007f932bc41000)]</span><br><span class="line">  0x00007f9b486df800 JavaThread &quot;pool-32434-thread-1&quot; [_thread_blocked, id=1182, stack(0x00007f932bc41000,0x00007f932bd42000)]</span><br><span class="line">  0x00007f9b44631000 JavaThread &quot;pool-2-thread-16487&quot; [_thread_blocked, id=1180, stack(0x00007f932bd42000,0x00007f932be43000)]</span><br><span class="line">  0x00007f9b4462f000 JavaThread &quot;pool-2-thread-16486&quot; [_thread_blocked, id=1177, stack(0x00007f932be43000,0x00007f932bf44000)]</span><br><span class="line">  0x0000000001d29800 JavaThread &quot;pool-32433-thread-1&quot; [_thread_blocked, id=1176, stack(0x00007f932bf44000,0x00007f932c045000)]</span><br><span class="line">  0x00007f9c5458a800 JavaThread &quot;pool-32432-thread-1&quot; [_thread_blocked, id=1175, stack(0x00007f932c045000,0x00007f932c146000)]</span><br><span class="line">  0x00007f9b4462d000 JavaThread &quot;pool-2-thread-16485&quot; [_thread_blocked, id=1174, stack(0x00007f932c146000,0x00007f932c247000)]</span><br><span class="line">  0x00007f9c4465c800 JavaThread &quot;pool-32431-thread-1&quot; [_thread_blocked, id=1173, stack(0x00007f932c247000,0x00007f932c348000)]</span><br></pre></td></tr></table></figure><ul><li>JAVA线程堆栈，发现堆栈里面大量的pool的线程池，blocked阻塞线程高达32458个，这就是根本原因，每执行一个就创建。</li><li>误用JAVA线程池，每次用都新new一个线程池newSingleThreadScheduledExecutor</li><li>确实每次new会占用堆外堆存，没有跟踪到底层，但是线程池是管理线程的，虚拟机线程肯定是要跟OS申请线程资源的，linux中线程作为轻量进程，每fork一个肯定会占用OS的资源，相对于java虚拟机堆内内存来说，即是占用了堆外内存；而虚拟机本身由于线程池不释放，老生代会一直缓慢增加，但是没有堆外内存那么厉害，当老生代一直增加到100%后，虚拟机本身会报内存溢出。而操作系统层面，由于大量VIRT被占用，就连简单的top有时也会因为没有办法分配内存而执行不了</li></ul><p><a href="https://updatecg.oss-cn-beijing.aliyuncs.com/hs_err_pid114181.log" target="_blank" rel="noopener">[hs_err_pid文件]</a></p><h3 id="优化方案"><a href="#优化方案" class="headerlink" title="优化方案"></a>优化方案</h3><ul><li>线程池用完了必须shutdown()。</li><li>避免一直new创建新的线程池。</li><li>服务总内存16G，此服务启动设置了2G，增大了最大内存至3G，设置堆栈大小256K。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;定时服务无缘无故宕机了，服务相关日志没有任何错误日志。&lt;br&gt;首先报告领导&lt;br&gt;恢复业务&lt;br&gt;排查问题&lt;br&gt;监控服务&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;服务宕机了&quot;&gt;&lt;a href=&quot;#服务宕机了&quot; class=&quot;heade
      
    
    </summary>
    
      <category term="现网" scheme="http://www.updatecg.xin/categories/%E7%8E%B0%E7%BD%91/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
      <category term="JVM" scheme="http://www.updatecg.xin/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>JDK8之HashMap源码刨析实现原理</title>
    <link href="http://www.updatecg.xin/2020/03/01/HashMap/"/>
    <id>http://www.updatecg.xin/2020/03/01/HashMap/</id>
    <published>2020-03-01T02:05:02.000Z</published>
    <updated>2021-12-29T02:27:16.219Z</updated>
    
    <content type="html"><![CDATA[<h2 id="HashMap源码刨析"><a href="#HashMap源码刨析" class="headerlink" title="HashMap源码刨析"></a>HashMap源码刨析</h2><blockquote><p>Map接口的基于哈希表的实现。</p></blockquote><p><a href="https://blog.csdn.net/qq_37113604/article/details/81353626" target="_blank" rel="noopener">此文章参考连接</a></p><h3 id="官网解释"><a href="#官网解释" class="headerlink" title="官网解释"></a>官网解释</h3><p><img alt data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/hashMap.png" class="lozad"></p><h3 id="剖析解析"><a href="#剖析解析" class="headerlink" title="剖析解析"></a>剖析解析</h3><h3 id="重点一"><a href="#重点一" class="headerlink" title="重点一"></a>重点一</h3><blockquote><p>默认初始容量 (16) 和默认负载因子 (0.75) 的空HashMap,最大容量，在两个带参数的构造函数中的任何一个隐式指定更高的值时使用。 必须是 2 的幂 &lt;= 1&lt;&lt;30 (1073741824)。</p></blockquote><h4 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">*最大容量，在两个带参数的构造函数中的任何一个隐式指定更高的值时使用。 必须是 2 的幂 &lt;= 1&lt;&lt;30。</span></span><br><span class="line"><span class="comment">*/</span> </span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 构造一个具有指定初始容量和负载因子的空HashMap 。</span></span><br><span class="line"><span class="comment"> * 参数：</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * initialCapacity – 初始容量</span></span><br><span class="line"><span class="comment"> * loadFactor – 负载因子</span></span><br><span class="line"><span class="comment"> * 抛出：</span></span><br><span class="line"><span class="comment"> * IllegalArgumentException – 如果初始容量为负或负载因子为非正</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//初始容量小于0，则抛出异常</span></span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal initial capacity: "</span> +</span><br><span class="line">                                           initialCapacity);</span><br><span class="line">    <span class="comment">//初始容量最大MAXIMUM_CAPACITY</span></span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">        initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line">    <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal load factor: "</span> +</span><br><span class="line">                                           loadFactor);</span><br><span class="line">    <span class="keyword">this</span>.loadFactor = loadFactor;</span><br><span class="line">    <span class="keyword">this</span>.threshold = tableSizeFor(initialCapacity);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 实现了把一个数变为最接近的2的n次方</span></span><br><span class="line"><span class="comment"> * 如果传入A，当A大于0，小于定义的最大容量时，</span></span><br><span class="line"><span class="comment"> * 如果A是2次幂则返回A，否则将A转化为一个比A大且差距最小的2次幂。  </span></span><br><span class="line"><span class="comment"> * 例如传入7返回8，传入8返回8，传入9返回16</span></span><br><span class="line"><span class="comment"> * cap=7 代码逻辑如下</span></span><br><span class="line"><span class="comment"> * n|=n代表或运算 0对应0则是0 否则1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">tableSizeFor</span><span class="params">(<span class="keyword">int</span> cap)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n = cap - <span class="number">1</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">1</span>; <span class="comment">//n|(n&gt;&gt;&gt;1)  6|6&gt;&gt;&gt;1   00000110|00000110&gt;&gt;&gt;1  00000110|00000011 =00000111  n=7</span></span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">2</span>; <span class="comment">//n|(n&gt;&gt;&gt;2)  7|7&gt;&gt;&gt;2   00000111|00000111&gt;&gt;&gt;2  00000111|00000001 =00000111  n=7</span></span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">4</span>; <span class="comment">//n|(n&gt;&gt;&gt;4)  7|7&gt;&gt;&gt;4   00000111|00000111&gt;&gt;&gt;4  00000111|00000000 =00000111  n=7</span></span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">8</span>; <span class="comment">//n|(n&gt;&gt;&gt;8)  7|7&gt;&gt;&gt;8   00000111|00000111&gt;&gt;&gt;8  00000111|00000000 =00000111  n=7</span></span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">16</span>;<span class="comment">//n|(n&gt;&gt;&gt;16) 7|7&gt;&gt;&gt;16  00000111|00000111&gt;&gt;&gt;16 00000111|00000000 =00000111  n=7</span></span><br><span class="line">    <span class="comment">//(n &lt; 0) =false</span></span><br><span class="line">    <span class="comment">//(n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1</span></span><br><span class="line">    <span class="comment">//(n &gt;= 1&lt;&lt;30) n&gt;=1073741824 = false</span></span><br><span class="line">    <span class="comment">//false 得 n+1 = 8</span></span><br><span class="line">    <span class="keyword">return</span> (n &lt; <span class="number">0</span>) ? <span class="number">1</span> : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="核心函数put函数"><a href="#核心函数put函数" class="headerlink" title="核心函数put函数"></a>核心函数put函数</h4><h5 id="put函数"><a href="#put函数" class="headerlink" title="put函数"></a>put函数</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * put函数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> putVal(hash(key), key, value, <span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 获取hash值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> h;</span><br><span class="line">    <span class="comment">//^异或运算：相同置0，不同置1</span></span><br><span class="line">    <span class="keyword">return</span> (key == <span class="keyword">null</span>) ? <span class="number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="为什么要右移16位"><a href="#为什么要右移16位" class="headerlink" title="为什么要右移16位?"></a>为什么要右移16位?</h6><ul><li>保证高16位也参与计算， 我们直到int占4字节 32位，16是中位数</li><li>因为大部分情况下，都是低16位参与运算，高16位可以减少hash冲突<h5 id="putVal函数"><a href="#putVal函数" class="headerlink" title="putVal函数"></a>putVal函数</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 表，在第一次使用时初始化，并根据需要调整大小。 分配时，长度始终是 2 的幂。 （我们还在某些操作中容忍长度为零，以允许当前不需要的引导机制。）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">transient</span> Node&lt;K,V&gt;[] table;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用树而不是列表的 bin 计数阈值。 将元素添加到至少具有这么多节点的 bin 时，bin 会转换为树。 该值必须大于 2 且至少应为 8，以与树移除中关于在收缩时转换回普通 bin 的假设相匹配。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建新的node</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">Node&lt;K,V&gt; <span class="title">newNode</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, Node&lt;K,V&gt; next)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Node&lt;&gt;(hash, key, value, next);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 参数：</span></span><br><span class="line"><span class="comment"> *   hash – 密钥的散列</span></span><br><span class="line"><span class="comment"> *   value – 要放置的值</span></span><br><span class="line"><span class="comment"> *   onlyIfAbsent – 如果为真，则不更改现有值</span></span><br><span class="line"><span class="comment"> *   evict – 如果为 false，则表处于创建模式。</span></span><br><span class="line"><span class="comment"> * 返回：</span></span><br><span class="line"><span class="comment"> *   以前的值，如果没有，则为 null</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">boolean</span> onlyIfAbsent,<span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="keyword">int</span> n, i;</span><br><span class="line">    <span class="comment">//1、如果主干tab等于null或者tab长度为0 则调用resize()方法获取长度。</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)</span><br><span class="line">        n = (tab = resize()).length;</span><br><span class="line">    <span class="comment">//2、数组长度与计算得出的hash进行比较</span></span><br><span class="line">    <span class="keyword">if</span> ((p = tab[i = (n - <span class="number">1</span>) &amp; hash]) == <span class="keyword">null</span>)<span class="comment">//如果位置空，则将i位置值赋值给新的一个node对象</span></span><br><span class="line">        tab[i] = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">    <span class="keyword">else</span> &#123;<span class="comment">//3、位置不为空</span></span><br><span class="line">        Node&lt;K,V&gt; e; K k;</span><br><span class="line">        <span class="keyword">if</span> (p.hash == hash &amp;&amp;<span class="comment">//4、p旧节点与新添加元素完相同</span></span><br><span class="line">            ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            e = p;<span class="comment">//则将旧节点赋值给新节点</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)<span class="comment">//5、如果p已经是树节点的一个实例，既这里已经是树了</span></span><br><span class="line">            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(<span class="keyword">this</span>, tab, hash, key, value);</span><br><span class="line">        <span class="keyword">else</span> &#123;<span class="comment">//p旧节点与e新节点完全不相同，p也不是树节点treenode实例</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> binCount = <span class="number">0</span>; ; ++binCount) &#123;<span class="comment">//死循环</span></span><br><span class="line">                <span class="keyword">if</span> ((e = p.next) == <span class="keyword">null</span>) &#123;<span class="comment">//e新节点=p旧节点.next下一个节点等于空</span></span><br><span class="line">                    p.next = newNode(hash, key, value, <span class="keyword">null</span>);<span class="comment">//则赋值新的节点</span></span><br><span class="line">                    <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="number">1</span>) <span class="comment">// 如果链表长度大于等于8</span></span><br><span class="line">                        treeifyBin(tab, hash);<span class="comment">//将链表转为红黑树</span></span><br><span class="line">                    <span class="keyword">break</span>;<span class="comment">//跳出循环</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//如果遍历过程中链表中的元素与新添加的元素完全相同，则跳出循环</span></span><br><span class="line">                <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">                    ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                    <span class="keyword">break</span>;<span class="comment">//跳出循环</span></span><br><span class="line">                p = e;<span class="comment">//则将遍历节点元素赋值给新节点</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; <span class="comment">//这个判断中代码作用为：如果添加的元素产生了hash冲突，那么调用</span></span><br><span class="line">            V oldValue = e.value;</span><br><span class="line">            <span class="keyword">if</span> (!onlyIfAbsent || oldValue == <span class="keyword">null</span>)</span><br><span class="line">                e.value = value;</span><br><span class="line">            afterNodeAccess(e);</span><br><span class="line">            <span class="keyword">return</span> oldValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ++modCount;</span><br><span class="line">    <span class="keyword">if</span> (++size &gt; threshold)<span class="comment">//如果元素数量大于临界值，则进行扩容</span></span><br><span class="line">        resize();</span><br><span class="line">    afterNodeInsertion(evict);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h6 id="为什么会考虑红黑树？"><a href="#为什么会考虑红黑树？" class="headerlink" title="为什么会考虑红黑树？"></a>为什么会考虑红黑树？</h6><p>链表过长则使用红黑树，提高查找性能。</p><h6 id="HashMap链表转红黑树为什么是8？"><a href="#HashMap链表转红黑树为什么是8？" class="headerlink" title="HashMap链表转红黑树为什么是8？"></a>HashMap链表转红黑树为什么是8？</h6><p>对此源码也做了解释。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">* Because TreeNodes are about twice the size of regular nodes, we</span><br><span class="line">* use them only when bins contain enough nodes to warrant use</span><br><span class="line">* (see TREEIFY_THRESHOLD). <span class="function">And when they become too <span class="title">small</span> <span class="params">(due to</span></span></span><br><span class="line"><span class="function"><span class="params">* removal or resizing)</span> they are converted back to plain bins.  In</span></span><br><span class="line"><span class="function">* usages with well-distributed user hashCodes, tree bins are</span></span><br><span class="line"><span class="function">* rarely used.  Ideally, under random hashCodes, the frequency of</span></span><br><span class="line"><span class="function">* nodes in bins follows a Poisson distribution</span></span><br><span class="line"><span class="function">* <span class="params">(http://en.wikipedia.org/wiki/Poisson_distribution)</span> with a</span></span><br><span class="line"><span class="function">* parameter of about 0.5 on average <span class="keyword">for</span> the <span class="keyword">default</span> resizing</span></span><br><span class="line"><span class="function">* threshold of 0.75, although with a large variance because of</span></span><br><span class="line"><span class="function">* resizing granularity. Ignoring variance, the expected</span></span><br><span class="line"><span class="function">* occurrences of list size k <span class="title">are</span> <span class="params">(exp(<span class="number">-0.5</span>)</span> * <span class="title">pow</span><span class="params">(<span class="number">0.5</span>, k)</span> /</span></span><br><span class="line"><span class="function">* <span class="title">factorial</span><span class="params">(k)</span>). The first values are:</span></span><br><span class="line"><span class="function">*</span></span><br><span class="line"><span class="function">* 0:    0.60653066</span></span><br><span class="line"><span class="function">* 1:    0.30326533</span></span><br><span class="line"><span class="function">* 2:    0.07581633</span></span><br><span class="line"><span class="function">* 3:    0.01263606</span></span><br><span class="line"><span class="function">* 4:    0.00157952</span></span><br><span class="line"><span class="function">* 5:    0.00015795</span></span><br><span class="line"><span class="function">* 6:    0.00001316</span></span><br><span class="line"><span class="function">* 7:    0.00000094</span></span><br><span class="line"><span class="function">* 8:    0.00000006</span></span><br><span class="line"><span class="function">* more: less than 1 in ten million</span></span><br></pre></td></tr></table></figure></p><p>上面这段话的意思是，如果 hashCode 分布良好，也就是 hash 计算的结果离散好的话，那么红黑树这种形式是很少会被用到的，因为各个值都均匀分布，很少出现链表很长的情况。在理想情况下，链表长度符合泊松分布，各个长度的命中概率依次递减，当长度为 8 的时候，概率仅为 0.00000006。这是一个小于千万分之一的概率，通常我们的 Map 里面是不会存储这么多的数据的，所以通常情况下，并不会发生从链表向红黑树的转换。<br><a href="https://blog.csdn.net/kyle_wu_/article/details/113578055" target="_blank" rel="noopener">此问题参考连接</a></p><h5 id="resize扩容函数（源码详解）"><a href="#resize扩容函数（源码详解）" class="headerlink" title="resize扩容函数（源码详解）"></a>resize扩容函数（源码详解）</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">//2的幂数</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//要调整大小的下一个大小值（容量 * 负载因子）。</span></span><br><span class="line"><span class="keyword">int</span> threshold;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> Node&lt;K,V&gt;[] resize() &#123;</span><br><span class="line">       <span class="comment">//主干table赋值给oldTab   </span></span><br><span class="line">       Node&lt;K,V&gt;[] oldTab = table;</span><br><span class="line">       <span class="comment">//获取原哈希表容量  如果哈希表为空则容量为0 ，否则为原哈希表长度</span></span><br><span class="line">       <span class="keyword">int</span> oldCap = (oldTab == <span class="keyword">null</span>) ? <span class="number">0</span> : oldTab.length;</span><br><span class="line">       <span class="comment">//获取原生的扩容标准（容量16 * 负载因子0.75）</span></span><br><span class="line">       <span class="keyword">int</span> oldThr = threshold;</span><br><span class="line">       <span class="comment">//初始化新容量和新扩容门槛为0</span></span><br><span class="line">       <span class="keyword">int</span> newCap, newThr = <span class="number">0</span>;</span><br><span class="line">       <span class="keyword">if</span> (oldCap &gt; <span class="number">0</span>) &#123;</span><br><span class="line">           <span class="keyword">if</span> (oldCap &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">               threshold = Integer.MAX_VALUE;<span class="comment">//当容量超过最大值时，临界值设置成int最大值</span></span><br><span class="line">               <span class="keyword">return</span> oldTab;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">else</span> <span class="keyword">if</span> ((newCap = oldCap &lt;&lt; <span class="number">1</span>) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY)<span class="comment">//未达到1&lt;&lt;30，则进行扩容操作</span></span><br><span class="line">               newThr = oldThr &lt;&lt; <span class="number">1</span>; <span class="comment">// 容量扩充到2倍</span></span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">else</span> <span class="keyword">if</span> (oldThr &gt; <span class="number">0</span>) <span class="comment">//不执行</span></span><br><span class="line">           newCap = oldThr;</span><br><span class="line">       <span class="keyword">else</span> &#123;               <span class="comment">// 零初始阈值表示使用默认值</span></span><br><span class="line">           newCap = DEFAULT_INITIAL_CAPACITY;</span><br><span class="line">           newThr = (<span class="keyword">int</span>)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">if</span> (newThr == <span class="number">0</span>) &#123;<span class="comment">//不执行</span></span><br><span class="line">           <span class="keyword">float</span> ft = (<span class="keyword">float</span>)newCap * loadFactor;</span><br><span class="line">           newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (<span class="keyword">float</span>)MAXIMUM_CAPACITY ?</span><br><span class="line">                     (<span class="keyword">int</span>)ft : Integer.MAX_VALUE);</span><br><span class="line">       &#125;</span><br><span class="line">       threshold = newThr;<span class="comment">//将新的临界值赋值给threshold</span></span><br><span class="line">       <span class="meta">@SuppressWarnings</span>(&#123;<span class="string">"rawtypes"</span>,<span class="string">"unchecked"</span>&#125;)</span><br><span class="line">           Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node[newCap];</span><br><span class="line">       table = newTab;<span class="comment">//新的数组赋值给table</span></span><br><span class="line">        <span class="comment">//扩容后，重新计算元素新的位置</span></span><br><span class="line">       <span class="keyword">if</span> (oldTab != <span class="keyword">null</span>) &#123;</span><br><span class="line">           <span class="comment">//循环老的容量</span></span><br><span class="line">           <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; oldCap; ++j) &#123;</span><br><span class="line">               Node&lt;K,V&gt; e;</span><br><span class="line">               <span class="keyword">if</span> ((e = oldTab[j]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                   oldTab[j] = <span class="keyword">null</span>;</span><br><span class="line">                   <span class="keyword">if</span> (e.next == <span class="keyword">null</span>)</span><br><span class="line">                       newTab[e.hash &amp; (newCap - <span class="number">1</span>)] = e;</span><br><span class="line">                   <span class="keyword">else</span> <span class="keyword">if</span> (e <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                       <span class="comment">//当前index对应的节点为红黑树，当树的个数小于等于UNTREEIFY_THRESHOLD则转成链表</span></span><br><span class="line">                       ((TreeNode&lt;K,V&gt;)e).split(<span class="keyword">this</span>, newTab, j, oldCap);</span><br><span class="line">                   <span class="keyword">else</span> &#123; <span class="comment">// preserve order</span></span><br><span class="line">                       <span class="comment">//分成两个链表，减少扩容的迁移量</span></span><br><span class="line">                        <span class="comment">//loHead，下标不变情况下的链表头</span></span><br><span class="line">                        <span class="comment">//loTail，下标不变情况下的链表尾</span></span><br><span class="line">                        <span class="comment">//hiHead，下标改变情况下的链表头</span></span><br><span class="line">                        <span class="comment">//hiTail，下标改变情况下的链表尾</span></span><br><span class="line">                       Node&lt;K,V&gt; loHead = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line">                       Node&lt;K,V&gt; hiHead = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line">                       Node&lt;K,V&gt; next;</span><br><span class="line">                       <span class="keyword">do</span> &#123;</span><br><span class="line">                           next = e.next;</span><br><span class="line">                           <span class="keyword">if</span> ((e.hash &amp; oldCap) == <span class="number">0</span>) &#123;<span class="comment">//散列下标不变</span></span><br><span class="line">                               <span class="keyword">if</span> (loTail == <span class="keyword">null</span>)</span><br><span class="line">                                   loHead = e;<span class="comment">//设置链头</span></span><br><span class="line">                               <span class="keyword">else</span></span><br><span class="line">                                   loTail.next = e;</span><br><span class="line">                               loTail = e;<span class="comment">//设置链尾</span></span><br><span class="line">                           &#125;</span><br><span class="line">                           <span class="keyword">else</span> &#123;<span class="comment">//散列下标改变</span></span><br><span class="line">                               <span class="keyword">if</span> (hiTail == <span class="keyword">null</span>)</span><br><span class="line">                                   hiHead = e;<span class="comment">//设置链头</span></span><br><span class="line">                               <span class="keyword">else</span></span><br><span class="line">                                   hiTail.next = e;</span><br><span class="line">                               hiTail = e;<span class="comment">//设置链尾</span></span><br><span class="line">                           &#125;</span><br><span class="line">                       &#125; <span class="keyword">while</span> ((e = next) != <span class="keyword">null</span>);</span><br><span class="line">                       <span class="keyword">if</span> (loTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                           loTail.next = <span class="keyword">null</span>;</span><br><span class="line">                           newTab[j] = loHead;</span><br><span class="line">                       &#125;</span><br><span class="line">                       <span class="keyword">if</span> (hiTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                           hiTail.next = <span class="keyword">null</span>;</span><br><span class="line">                           <span class="comment">// 扩容长度为当前index位置+旧的容量</span></span><br><span class="line">                           newTab[j + oldCap] = hiHead;</span><br><span class="line">                       &#125;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> newTab;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h6 id="扩容机制？"><a href="#扩容机制？" class="headerlink" title="扩容机制？"></a>扩容机制？</h6><ul><li>限制扩容大小不能大于1&lt;&lt;30（1073741824），最低16。</li><li>扩容倍数是最接近2的幂次，例如：new HashMap(13) 最终仍会是16长度。</li></ul><h6 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h6><p>1、定义了oldCap原table长度，newCap新table长度，newCap是oldCap的两倍。<br>2、循环原table，获取链上元素存入新table<br>3、计算新旧下标结果，要么相同，要么新下标=旧下标+旧小标数组长度。</p><h6 id="hashMap是先插入还是先扩容？"><a href="#hashMap是先插入还是先扩容？" class="headerlink" title="hashMap是先插入还是先扩容？"></a>hashMap是先插入还是先扩容？</h6><p>1、初始容量，是先扩容在插入，后续就是先插入后扩容，因为resize()会进行新旧table做比较。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;HashMap源码刨析&quot;&gt;&lt;a href=&quot;#HashMap源码刨析&quot; class=&quot;headerlink&quot; title=&quot;HashMap源码刨析&quot;&gt;&lt;/a&gt;HashMap源码刨析&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Map接口的基于哈希表的实现。&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="源码刨析" scheme="http://www.updatecg.xin/categories/%E6%BA%90%E7%A0%81%E5%88%A8%E6%9E%90/"/>
    
    
      <category term="HashMap" scheme="http://www.updatecg.xin/tags/HashMap/"/>
    
      <category term="Java" scheme="http://www.updatecg.xin/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>RocketMq源码刨析之分布式事务</title>
    <link href="http://www.updatecg.xin/2020/03/01/RocketMq/"/>
    <id>http://www.updatecg.xin/2020/03/01/RocketMq/</id>
    <published>2020-03-01T02:05:02.000Z</published>
    <updated>2021-12-29T03:09:45.499Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RocketMq源码刨析"><a href="#RocketMq源码刨析" class="headerlink" title="RocketMq源码刨析"></a>RocketMq源码刨析</h2><blockquote><p>想必大家都比较熟悉RocketMQ,阿里开源消息队列项目。对于队列来说可以直接强势得理解成，处理并非、分布式事务得敌虫。</p></blockquote><h3 id="源码地址-https-github-com-apache-rocketmq"><a href="#源码地址-https-github-com-apache-rocketmq" class="headerlink" title="[源码地址]: https://github.com/apache/rocketmq"></a>[源码地址]: <a href="https://github.com/apache/rocketmq" target="_blank" rel="noopener">https://github.com/apache/rocketmq</a></h3><p><img data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/rocket.jpg" class="lozad"></p><h2 id="RocketMq4-3版本-支持分布式事物"><a href="#RocketMq4-3版本-支持分布式事物" class="headerlink" title="RocketMq4.3版本 支持分布式事物"></a>RocketMq4.3版本 支持分布式事物</h2><h3 id="案例入口【org-apache-rocketmq-example-transaction-TransactionProducer】"><a href="#案例入口【org-apache-rocketmq-example-transaction-TransactionProducer】" class="headerlink" title="案例入口【org.apache.rocketmq.example.transaction.TransactionProducer】"></a>案例入口【org.apache.rocketmq.example.transaction.TransactionProducer】</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//实现监听</span></span><br><span class="line">TransactionListener transactionListener = <span class="keyword">new</span> TransactionListenerImpl();</span><br><span class="line"><span class="comment">//生产者本地初始化</span></span><br><span class="line">TransactionMQProducer producer = <span class="keyword">new</span> TransactionMQProducer(<span class="string">"please_rename_unique_group_name"</span>);</span><br><span class="line">ExecutorService executorService = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">2</span>, <span class="number">5</span>, <span class="number">100</span>, TimeUnit.SECONDS, <span class="keyword">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class="number">2000</span>), <span class="keyword">new</span> ThreadFactory() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Thread <span class="title">newThread</span><span class="params">(Runnable r)</span> </span>&#123;</span><br><span class="line">        Thread thread = <span class="keyword">new</span> Thread(r);</span><br><span class="line">        thread.setName(<span class="string">"client-transaction-msg-check-thread"</span>);</span><br><span class="line">        <span class="keyword">return</span> thread;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">//设置线程池</span></span><br><span class="line">producer.setExecutorService(executorService);</span><br><span class="line"><span class="comment">//设置生产者本地事务得回调组件</span></span><br><span class="line">producer.setTransactionListener(transactionListener);</span><br><span class="line"><span class="comment">//开启消息处理</span></span><br><span class="line">producer.start();</span><br></pre></td></tr></table></figure><h3 id="案例入口【org-apache-rocketmq-client-impl-producer-DefaultMQProducerImpl-sendMessageInTransaction】"><a href="#案例入口【org-apache-rocketmq-client-impl-producer-DefaultMQProducerImpl-sendMessageInTransaction】" class="headerlink" title="案例入口【org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendMessageInTransaction】"></a>案例入口【org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendMessageInTransaction】</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> TransactionSendResult <span class="title">sendMessageInTransaction</span><span class="params">(<span class="keyword">final</span> Message msg,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                      <span class="keyword">final</span> LocalTransactionExecuter localTransactionExecuter, <span class="keyword">final</span> Object arg)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> MQClientException </span>&#123;</span><br><span class="line">    <span class="comment">//获取之前注册得TransactionListener本地事务回调组件</span></span><br><span class="line">    TransactionListener transactionListener = getCheckListener();</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == localTransactionExecuter &amp;&amp; <span class="keyword">null</span> == transactionListener) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> MQClientException(<span class="string">"tranExecutor is null"</span>, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//验证消息</span></span><br><span class="line">    Validators.checkMessage(msg, <span class="keyword">this</span>.defaultMQProducer);</span><br><span class="line"></span><br><span class="line">    SendResult sendResult = <span class="keyword">null</span>;</span><br><span class="line">    MessageAccessor.putProperty(msg, MessageConst.PROPERTY_TRANSACTION_PREPARED, <span class="string">"true"</span>);</span><br><span class="line">    MessageAccessor.putProperty(msg, MessageConst.PROPERTY_PRODUCER_GROUP, <span class="keyword">this</span>.defaultMQProducer.getProducerGroup());</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//发送消息</span></span><br><span class="line">        sendResult = <span class="keyword">this</span>.send(msg);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> MQClientException(<span class="string">"send message Exception"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW;</span><br><span class="line">    Throwable localException = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取发送消息回调结果</span></span><br><span class="line">    <span class="keyword">switch</span> (sendResult.getSendStatus()) &#123;</span><br><span class="line">        <span class="keyword">case</span> SEND_OK: &#123;<span class="comment">//发送成功</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (sendResult.getTransactionId() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    msg.putUserProperty(<span class="string">"__transactionId__"</span>, sendResult.getTransactionId());</span><br><span class="line">                &#125;</span><br><span class="line">                String transactionId = msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX);</span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">null</span> != transactionId &amp;&amp; !<span class="string">""</span>.equals(transactionId)) &#123;</span><br><span class="line">                    msg.setTransactionId(transactionId);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">//开启了本地事务回调组件才会进行回调处理</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">null</span> != localTransactionExecuter) &#123;</span><br><span class="line">                    localTransactionState = localTransactionExecuter.executeLocalTransactionBranch(msg, arg);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (transactionListener != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    log.debug(<span class="string">"Used new transaction API"</span>);</span><br><span class="line">                    <span class="comment">//执行本地事务</span></span><br><span class="line">                    localTransactionState = transactionListener.executeLocalTransaction(msg, arg);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">null</span> == localTransactionState) &#123;</span><br><span class="line">                    localTransactionState = LocalTransactionState.UNKNOW;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (localTransactionState != LocalTransactionState.COMMIT_MESSAGE) &#123;</span><br><span class="line">                    log.info(<span class="string">"executeLocalTransactionBranch return &#123;&#125;"</span>, localTransactionState);</span><br><span class="line">                    log.info(msg.toString());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">                log.info(<span class="string">"executeLocalTransactionBranch exception"</span>, e);</span><br><span class="line">                log.info(msg.toString());</span><br><span class="line">                localException = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> FLUSH_DISK_TIMEOUT:</span><br><span class="line">        <span class="keyword">case</span> FLUSH_SLAVE_TIMEOUT:</span><br><span class="line">        <span class="keyword">case</span> SLAVE_NOT_AVAILABLE:</span><br><span class="line">            localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//根据本地事务执行的结果去发送commit消息或者rollback消息</span></span><br><span class="line">        <span class="keyword">this</span>.endTransaction(sendResult, localTransactionState, localException);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        log.warn(<span class="string">"local transaction execute "</span> + localTransactionState + <span class="string">", but end broker transaction failed"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    TransactionSendResult transactionSendResult = <span class="keyword">new</span> TransactionSendResult();</span><br><span class="line">    transactionSendResult.setSendStatus(sendResult.getSendStatus());</span><br><span class="line">    transactionSendResult.setMessageQueue(sendResult.getMessageQueue());</span><br><span class="line">    transactionSendResult.setMsgId(sendResult.getMsgId());</span><br><span class="line">    transactionSendResult.setQueueOffset(sendResult.getQueueOffset());</span><br><span class="line">    transactionSendResult.setTransactionId(sendResult.getTransactionId());</span><br><span class="line">    transactionSendResult.setLocalTransactionState(localTransactionState);</span><br><span class="line">    <span class="keyword">return</span> transactionSendResult;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="总要节点"><a href="#总要节点" class="headerlink" title="总要节点"></a>总要节点</h4><ul><li>获取之前注册得TransactionListener本地事务回调组件：TransactionListener transactionListener = getCheckListener();</li><li>验证消息： Validators.checkMessage(msg, this.defaultMQProducer);</li><li>发送消息： sendResult = this.send(msg);</li><li>获取发送消息回调结果：switch (sendResult.getSendStatus())</li><li>如果开启事务transactionListener，执行本地事务：localTransactionState = transactionListener.executeLocalTransaction(msg, arg);</li><li>根据本地事务执行的结果去发送commit消息或者rollback消息：this.endTransaction(sendResult, localTransactionState, localException);</li></ul><h4 id="本地事务逻辑"><a href="#本地事务逻辑" class="headerlink" title="本地事务逻辑"></a>本地事务逻辑</h4><h5 id="案例入口【org-apache-rocketmq-example-transaction-executeLocalTransaction】"><a href="#案例入口【org-apache-rocketmq-example-transaction-executeLocalTransaction】" class="headerlink" title="案例入口【org.apache.rocketmq.example.transaction.executeLocalTransaction】"></a>案例入口【org.apache.rocketmq.example.transaction.executeLocalTransaction】</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> LocalTransactionState <span class="title">executeLocalTransaction</span><span class="params">(Message msg, Object arg)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//这里会执行本地业务逻辑，此处省略...</span></span><br><span class="line">      <span class="comment">//返回本地事物的执行结果（UNKNOW、commit、rollback）</span></span><br><span class="line">      <span class="keyword">int</span> value = transactionIndex.getAndIncrement();</span><br><span class="line">      <span class="keyword">int</span> status = value % <span class="number">3</span>;</span><br><span class="line">      localTrans.put(msg.getTransactionId(), status);</span><br><span class="line">      <span class="keyword">return</span> LocalTransactionState.UNKNOW;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h4 id="Netty线程检查事务状态"><a href="#Netty线程检查事务状态" class="headerlink" title="Netty线程检查事务状态"></a>Netty线程检查事务状态</h4><h5 id="案例入口【org-apache-rocketmq-example-transaction-checkLocalTransaction】"><a href="#案例入口【org-apache-rocketmq-example-transaction-checkLocalTransaction】" class="headerlink" title="案例入口【org.apache.rocketmq.example.transaction.checkLocalTransaction】"></a>案例入口【org.apache.rocketmq.example.transaction.checkLocalTransaction】</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> LocalTransactionState <span class="title">checkLocalTransaction</span><span class="params">(MessageExt msg)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//实现本地事务处理得结果逻辑</span></span><br><span class="line">    <span class="comment">//TODO 业务数据</span></span><br><span class="line">    <span class="comment">//比如本地业务想表A插入数据，那么此处可以去表A查询数据是否存在，就可以指导本地事务是否成功</span></span><br><span class="line">    <span class="comment">//根据本地事务响应得到结果，返回不同得状态。</span></span><br><span class="line">    <span class="comment">//本地事物执行成功返回COMMIT_MESSAGE，反之失败返回ROLLBACK_MESSAGE</span></span><br><span class="line">    Integer status = localTrans.get(msg.getTransactionId());</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> != status) &#123;</span><br><span class="line">        <span class="keyword">switch</span> (status) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> LocalTransactionState.UNKNOW;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>业务场景源码正在创作..</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;RocketMq源码刨析&quot;&gt;&lt;a href=&quot;#RocketMq源码刨析&quot; class=&quot;headerlink&quot; title=&quot;RocketMq源码刨析&quot;&gt;&lt;/a&gt;RocketMq源码刨析&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;想必大家都比较熟悉RocketMQ
      
    
    </summary>
    
      <category term="源码刨析" scheme="http://www.updatecg.xin/categories/%E6%BA%90%E7%A0%81%E5%88%A8%E6%9E%90/"/>
    
    
      <category term="HashMap" scheme="http://www.updatecg.xin/tags/HashMap/"/>
    
      <category term="Java" scheme="http://www.updatecg.xin/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>ConcurrentHashMap详解</title>
    <link href="http://www.updatecg.xin/2020/01/20/ConcurrentHashMap/"/>
    <id>http://www.updatecg.xin/2020/01/20/ConcurrentHashMap/</id>
    <published>2020-01-20T06:08:00.000Z</published>
    <updated>2021-08-19T08:56:50.369Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ConcurrentHashMap线程安全</p></blockquote><h2 id="Segment段"><a href="#Segment段" class="headerlink" title="Segment段"></a>Segment段</h2><p>因Segment继承ReentrantLock加锁，所以ConcurrentHashMap支持并发操作。<br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/Segment.png" class="lozad"></p><h2 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h2><p>简单理解就是，ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。</p><h2 id="并行度（默认-16）"><a href="#并行度（默认-16）" class="headerlink" title="并行度（默认 16）"></a>并行度（默认 16）</h2><p><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/ConcurrentHashMapJDK7.jpg" class="lozad"><br>concurrencyLevel：并行级别、并发数、Segment 数，怎么翻译不重要，理解它。默认是 16， 也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。<br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/ConcurrentHashMapJDK8.jpg" class="lozad"><br>Java8 对 ConcurrentHashMap 进行了比较大的改动,Java8 也引入了红黑树。</p><h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><h3 id="减小锁粒度"><a href="#减小锁粒度" class="headerlink" title="减小锁粒度"></a>减小锁粒度</h3><p>减小锁粒度是指缩小锁定对象的范围，从而减小锁冲突的可能性，从而提高系统的并发能力。减小锁粒度是一种削弱多线程锁竞争的有效手段，这种技术典型的应用是 ConcurrentHashMap(高性能的 HashMap)类的实现。对于 HashMap 而言，最重要的两个方法是get 与set 方法，如果我们对整个 HashMap 加锁，可以得到线程安全的对象，但是加锁粒度太大。<span style="font-weight:bold;color:red">Segment 的大小也被称为ConcurrentHashMap 的并发度</span>。</p><h3 id="分段锁"><a href="#分段锁" class="headerlink" title="分段锁"></a>分段锁</h3><p>ConcurrentHashMap，它内部细分了若干个小的 HashMap，称之为段(Segment)。<span style="font-weight:bold;color:red">默认情况下一个ConcurrentHashMap 被进一步细分为 16 个段，既就是锁的并发度</span>。<br>如果需要在 ConcurrentHashMap 中添加一个新的表项，并不是将整个 HashMap 加锁，而是首先根据hashcode 得到该表项应该存放在哪个段中，然后对该段加锁，并完成put 操作。在多线程环境中，如果多个线程同时进行put 操作，只要被加入的表项不存放在同一个段中，则线程间可以做到真正的并行。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;ConcurrentHashMap线程安全&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Segment段&quot;&gt;&lt;a href=&quot;#Segment段&quot; class=&quot;headerlink&quot; title=&quot;Segment段&quot;&gt;&lt;/a&gt;Segmen
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
      <category term="JAVA" scheme="http://www.updatecg.xin/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>JAVA锁</title>
    <link href="http://www.updatecg.xin/2019/12/20/JAVA%E9%94%81/"/>
    <id>http://www.updatecg.xin/2019/12/20/JAVA锁/</id>
    <published>2019-12-20T09:16:00.000Z</published>
    <updated>2021-08-19T08:57:15.498Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>现场安全标识</p></blockquote><h2 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h2><p>乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是<span style="font-weight:bold;color:red">在更新的时候会判断一下在此期间别人有没有去更新这个数  据，采取在写时先读出当前版本号，然后加锁操作<span>（比较跟上一次的版本号，如果一样则更新）， 如果失败则要重复读-比较-写的操作。<br>java 中的乐观锁基本都是通过 CAS 操作实现的，CAS 是一种更新的原子操作，<span style="font-weight:bold;color:red">比较当前值跟传入值是否一样，一样则更新，否则失败<span>。</span></span></span></span></p><h2 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h2><p>悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block 直到拿到锁。java 中的悲观锁就是<span style="font-weight:bold;color:red">Synchronized<span>,AQS 框架下的锁则是先尝试cas 乐观锁去获取锁，获取不到， 才会转换为悲观锁，如RetreenLock。</span></span></p><h2 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h2><p>自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋）， 等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。<br>线程自旋是需要消耗 cup 的，说白了就是让 cup 在做无用功，如果一直获取不到锁，那线程也不能一直占用 cup 自旋做无用功，所以需要设定一个自旋等待的最大时间。<br>如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。</p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换！</p><p>但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，占着 XX 不 XX，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗， 其它需要 cup 的线程又不能获取到 cpu，造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁；</p><h2 id="公平与非公平锁"><a href="#公平与非公平锁" class="headerlink" title="公平与非公平锁"></a>公平与非公平锁</h2><h3 id="公平锁（Fair）"><a href="#公平锁（Fair）" class="headerlink" title="公平锁（Fair）"></a>公平锁（Fair）</h3><p>加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得</p><h3 id="非公平锁（Nonfair）"><a href="#非公平锁（Nonfair）" class="headerlink" title="非公平锁（Nonfair）"></a>非公平锁（Nonfair）</h3><p>加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待</p><ul><li>非公平锁性能比公平锁高 5~10 倍，因为公平锁需要在多核的情况下维护一个队列</li><li>Java 中的synchronized 是非公平锁，ReentrantLock 默认的lock()方法采用的是非公平锁。</li></ul><h2 id="ReadWriteLock-读写锁"><a href="#ReadWriteLock-读写锁" class="headerlink" title="ReadWriteLock 读写锁"></a>ReadWriteLock 读写锁</h2><p>为了提高性能，Java 提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的,在一定程度上提高了程序的执行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm 自己控制的，你只要上好相应的锁即可。</p><h3 id="读锁"><a href="#读锁" class="headerlink" title="读锁"></a>读锁</h3><p>如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁</p><h3 id="写锁"><a href="#写锁" class="headerlink" title="写锁"></a>写锁</h3><p>如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！<br>Java 中 读 写 锁 有 个 接 口 java.util.concurrent.locks.ReadWriteLock ， 也 有 具 体 的 实 现ReentrantReadWriteLock。</p><h2 id="共享锁和独占锁java-并发包提供的加锁模式分为独占锁和共享锁。独占锁"><a href="#共享锁和独占锁java-并发包提供的加锁模式分为独占锁和共享锁。独占锁" class="headerlink" title="共享锁和独占锁java 并发包提供的加锁模式分为独占锁和共享锁。独占锁"></a>共享锁和独占锁java 并发包提供的加锁模式分为独占锁和共享锁。独占锁</h2><p>独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。</p><h3 id="共享锁"><a href="#共享锁" class="headerlink" title="共享锁"></a>共享锁</h3><p>共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。</p><ul><li>AQS 的内部类Node 定义了两个常量 SHARED 和EXCLUSIVE，他们分别标识 AQS 队列中等待线程的锁获取模式。</li><li>java 的并发包中提供了ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问， 或者被一个 写操作访问，但两者不能同时进行。</li></ul><h2 id="分段锁"><a href="#分段锁" class="headerlink" title="分段锁"></a>分段锁</h2><p>分段锁也并非一种实际的锁，而是一种思想ConcurrentHashMap中Segment分段锁。</p><h2 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h2><h3 id="减少锁持有时间"><a href="#减少锁持有时间" class="headerlink" title="减少锁持有时间"></a>减少锁持有时间</h3><p>只用在有线程安全要求的程序上加锁</p><h3 id="减小锁粒度"><a href="#减小锁粒度" class="headerlink" title="减小锁粒度"></a>减小锁粒度</h3><p>将大对象（这个对象可能会被很多线程访问），拆成小对象，大大增加并行度，降低锁竞争。降低了锁的竞争，偏向锁，轻量级锁成功率才会提高。最最典型的减小锁粒度的案例就是ConcurrentHashMap。</p><h3 id="锁分离"><a href="#锁分离" class="headerlink" title="锁分离"></a>锁分离</h3><p><span style="font-weight:bold;color:red">最常见的锁分离就是读写锁 ReadWriteLock</span>，根据功能进行分离成读锁和写锁，这样读读不互斥，读写互斥，写写互斥，即保证了线程安全，又提高了性能，具体也请查看[高并发 Java 五] JDK 并发包 1。读写分离思想可以延伸，只要操作互不影响，锁就可以分离。比如LinkedBlockingQueue 从头部取出，从尾部放数据</p><h3 id="锁粗化"><a href="#锁粗化" class="headerlink" title="锁粗化"></a>锁粗化</h3><p>通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完公共资源后，应该立即释放锁。但是，凡事都有一个度，<span style="font-weight:bold;color:red">如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化 </span>。</p><h3 id="锁消除"><a href="#锁消除" class="headerlink" title="锁消除"></a>锁消除</h3><p>锁消除是在编译器级别的事情。在即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作，多数是因为程序员编码不规范引起。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;现场安全标识&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;乐观锁&quot;&gt;&lt;a href=&quot;#乐观锁&quot; class=&quot;headerlink&quot; title=&quot;乐观锁&quot;&gt;&lt;/a&gt;乐观锁&lt;/h2&gt;&lt;p&gt;乐观锁是一种乐观思想，即认为读多写少，遇到并发写的
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
      <category term="JAVA" scheme="http://www.updatecg.xin/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>liunx常用命令</title>
    <link href="http://www.updatecg.xin/2019/05/30/liunx%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://www.updatecg.xin/2019/05/30/liunx常用命令/</id>
    <published>2019-05-30T08:21:00.000Z</published>
    <updated>2021-08-19T08:58:27.671Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>检验真理得决定性是实践。</p></blockquote><h1 id="查看服务器内存信息"><a href="#查看服务器内存信息" class="headerlink" title="查看服务器内存信息"></a>查看服务器内存信息</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@VM_0_12_centos 388]# free -m</span><br><span class="line">            total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:         1839         625         417           0         796        1013</span><br><span class="line">Swap:        0            0           0</span><br></pre></td></tr></table></figure><h1 id="Liunx查看进程运行得完成路径方法"><a href="#Liunx查看进程运行得完成路径方法" class="headerlink" title="Liunx查看进程运行得完成路径方法"></a>Liunx查看进程运行得完成路径方法</h1><h3 id="proc"><a href="#proc" class="headerlink" title="/proc"></a>/proc</h3><p>Linux在启动一个进程时，系统会在/proc下创建一个以PID命名的文件夹，在该文件夹下会有我们的进程的信息，<br>其中包括一个名为exe的文件即记录了绝对路径，通过ll或ls –l命令即可查看。</p><p>列入查看cpu高得服务情况<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PID  USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                                                                                                                                                388  root      16  -4  114564   1264   1032 S  0.3  0.1   4:50.63 auditd                                                                                                                                                                                                    5646 root      20   0  573864  20200   2772 S  0.3  1.1 258:37.17 YDService                                                                                                                                                                                                 5990 root      20   0  576604  41248  12820 S  0.3  2.2   0:03.58 node /data/blog</span><br></pre></td></tr></table></figure></p><p>查询PID等于388<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@VM_0_12_centos data]# cd /proc/388</span><br><span class="line">[root@VM_0_12_centos 388]# ll</span><br><span class="line">total 0</span><br><span class="line">dr-xr-xr-x 2 root root 0 Mar  7 15:03 attr</span><br><span class="line">-rw-r--r-- 1 root root 0 May 30 16:54 autogroup</span><br><span class="line">-r-------- 1 root root 0 May 30 16:54 auxv</span><br><span class="line">-r--r--r-- 1 root root 0 Mar  7 15:03 cgroup</span><br><span class="line">--w------- 1 root root 0 May 30 16:54 clear_refs</span><br><span class="line">-r--r--r-- 1 root root 0 Mar  7 15:03 cmdline</span><br><span class="line">-rw-r--r-- 1 root root 0 Mar  7 15:03 comm</span><br><span class="line">-rw-r--r-- 1 root root 0 May 30 16:54 coredump_filter</span><br><span class="line">-r--r--r-- 1 root root 0 May 30 16:54 cpuset</span><br><span class="line">lrwxrwxrwx 1 root root 0 Mar 24 02:36 cwd -&gt; /</span><br><span class="line">-r-------- 1 root root 0 May 30 16:54 environ</span><br><span class="line">lrwxrwxrwx 1 root root 0 Mar  7 15:03 exe -&gt; /usr/sbin/auditd</span><br><span class="line">dr-x------ 2 root root 0 Mar  7 15:03 fd</span><br><span class="line">dr-x------ 2 root root 0 May 25 10:09 fdinfo</span><br><span class="line">-rw-r--r-- 1 root root 0 May 30 16:54 gid_map</span><br><span class="line">-r-------- 1 root root 0 May 30 16:54 io</span><br><span class="line">-r--r--r-- 1 root root 0 May 30 16:54 limits</span><br><span class="line">-rw-r--r-- 1 root root 0 Mar  7 15:03 loginuid</span><br><span class="line">dr-x------ 2 root root 0 May 30 16:54 map_files</span><br><span class="line">-r--r--r-- 1 root root 0 May 30 16:54 maps</span><br></pre></td></tr></table></figure></p><p>可以看出,即可追踪服务地址<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lrwxrwxrwx 1 root root 0 Mar  7 15:03 exe -&gt; /usr/sbin/auditd</span><br></pre></td></tr></table></figure></p><h2 id="ps-aux"><a href="#ps-aux" class="headerlink" title="ps -aux"></a>ps -aux</h2><p>可查看详细信息<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root         1  0.0  0.1  41108  2924 ?        Ss   Mar07   6:02 /usr/lib/systemd/systemd --system --deserialize 25</span><br><span class="line">root         2  0.0  0.0      0     0 ?        S    Mar07   0:00 [kthreadd]</span><br><span class="line">root         3  0.0  0.0      0     0 ?        S    Mar07   1:28 [ksoftirqd/0]</span><br><span class="line">root         5  0.0  0.0      0     0 ?        S&lt;   Mar07   0:00 [kworker/0:0H]</span><br></pre></td></tr></table></figure></p><h1 id="查看文件夹容量"><a href="#查看文件夹容量" class="headerlink" title="查看文件夹容量"></a>查看文件夹容量</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@VM_0_12_centos data]# du -sh</span><br><span class="line">248M.</span><br></pre></td></tr></table></figure><h1 id="Liunx如何修改默认SSH端口"><a href="#Liunx如何修改默认SSH端口" class="headerlink" title="Liunx如何修改默认SSH端口"></a>Liunx如何修改默认SSH端口</h1><p>linux SSH默认端口是22，不修改的话存在一定的风险，要么是被人恶意扫描，要么会被人破解或者攻击，所以我们需要修改默认的SSH端口。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure></p><p>默认端口是22，并且已经被注释掉了，打开注释修改为其他未占用端口即可。</p><p>开启防火墙端口并重复服务即可。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart sshd.service</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;检验真理得决定性是实践。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;查看服务器内存信息&quot;&gt;&lt;a href=&quot;#查看服务器内存信息&quot; class=&quot;headerlink&quot; title=&quot;查看服务器内存信息&quot;&gt;&lt;/a&gt;查看服务器内存信息&lt;/h
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
      <category term="liunx" scheme="http://www.updatecg.xin/tags/liunx/"/>
    
  </entry>
  
  <entry>
    <title>docker命令大全</title>
    <link href="http://www.updatecg.xin/2019/05/20/docker%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/"/>
    <id>http://www.updatecg.xin/2019/05/20/docker命令大全/</id>
    <published>2019-05-20T09:16:00.000Z</published>
    <updated>2021-08-19T08:58:47.523Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>docker 必须掌握得命令</p></blockquote><h1 id="查看镜像"><a href="#查看镜像" class="headerlink" title="查看镜像"></a>查看镜像</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker images</td><td>列出所有镜像文件</td></tr><tr><td>docker images -a</td><td>列出所有得镜像文件-包括历史</td></tr><tr><td>docker rmi <image id></image></td><td>删除一个或多个镜像</td></tr></tbody></table><h1 id="查看容器"><a href="#查看容器" class="headerlink" title="查看容器"></a>查看容器</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker ps</td><td>列出当前所有正在运行得容器</td></tr><tr><td>docker ps -l</td><td>列出最近一次启动得容器</td></tr><tr><td>docker ps -a</td><td>列出所有容器（包括历史，即运行过得容器）</td></tr><tr><td>docker ps -q</td><td>列出最近一次运行得容器ID</td></tr></tbody></table><h1 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker start/stop/restart <container></container></td><td>开启/停止/重启container</td></tr><tr><td>docker start [container_id]</td><td>再次运行某个container （包括历史container）</td></tr><tr><td>docker attach [container_id]</td><td>连接一个正在运行的container实例（即实例必须为start状态，可以多个窗口同时attach 一个container实例）</td></tr><tr><td>docker exec -it &lt;container_id&gt; /bin/bash</td><td>进入容器</td></tr><tr><td>docker start -i <container></container></td><td>启动一个container并进入交互模式（相当于先start，在attach）</td></tr><tr><td>docker run -i -t <image> /bin/bash</image></td><td>使用image创建container并进入交互模式, login shell是/bin/bash</td></tr><tr><td>docker run -i -t -p &lt;host_port:contain_port&gt;</td><td>映射 HOST 端口到容器，方便外部访问容器内服务，host_port 可以省略，省略表示把 container_port 映射到一个动态端口。</td></tr></tbody></table><p>注：使用start是启动已经创建过得container，使用run则通过image开启一个新的container。</p><h1 id="如何在docker容器和宿主机之间复制文件"><a href="#如何在docker容器和宿主机之间复制文件" class="headerlink" title="如何在docker容器和宿主机之间复制文件"></a>如何在docker容器和宿主机之间复制文件</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>sudo docker cp host_path containerID:container_path</td><td>从主机复制到容器</td></tr><tr><td>sudo docker cp containerID:container_path host_path</td><td>从容器复制到主机</td></tr><tr><td>docker run –name cloud1 -h cloud1 -it jchubby/spark:1.0</td><td>利用镜像启用容器</td></tr></tbody></table><h1 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker rm &lt;container…&gt;</td><td>删除一个或多个container</td></tr><tr><td>docker rm <code>docker ps -a -q</code></td><td>删除所有的container</td></tr><tr><td>docker ps -a -q</td><td>xargs docker rm</td><td>同上, 删除所有的container</td></tr></tbody></table><h1 id="通过容器生成新的镜像"><a href="#通过容器生成新的镜像" class="headerlink" title="通过容器生成新的镜像"></a>通过容器生成新的镜像</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker commit <container-id> <image-name></image-name></container-id></td><td>把一个容器转变为一个新的镜像</td></tr></tbody></table><h1 id="持久化容器"><a href="#持久化容器" class="headerlink" title="持久化容器"></a>持久化容器</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker export <container id> &gt; /tmp/export.tar</container></td><td>export命令用于持久化容器</td></tr></tbody></table><h1 id="特殊命令"><a href="#特殊命令" class="headerlink" title="特殊命令"></a>特殊命令</h1><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>docker logs $CONTAINER_ID</td><td>查看docker实例运行日志，确保正常运行</td></tr><tr><td>docker inspect $CONTAINER_ID docker inspect &lt;image或者container&gt;</td><td>查看image或container的底层信息</td></tr><tr><td>docker build <path></path></td><td>寻找path路径下名为的Dockerfile的配置文件，使用此配置生成新的image</td></tr><tr><td>docker build -t repo[:tag]</td><td>同上，可以指定repo和可选的tag</td></tr><tr><td>docker build -f <dockerfile></dockerfile></td><td>使用指定的dockerfile配置文件，docker以stdin方式获取内容，使用此配置生成新的image</td></tr><tr><td>docker port <container> <container port></container></container></td><td>查看本地哪个端口映射到container的指定端口，其实用docker ps 也可以看到</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;docker 必须掌握得命令&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;查看镜像&quot;&gt;&lt;a href=&quot;#查看镜像&quot; class=&quot;headerlink&quot; title=&quot;查看镜像&quot;&gt;&lt;/a&gt;查看镜像&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;

      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
  </entry>
  
  <entry>
    <title>Nginx参数配置说明</title>
    <link href="http://www.updatecg.xin/2019/04/15/Nginx%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/"/>
    <id>http://www.updatecg.xin/2019/04/15/Nginx参数配置说明/</id>
    <published>2019-04-15T09:02:00.000Z</published>
    <updated>2020-05-28T04:03:10.662Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Nginx详细配置</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#运行用户</span><br><span class="line">user nobody;</span><br><span class="line">#启动进程,通常设置成和cpu的数量相等</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">#全局错误日志及PID文件</span><br><span class="line">#error_log  logs/error.log;</span><br><span class="line">#error_log  logs/error.log  notice;</span><br><span class="line">#error_log  logs/error.log  info;</span><br><span class="line"></span><br><span class="line">#pid        logs/nginx.pid;</span><br><span class="line"></span><br><span class="line">#工作模式及连接数上限</span><br><span class="line">events &#123;</span><br><span class="line">    #epoll是多路复用IO(I/O Multiplexing)中的一种方式,</span><br><span class="line">    #仅用于linux2.6以上内核,可以大大提高nginx的性能</span><br><span class="line">    use   epoll;</span><br><span class="line"></span><br><span class="line">    #单个后台worker process进程的最大并发链接数    </span><br><span class="line">    worker_connections  1024;</span><br><span class="line"></span><br><span class="line">    # 并发总数是 worker_processes 和 worker_connections 的乘积</span><br><span class="line">    # 即 max_clients = worker_processes * worker_connections</span><br><span class="line">    # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4  为什么</span><br><span class="line">    # 为什么上面反向代理要除以4，应该说是一个经验值</span><br><span class="line">    # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000</span><br><span class="line">    # worker_connections 值的设置跟物理内存大小有关</span><br><span class="line">    # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数</span><br><span class="line">    # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右</span><br><span class="line">    # 我们来看看360M内存的VPS可以打开的文件句柄数是多少：</span><br><span class="line">    # $ cat /proc/sys/fs/file-max</span><br><span class="line">    # 输出 34336</span><br><span class="line">    # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内</span><br><span class="line">    # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置</span><br><span class="line">    # 使得并发总数小于操作系统可以打开的最大文件数目</span><br><span class="line">    # 其实质也就是根据主机的物理CPU和内存进行配置</span><br><span class="line">    # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。</span><br><span class="line">    # ulimit -SHn 65535</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    #设定mime类型,类型由mime.type文件定义</span><br><span class="line">    include    mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    #设定日志格式</span><br><span class="line">    log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line">                      &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">                      &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;</span><br><span class="line"></span><br><span class="line">    access_log  logs/access.log  main;</span><br><span class="line"></span><br><span class="line">    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，</span><br><span class="line">    #对于普通应用，必须设为 on,</span><br><span class="line">    #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，</span><br><span class="line">    #以平衡磁盘与网络I/O处理速度，降低系统的uptime.</span><br><span class="line">    sendfile     on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    #连接超时时间</span><br><span class="line">    #keepalive_timeout  0;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line">    tcp_nodelay     on;</span><br><span class="line"></span><br><span class="line">    #开启gzip压缩</span><br><span class="line">    gzip  on;</span><br><span class="line">    gzip_disable &quot;MSIE [1-6].&quot;;</span><br><span class="line"></span><br><span class="line">    #设定请求缓冲</span><br><span class="line">    client_header_buffer_size    128k;</span><br><span class="line">    large_client_header_buffers  4 128k;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #设定虚拟主机配置</span><br><span class="line">    server &#123;</span><br><span class="line">        #侦听80端口</span><br><span class="line">        listen    80;</span><br><span class="line">        #定义使用 www.nginx.cn访问</span><br><span class="line">        server_name  www.nginx.cn;</span><br><span class="line"></span><br><span class="line">        #定义服务器的默认网站根目录位置</span><br><span class="line">        root html;</span><br><span class="line"></span><br><span class="line">        #设定本虚拟主机的访问日志</span><br><span class="line">        access_log  logs/nginx.access.log  main;</span><br><span class="line"></span><br><span class="line">        #默认请求</span><br><span class="line">        location / &#123;</span><br><span class="line"></span><br><span class="line">            #定义首页索引文件的名称</span><br><span class="line">            index index.php index.html index.htm;   </span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        # 定义错误提示页面</span><br><span class="line">        error_page   500 502 503 504 /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        #静态文件，nginx自己处理</span><br><span class="line">        location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123;</span><br><span class="line"></span><br><span class="line">            #过期30天，静态文件不怎么更新，过期可以设大一点，</span><br><span class="line">            #如果频繁更新，则可以设置得小一点。</span><br><span class="line">            expires 30d;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.</span><br><span class="line">        location ~ .php$ &#123;</span><br><span class="line">            fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">            fastcgi_index index.php;</span><br><span class="line">            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;</span><br><span class="line">            include fastcgi_params;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        #禁止访问 .htxxx 文件</span><br><span class="line">            location ~ /.ht &#123;</span><br><span class="line">            deny all;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Nginx详细配置&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;#运行用户&lt;/span&gt;
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="Nginx" scheme="http://www.updatecg.xin/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>为什么我们做分布式使用Redis</title>
    <link href="http://www.updatecg.xin/2019/03/29/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%BB%AC%E5%81%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%BD%BF%E7%94%A8Redis/"/>
    <id>http://www.updatecg.xin/2019/03/29/为什么我们做分布式使用Redis/</id>
    <published>2019-03-29T03:01:00.000Z</published>
    <updated>2020-05-28T04:03:11.087Z</updated>
    
    <content type="html"><![CDATA[<p>绝大部分写业务的程序员，在实际开发中使用 Redis 的时候，只会 Set Value 和 Get Value 两个操作，对 Redis 整体缺乏一个认知。这里对 Redis 常见问题做一个总结，解决大家的知识盲点。</p><h2 id="1、为什么使用-Redis"><a href="#1、为什么使用-Redis" class="headerlink" title="1、为什么使用 Redis"></a>1、为什么使用 Redis</h2><p>在项目中使用 Redis，主要考虑两个角度：性能和并发。如果只是为了分布式锁这些其他功能，还有其他中间件 Zookpeer 等代替，并非一定要使用 Redis。</p><h3 id="性能："><a href="#性能：" class="headerlink" title="性能："></a>性能：</h3><p>如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的 SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。</p><p>特别是在秒杀系统，在同一时间，几乎所有人都在点，都在下单。。。执行的是同一操作———向数据库查数据。</p><p><img alt="输入图片说明" title="屏幕截图.png" data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/090927_1b0c4b61_87650.png" class="lozad"></p><p>根据交互效果的不同，响应时间没有固定标准。在理想状态下，我们的页面跳转需要在瞬间解决，对于页内操作则需要在刹那间解决。</p><h3 id="并发："><a href="#并发：" class="headerlink" title="并发："></a>并发：</h3><p>如下图所示，在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用 Redis 做一个缓冲操作，让请求先访问到 Redis，而不是直接访问数据库。</p><p> <img alt="输入图片说明" title="屏幕截图.png" data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/090934_f875e978_87650.png" class="lozad"></p><h3 id="使用-Redis-的常见问题"><a href="#使用-Redis-的常见问题" class="headerlink" title="使用 Redis 的常见问题"></a>使用 Redis 的常见问题</h3><ul><li><p>缓存和数据库双写一致性问题</p></li><li><p>缓存雪崩问题</p></li><li><p>缓存击穿问题</p></li><li><p>缓存的并发竞争问题</p></li></ul><h2 id="2、单线程的-Redis-为什么这么快"><a href="#2、单线程的-Redis-为什么这么快" class="headerlink" title="2、单线程的 Redis 为什么这么快"></a>2、单线程的 Redis 为什么这么快</h2><p>这个问题是对 Redis 内部机制的一个考察。很多人都不知道 Redis 是单线程工作模型。</p><h3 id="原因主要是以下三点："><a href="#原因主要是以下三点：" class="headerlink" title="原因主要是以下三点："></a>原因主要是以下三点：</h3><p>纯内存操作</p><p>单线程操作，避免了频繁的上下文切换</p><p>采用了非阻塞 I/O 多路复用机制</p><p>仔细说一说 I/O 多路复用机制，打一个比方：小名在 A 城开了一家快餐店店，负责同城快餐服务。小明因为资金限制，雇佣了一批配送员，然后小曲发现资金不够了，只够买一辆车送快递。</p><h3 id="经营方式一"><a href="#经营方式一" class="headerlink" title="经营方式一"></a>经营方式一</h3><p>客户每下一份订单，小明就让一个配送员盯着，然后让人开车去送。慢慢的小曲就发现了这种经营方式存在下述问题：</p><p>时间都花在了抢车上了，大部分配送员都处在闲置状态，抢到车才能去送。</p><p>随着下单的增多，配送员也越来越多，小明发现快递店里越来越挤，没办法雇佣新的配送员了。</p><p>配送员之间的协调很花时间。</p><p>综合上述缺点，小明痛定思痛，提出了经营方式二。</p><h3 id="经营方式二"><a href="#经营方式二" class="headerlink" title="经营方式二"></a>经营方式二</h3><p>小明只雇佣一个配送员。当客户下单，小明按送达地点标注好，依次放在一个地方。最后，让配送员依次开着车去送，送好了就回来拿下一个。上述两种经营方式对比，很明显第二种效率更高。</p><p>在上述比喻中：</p><p>每个配送员→每个线程</p><p>每个订单→每个 Socket(I/O 流)</p><p>订单的送达地点→Socket 的不同状态</p><p>客户送餐请求→来自客户端的请求</p><p>明曲的经营方式→服务端运行的代码</p><p>一辆车→CPU 的核数</p><p>于是有了如下结论：</p><p>经营方式一就是传统的并发模型，每个 I/O 流(订单)都有一个新的线程(配送员)管理。</p><p>经营方式二就是 I/O 多路复用。只有单个线程(一个配送员)，通过跟踪每个 I/O 流的状态(每个配送员的送达地点)，来管理多个 I/O 流。</p><p>下面类比到真实的 Redis 线程模型，如图所示：</p><p><img alt="输入图片说明" title="屏幕截图.png" data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/090949_68d6f98f_87650.png" class="lozad"></p><p>Redis-client 在操作的时候，会产生具有不同事件类型的 Socket。在服务端，有一段 I/O 多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。</p><h2 id="3、Redis-的数据类型及使用场景"><a href="#3、Redis-的数据类型及使用场景" class="headerlink" title="3、Redis 的数据类型及使用场景"></a>3、Redis 的数据类型及使用场景</h2><p>一个合格的程序员，这五种类型都会用到。</p><p>String</p><p>最常规的 set/get 操作，Value 可以是 String 也可以是数字。一般做一些复杂的计数功能的缓存。</p><p>Hash</p><p>这里 Value 存放的是结构化的对象，比较方便的就是操作其中的某个字段。我在做单点登录的时候，就是用这种数据结构存储用户信息，以 CookieId 作为 Key，设置 30 分钟为缓存过期时间，能很好的模拟出类似 Session 的效果。</p><p>List</p><p>使用 List 的数据结构，可以做简单的消息队列的功能。另外，可以利用 lrange 命令，做基于 Redis 的分页功能，性能极佳，用户体验好。</p><p>Set</p><p>因为 Set 堆放的是一堆不重复值的集合。所以可以做全局去重的功能。我们的系统一般都是集群部署，使用 JVM 自带的 Set 比较麻烦。另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。</p><p>Sorted Set</p><p>Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。可以做排行榜应用，取 TOP N 操作。Sorted Set 可以用来做延时任务。</p><h2 id="4、Redis-的过期策略和内存淘汰机制"><a href="#4、Redis-的过期策略和内存淘汰机制" class="headerlink" title="4、Redis 的过期策略和内存淘汰机制"></a>4、Redis 的过期策略和内存淘汰机制</h2><p>Redis 是否用到家，从这就能看出来。比如你 Redis 只能存 5G 数据，可是你写了 10G，那会删 5G 的数据。怎么删的，这个问题思考过么？</p><p>正解：Redis 采用的是定期删除+惰性删除策略。</p><p>为什么不用定时删除策略</p><p>定时删除，用一个定时器来负责监视 Key，过期则自动删除。虽然内存及时释放，但是十分消耗 CPU 资源。在大并发请求下，CPU 要将时间应用在处理请求，而不是删除 Key，因此没有采用这一策略。</p><p>定期删除+惰性删除如何工作</p><p>定期删除，Redis 默认每个 100ms 检查，有过期 Key 则删除。需要说明的是，Redis 不是每个 100ms 将所有的 Key 检查一次，而是随机抽取进行检查。如果只采用定期删除策略，会导致很多 Key 到时间没有删除。于是，惰性删除派上用场。</p><p>采用定期删除+惰性删除就没其他问题了么</p><p>不是的，如果定期删除没删除掉 Key。并且你也没及时去请求 Key，也就是说惰性删除也没生效。这样，Redis 的内存会越来越高。那么就应该采用内存淘汰机制。</p><p>在 redis.conf 中有一行配置：</p><h1 id="maxmemory-policy-volatile-lru"><a href="#maxmemory-policy-volatile-lru" class="headerlink" title="maxmemory-policy volatile-lru"></a>maxmemory-policy volatile-lru</h1><p>该配置就是配内存淘汰策略的：</p><ul><li><p>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。</p></li><li><p>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。（推荐使用，目前项目在用这种）(最近最久使用算法)</p></li><li><p>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。（应该也没人用吧，你不删最少使用 Key，去随机删）</p></li><li><p>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。（不推荐）</p></li><li><p>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。（依然不推荐）</p></li><li><p>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。（不推荐）</p></li></ul><h2 id="5、Redis-和数据库双写一致性问题"><a href="#5、Redis-和数据库双写一致性问题" class="headerlink" title="5、Redis 和数据库双写一致性问题"></a>5、Redis 和数据库双写一致性问题</h2><p>一致性问题还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。前提是如果对数据有强一致性要求，不能放缓存。我们所做的一切，只能保证最终一致性。</p><p>另外，我们所做的方案从根本上来说，只能降低不一致发生的概率。因此，有强一致性要求的数据，不能放缓存。首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。</p><h2 id="6、如何应对缓存穿透和缓存雪崩问题"><a href="#6、如何应对缓存穿透和缓存雪崩问题" class="headerlink" title="6、如何应对缓存穿透和缓存雪崩问题"></a>6、如何应对缓存穿透和缓存雪崩问题</h2><p>这两个问题，一般中小型传统软件企业很难碰到。如果有大并发的项目，流量有几百万左右，这两个问题一定要深刻考虑。缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。</p><h3 id="缓存穿透解决方案："><a href="#缓存穿透解决方案：" class="headerlink" title="缓存穿透解决方案："></a>缓存穿透解决方案：</h3><ul><li><p>利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。</p></li><li><p>采用异步更新策略，无论 Key 是否取到值，都直接返回。Value 值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。</p></li><li><p>提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的 Key。迅速判断出，请求所携带的 Key 是否合法有效。如果不合法，则直接返回。</p></li><li><p>缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。</p></li></ul><h3 id="缓存雪崩解决方案："><a href="#缓存雪崩解决方案：" class="headerlink" title="缓存雪崩解决方案："></a>缓存雪崩解决方案：</h3><ul><li><p>给缓存的失效时间，加上一个随机值，避免集体失效。</p></li><li><p>使用互斥锁，但是该方案吞吐量明显下降了。</p></li><li><p>双缓存。我们有两个缓存，缓存 A 和缓存 B。缓存 A 的失效时间为 20 分钟，缓存 B 不设失效时间。自己做缓存预热操作。</p></li><li><p>然后细分以下几个小点：从缓存 A 读数据库，有则直接返回；A 没有数据，直接从 B 读数据，直接返回，并且异步启动一个更新线程，更新线程同时更新缓存 A 和缓存 B。</p></li></ul><h2 id="7、如何解决-Redis-的并发竞争-Key-问题"><a href="#7、如何解决-Redis-的并发竞争-Key-问题" class="headerlink" title="7、如何解决 Redis 的并发竞争 Key 问题"></a>7、如何解决 Redis 的并发竞争 Key 问题</h2><p>这个问题大致就是，同时有多个子系统去 Set 一个 Key。这个时候要注意什么呢？大家基本都是推荐用 Redis 事务机制。</p><p>但是我并不推荐使用 Redis 的事务机制。因为我们的生产环境，基本都是 Redis 集群环境，做了数据分片操作。你一个事务中有涉及到多个 Key 操作的时候，这多个 Key 不一定都存储在同一个 redis-server 上。因此，Redis 的事务机制，十分鸡肋。</p><h3 id="如果对这个-Key-操作，不要求顺序"><a href="#如果对这个-Key-操作，不要求顺序" class="headerlink" title="如果对这个 Key 操作，不要求顺序"></a>如果对这个 Key 操作，不要求顺序</h3><p>这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做 set 操作即可，比较简单。</p><h3 id="如果对这个-Key-操作，要求顺序"><a href="#如果对这个-Key-操作，要求顺序" class="headerlink" title="如果对这个 Key 操作，要求顺序"></a>如果对这个 Key 操作，要求顺序</h3><p>假设有一个 key1，系统 A 需要将 key1 设置为 valueA，系统 B 需要将 key1 设置为 valueB，系统 C 需要将 key1 设置为 valueC。</p><p>期望按照 key1 的 value 值按照 valueA &gt; valueB &gt; valueC 的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。</p><h3 id="假设时间戳如下："><a href="#假设时间戳如下：" class="headerlink" title="假设时间戳如下："></a>假设时间戳如下：</h3><p>系统 A key 1 {valueA  3:00}<br>系统 B key 1 {valueB  3:05}<br>系统 C key 1 {valueC  3:10}</p><p>那么，假设系统 B 先抢到锁，将 key1 设置为{valueB 3:05}。接下来系统 A 抢到锁，发现自己的 valueA 的时间戳早于缓存中的时间戳，那就不做 set 操作了，以此类推。其他方法，比如利用队列，将 set 方法变成串行访问也可以。</p><h2 id="8、总结"><a href="#8、总结" class="headerlink" title="8、总结"></a>8、总结</h2><p>Redis 在国内各大公司都能看到其身影，比如我们熟悉的新浪，阿里，腾讯，百度，美团，小米等。学习 Redis，这几方面尤其重要：Redis 客户端、Redis 高级功能、Redis 持久化和开发运维常用问题探讨、Redis 复制的原理和优化策略、Redis 分布式解决方案等。</p><p>转自：<a href="https://www.cnblogs.com/yaodengyan/p/9717080.html" target="_blank" rel="noopener">https://www.cnblogs.com/yaodengyan/p/9717080.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;绝大部分写业务的程序员，在实际开发中使用 Redis 的时候，只会 Set Value 和 Get Value 两个操作，对 Redis 整体缺乏一个认知。这里对 Redis 常见问题做一个总结，解决大家的知识盲点。&lt;/p&gt;
&lt;h2 id=&quot;1、为什么使用-Redis&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="Redis" scheme="http://www.updatecg.xin/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>大数据案例之HDFS-HIVE-Spark</title>
    <link href="http://www.updatecg.xin/2019/03/21/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B%E4%B9%8BHDFS-HIVE-Spark/"/>
    <id>http://www.updatecg.xin/2019/03/21/大数据案例之HDFS-HIVE-Spark/</id>
    <published>2019-03-21T03:16:00.000Z</published>
    <updated>2021-12-29T03:06:08.634Z</updated>
    
    <content type="html"><![CDATA[<blockquote><ul><li>发现Hive后台使用MapReduce作为执行引擎，实在是有点慢.几十万数据查询了10+秒，上千万数据查询了100+秒。</li><li>还是单纯查询没有附加任何条件。Hive作为数据仓库是不错的选择，单表支持几十亿数据库存储。</li><li>对于查询来说，我想就需要考虑其他的MapReduce查询方式了。这里考虑学习SparkSql。</li><li>原因的话就让我们一起来学习，认识吧。</li></ul></blockquote><h2 id="推荐管理Hive数据库软件-Aginity-Workbench-for-Hadoop"><a href="#推荐管理Hive数据库软件-Aginity-Workbench-for-Hadoop" class="headerlink" title="推荐管理Hive数据库软件 Aginity Workbench for Hadoop"></a>推荐管理Hive数据库软件 <code>Aginity Workbench for Hadoop</code></h2><blockquote><p>可视化管理HIVE数据、支持远程连接Hadoop根据dfs创建hive外部映射表。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;发现Hive后台使用MapReduce作为执行引擎，实在是有点慢.几十万数据查询了10+秒，上千万数据查询了100+秒。&lt;/li&gt;
&lt;li&gt;还是单纯查询没有附加任何条件。Hive作为数据仓库是不错的选择，单表支持几十亿数据库存储。&lt;/l
      
    
    </summary>
    
      <category term="大数据" scheme="http://www.updatecg.xin/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="http://www.updatecg.xin/tags/Hadoop/"/>
    
      <category term="Hive" scheme="http://www.updatecg.xin/tags/Hive/"/>
    
      <category term="Spark" scheme="http://www.updatecg.xin/tags/Spark/"/>
    
      <category term="Aginity" scheme="http://www.updatecg.xin/tags/Aginity/"/>
    
  </entry>
  
  <entry>
    <title>大数据案例之HDFS-HIVE</title>
    <link href="http://www.updatecg.xin/2019/03/13/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B%E4%B9%8BHDFS-HIVE/"/>
    <id>http://www.updatecg.xin/2019/03/13/大数据案例之HDFS-HIVE/</id>
    <published>2019-03-13T07:42:00.000Z</published>
    <updated>2020-05-28T04:03:09.916Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>基于Hdfs、hive、mysql数据处理案例，闲时自玩项目</p></blockquote><h2 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h2><blockquote><p>数据采集方式有很多种，一般在项目中采用数据上报方式。本地为了方便测试则采用读取csv文件。后续python自动抓取数据。</p></blockquote><p>链接: <a href="https://pan.baidu.com/s/1cOCe1GXAxtkXCUbvY0MWFw" target="_blank" rel="noopener">https://pan.baidu.com/s/1cOCe1GXAxtkXCUbvY0MWFw</a> 提取码: r23c<br>数据量不多，侧重于功能</p><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><blockquote><p>清洗数据,统计分析数据，结果存储HDFS ,加载至HIVE, Sqoop至MYSQL</p></blockquote><h3 id="CSV-数据加载入Hadoop-部分代码"><a href="#CSV-数据加载入Hadoop-部分代码" class="headerlink" title="CSV 数据加载入Hadoop  部分代码"></a>CSV 数据加载入Hadoop  部分代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public String transfer(File file, String folderPath, String fileName) throws Exception &#123;</span><br><span class="line">  if (!opened) &#123;</span><br><span class="line">      throw new Exception(&quot;FileSystem was not opened!&quot;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  boolean folderCreated = fs.mkdirs(new Path(folderPath));</span><br><span class="line"></span><br><span class="line">  Path filePath = new Path(folderPath, StrUtils.isEmpty(fileName) ? file.getName() : fileName);</span><br><span class="line">  boolean fileCreated = fs.createNewFile(filePath);</span><br><span class="line"></span><br><span class="line">  FSDataOutputStream append = fs.append(filePath);</span><br><span class="line">  byte[] bytes = new byte[COPY_BUFFERSIZE];</span><br><span class="line">  int size = 0;</span><br><span class="line">  FileInputStream fileInputStream = new FileInputStream(file);</span><br><span class="line">  while ((size = fileInputStream.read(bytes)) &gt; 0) &#123;</span><br><span class="line">      append.write(bytes, 0, size);</span><br><span class="line">  &#125;</span><br><span class="line">  fileInputStream.close();</span><br><span class="line">  return filePath.toUri().toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="将dfs文件加载入hive-部分代码"><a href="#将dfs文件加载入hive-部分代码" class="headerlink" title="将dfs文件加载入hive 部分代码"></a>将dfs文件加载入hive 部分代码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  //表</span><br><span class="line">  String yyyyMMdd = hiveTable + DateUtil.formatDate(new Date(), &quot;yyyyMMdd&quot;);</span><br><span class="line">  //参数</span><br><span class="line">  Map&lt;String, String&gt; map = new HashMap&lt;&gt;();</span><br><span class="line">  map.put(&quot;title&quot;, &quot;STRING&quot;);</span><br><span class="line">  map.put(&quot;discountPrice&quot;, &quot;STRING&quot;);</span><br><span class="line">  map.put(&quot;price&quot;, &quot;STRING&quot;);</span><br><span class="line">  map.put(&quot;address&quot;, &quot;STRING&quot;);</span><br><span class="line">  map.put(&quot;count&quot;, &quot;STRING&quot;);</span><br><span class="line"></span><br><span class="line">  //创建表 按天分表</span><br><span class="line">  hiveDataService.createHiveTable(yyyyMMdd, map);</span><br><span class="line">  //将dfs数据加载到hive表</span><br><span class="line">  hiveDataService.loadHiveIntoTable(fs.getDfsPath(), yyyyMMdd);</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">  * @param tableName     hive表名</span><br><span class="line">  * @param parametersMap 表字段值/类型</span><br><span class="line">  */</span><br><span class="line"> @Override</span><br><span class="line"> public void createHiveTable(String tableName, Map&lt;String, String&gt; parametersMap) &#123;</span><br><span class="line">     StringBuffer sql = new StringBuffer(&quot;CREATE TABLE IF NOT EXISTS &quot;);</span><br><span class="line">     sql.append(&quot;&quot; + tableName + &quot;&quot;);</span><br><span class="line">     StringBuffer sb = new StringBuffer();</span><br><span class="line">     parametersMap.forEach((k, v) -&gt; &#123;</span><br><span class="line">         sb.append(k + &quot; &quot; + v + &quot;,&quot;);</span><br><span class="line">     &#125;);</span><br><span class="line">     sql.append(&quot;(&quot; + sb.deleteCharAt(sb.length() - 1) + &quot;)&quot;);</span><br><span class="line">     sql.append(&quot;ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; LINES TERMINATED BY &apos;\n&apos; &quot;); // 定义分隔符</span><br><span class="line">     sql.append(&quot;STORED AS TEXTFILE&quot;); // 作为文本存储</span><br><span class="line"></span><br><span class="line">     Log.info(&quot;Create table [&quot; + tableName + &quot;] successfully...&quot;);</span><br><span class="line">     try &#123;</span><br><span class="line">         hiveJdbcTemplate.execute(sql.toString());</span><br><span class="line">     &#125; catch (DataAccessException dae) &#123;</span><br><span class="line">         Log.error(dae.fillInStackTrace());</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * @param filePath  dfs文件路径</span><br><span class="line"> * @param tableName 表名</span><br><span class="line"> */</span><br><span class="line">@Override</span><br><span class="line">public void loadHiveIntoTable(String filePath, String tableName) &#123;</span><br><span class="line">    StringBuffer sql = new StringBuffer(&quot;load data inpath &quot;);</span><br><span class="line">    sql.append(&quot;&apos;&quot; + filePath + &quot;&apos;into table &quot; + tableName);</span><br><span class="line">    Log.info(&quot;Load data into table successfully...&quot;);</span><br><span class="line">    try &#123;</span><br><span class="line">        hiveJdbcTemplate.execute(sql.toString());</span><br><span class="line">    &#125; catch (DataAccessException dae) &#123;</span><br><span class="line">        Log.error(dae.fillInStackTrace());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="利用外部表加载dfs数据至分区表"><a href="#利用外部表加载dfs数据至分区表" class="headerlink" title="利用外部表加载dfs数据至分区表"></a>利用外部表加载dfs数据至分区表</h4><blockquote><p>上述代码中有一步为load data 至hive。在于朋友交流中，他提醒可以直接利用<code>外部加载数据</code>，自此代码如下：</p></blockquote><h5 id="外部表好处"><a href="#外部表好处" class="headerlink" title="外部表好处"></a><code>外部表</code>好处</h5><ul><li>hive创建外部表时,仅记录数据所在的路径,不对数据的位置做任何改变</li><li>删除表的时候,外部表只删除元数据,不删除数据</li><li>内部表drop表会把元数据删除</li></ul><h5 id="Hive创建外部表"><a href="#Hive创建外部表" class="headerlink" title="Hive创建外部表"></a>Hive创建外部表</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---------------------------------java代码-----------------------------------------</span><br><span class="line">    /**</span><br><span class="line">     * 利用外部表加载数据   </span><br><span class="line">     *</span><br><span class="line">     * @param tableName     hive表名</span><br><span class="line">     * @param parametersMap 表字段值/类型</span><br><span class="line">     * @param dfsUrl        dfs文件地址</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public synchronized void createOuterHiveTable(String tableName, Map&lt;String, String&gt; parametersMap, String dfsUrl) &#123;</span><br><span class="line">        StringBuffer sql = new StringBuffer(&quot;CREATE EXTERNAL TABLE IF NOT EXISTS &quot;);</span><br><span class="line">        sql.append(&quot;&quot; + tableName + &quot;&quot;);</span><br><span class="line">        StringBuffer sb = new StringBuffer();</span><br><span class="line">        parametersMap.forEach((k, v) -&gt; &#123;</span><br><span class="line">            sb.append(k + &quot; &quot; + v + &quot;,&quot;);</span><br><span class="line">        &#125;);</span><br><span class="line">        sql.append(&quot;(&quot; + sb.deleteCharAt(sb.length() - 1) + &quot;)&quot;);</span><br><span class="line">        sql.append(&quot; PARTITIONED BY (day STRING)&quot;);</span><br><span class="line">        sql.append(&quot; ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; &quot; +</span><br><span class="line">                &quot; COLLECTION ITEMS TERMINATED BY &apos;\\002&apos;&quot; +</span><br><span class="line">                &quot; MAP KEYS TERMINATED BY &apos;\\003&apos;&quot; +</span><br><span class="line">                &quot; LINES TERMINATED BY &apos;\n&apos; &quot;); // 定义分隔符</span><br><span class="line">        sql.append(&quot;LOCATION &apos;&quot; + dfsUrl + &quot;&apos;&quot;); // 外部表加载hdfs数据目录</span><br><span class="line"></span><br><span class="line">        Log.info(&quot;Create EXTERNAL table [&quot; + tableName + &quot;] successfully...&quot;);</span><br><span class="line">        try &#123;</span><br><span class="line">            hiveJdbcTemplate.execute(sql.toString());</span><br><span class="line">        &#125; catch (DataAccessException dae) &#123;</span><br><span class="line">            Log.error(dae.fillInStackTrace());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">------------------------------------Sql---------------------------------------------</span><br><span class="line">    CREATE EXTERNAL TABLE IF NOT EXISTS  xx_outer_partitioned</span><br><span class="line">    (</span><br><span class="line">    affiliatedbasenum STRING,</span><br><span class="line">    locationid STRING,</span><br><span class="line">    pickupdate</span><br><span class="line">    dispatchingbasenum STRING</span><br><span class="line">    )</span><br><span class="line">    PARTITIONED BY (day STRING)</span><br><span class="line">    ROW FORMAT DELIMITED</span><br><span class="line">    FIELDS TERMINATED BY &apos;,&apos;</span><br><span class="line">    COLLECTION ITEMS TERMINATED BY &apos;\002&apos;</span><br><span class="line">    MAP KEYS TERMINATED BY &apos;\003&apos;</span><br><span class="line">    LINES TERMINATED BY &apos;\n&apos;</span><br><span class="line">    LOCATION &apos;/data/outerClientSummary/&apos;;</span><br></pre></td></tr></table></figure><h3 id="HIVE分析数据"><a href="#HIVE分析数据" class="headerlink" title="HIVE分析数据"></a>HIVE分析数据</h3><blockquote><p>hive支持sql操作（支持连表操作、排序），支持分区（此功能特别实用，比如数据量庞大时一般会按照天分表，此时就可以利用按天分区）</p></blockquote><h4 id="案列-：统计服装制造商主要城市分布-（因为hive字段与值对应错乱，但是导入至mysql不会错乱）"><a href="#案列-：统计服装制造商主要城市分布-（因为hive字段与值对应错乱，但是导入至mysql不会错乱）" class="headerlink" title="案列 ：统计服装制造商主要城市分布 （因为hive字段与值对应错乱，但是导入至mysql不会错乱）"></a><code>案列</code> ：统计服装制造商主要城市分布 （因为hive字段与值对应错乱，但是导入至mysql不会错乱）</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select count as addr,count(count)  from commodity20190315 GROUP BY count;</span><br><span class="line">广东广州361</span><br><span class="line">浙江杭州94</span><br><span class="line">广东深圳87</span><br><span class="line">上海76</span><br><span class="line">广东东莞74</span><br><span class="line">江苏苏州52</span><br><span class="line">浙江嘉兴24</span><br><span class="line">广东佛山22</span><br><span class="line">福建泉州15</span><br><span class="line">北京14</span><br><span class="line">天津13</span><br><span class="line">四川成都12</span><br><span class="line"></span><br><span class="line">....... 省略</span><br></pre></td></tr></table></figure><p><code>结果</code>：这是对一千多条的抽样调查，由此可见我们平时的衣物制造商地点<code>广东广州</code>居多。</p><h3 id="Sqoop-将分析后HIVE数据导出至MYSQL-主要思想："><a href="#Sqoop-将分析后HIVE数据导出至MYSQL-主要思想：" class="headerlink" title="Sqoop 将分析后HIVE数据导出至MYSQL 主要思想："></a>Sqoop 将分析后HIVE数据导出至MYSQL <code>主要思想</code>：</h3><blockquote><p>sqoop export –connect jdbc:mysql://IP地址:3306/mall –username root  –password 123456 –table commodity20190315 –export-dir /hivedata/warehouse/hive.db/commodity20190314 –input-fields-terminated-by ‘,’ –input-null-string ‘\N’ –input-null-non-string ‘\N’</p></blockquote><blockquote><p>此命令是经过一下错误原因完善出来的。</p></blockquote><p><code>--export-dir</code>：代表dfs文件目录，则是hive存储数据的地方<br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/dfs1.jpg" class="lozad"></p><p><code>错误原因1</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">19/03/15 09:20:25 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Error parsing arguments for export:</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Unrecognized argument: –input-null-string</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Unrecognized argument: \N</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Unrecognized argument: –input-null-non-string</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Unrecognized argument: \N</span><br><span class="line">19/03/15 09:20:25 ERROR tool.BaseSqoopTool: Unrecognized argument: –input-fields-terminated-by</span><br></pre></td></tr></table></figure></p><p><code>解决方式</code> ：命令输入错误，注意“-connect”应该是“–connect”杠</p><p><code>错误原因2</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">19/03/15 09:41:47 ERROR mapreduce.TextExportMapper: Exception:</span><br><span class="line">java.lang.RuntimeException: Can&apos;t parse input data: &apos;2019春季新款chic条纹套头毛衣女装学生韩版宽松显瘦百搭长袖上衣,39.98,42.98,广东 广州,350&apos;</span><br><span class="line">at commodity20190314.__loadFromFields(commodity20190314.java:487)</span><br><span class="line">at commodity20190314.parse(commodity20190314.java:386)</span><br><span class="line">at org.apache.sqoop.mapreduce.TextExportMapper.map(TextExportMapper.java:89)</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.lang.Exception: java.io.IOException: Can&apos;t export data, please check failed map task logs</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)</span><br><span class="line">Caused by: java.io.IOException: Can&apos;t export data, please check failed map task logs</span><br><span class="line">at org.apache.sqoop.mapreduce.TextExportMapper.map(TextExportMapper.java:122)</span><br><span class="line">at org.apache.sqoop.mapreduce.TextExportMapper.map(TextExportMapper.java:39)</span><br><span class="line">at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)</span><br><span class="line">at org.apache.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:64)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)</span><br><span class="line">at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)</span><br><span class="line">at java.lang.Thread.run(Thread.java:745)</span><br></pre></td></tr></table></figure><p><code>解决方式</code> ：检查数据是否包含“ ”空格，去掉空格，hive默认分割符–input-fields-terminated-by ‘,’，后续发现mysql表多了id，hive没有导致转码出错。</p><p><code>成功将HIVE数据导入MYSQL</code><br><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/hiveToMysql.jpg" class="lozad"></p><h2 id="统计-分析"><a href="#统计-分析" class="headerlink" title="统计/分析"></a>统计/分析</h2><blockquote><p>因数据量较小，则想利用python爬取数据，数据量偏少。则通过第三方地址下载。</p></blockquote><h3 id="爬取今日头条"><a href="#爬取今日头条" class="headerlink" title="爬取今日头条"></a>爬取今日头条</h3><blockquote><p>今日头条每天新闻信息在100条左右，最多抓取5天之内的数据。数据量极少。</p></blockquote><p><img data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/%E5%A4%B4%E6%9D%A1.jpg" class="lozad"></p><h3 id="HIVE数据分析"><a href="#HIVE数据分析" class="headerlink" title="HIVE数据分析"></a>HIVE数据分析</h3><p><code>数据集资源来源</code>:<a href="http://dataju.cn/Dataju/web/home" target="_blank" rel="noopener">http://dataju.cn/Dataju/web/home</a> 里面包含各种类数据集M-T级文件不等。是一个自娱自玩数据来源的好地址。</p><blockquote><p>总条数 <code>14270481</code> 条</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select count(*) from commodity20190320;</span><br><span class="line">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Query ID = root_20190320095041_1829fe55-336b-4481-a869-0b24ea274854</span><br><span class="line">Total jobs = 1</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks determined at compile time: 1</span><br><span class="line">In order to change the average load for a reducer (in bytes):</span><br><span class="line">set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line">In order to limit the maximum number of reducers:</span><br><span class="line">set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line">In order to set a constant number of reducers:</span><br><span class="line">set mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Job running in-process (local Hadoop)</span><br><span class="line">2019-03-20 09:50:43,908 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2019-03-20 09:50:45,926 Stage-1 map = 100%,  reduce = 0%</span><br><span class="line">2019-03-20 09:50:46,936 Stage-1 map = 100%,  reduce = 100%</span><br><span class="line">Ended Job = job_local1948148359_0001</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage-Stage-1:  HDFS Read: 4150522476 HDFS Write: 0 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 0 msec</span><br><span class="line">OK</span><br><span class="line">14270481</span><br><span class="line">Time taken: 6.276 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure><h4 id="按时间动态分区"><a href="#按时间动态分区" class="headerlink" title="按时间动态分区"></a>按时间动态分区</h4><blockquote><p><code>commodity20190320</code> 此表是通过csv导入的全量数据，包含了时间段。</p></blockquote><p><code>使用动态分区需要注意设定以下参数</code>：</p><ul><li>hive.exec.dynamic.partition  <ul><li><code>默认值</code>：false  </li><li><code>是否开启动态分区功能</code>: 默认false关闭</li></ul></li><li>hive.exec.dynamic.partition.mode  <ul><li><code>默认值</code>：strict  </li><li><code>动态分区的模式</code>，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。</li></ul></li><li>hive.exec.max.dynamic.partitions.pernode  <ul><li><code>默认值</code>：100</li><li>在每个执行MR的节点上，最大可以创建多少个动态分区。</li><li>该参数需要根据实际的数据来设定。</li><li>比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</li></ul></li><li>hive.exec.max.dynamic.partitions<ul><li><code>默认值</code>：1000</li><li>在所有执行MR的节点上，最大一共可以创建多少个动态分区。</li></ul></li><li>hive.exec.max.created.files<ul><li><code>默认值</code>：100000</li><li>整个MR Job中，最大可以创建多少个HDFS文件。</li><li>一般默认值足够了，除非你的数据量非常大，需要创建的文件数大于100000，可根据实际情况加以调整。</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//查看表结构</span><br><span class="line">    hive&gt; desc commodity20190320;</span><br><span class="line">    OK</span><br><span class="line">    affiliatedbasenum   string                                  </span><br><span class="line">    locationid          string                                  </span><br><span class="line">    pickupdate          string                                  </span><br><span class="line">    dispatchingbasenum  string                                  </span><br><span class="line">    Time taken: 0.044 seconds, Fetched: 4 row(s)</span><br><span class="line"></span><br><span class="line">//创建按月按天分区表</span><br><span class="line">    hive&gt; CREATE TABLE commodity_partitioned (</span><br><span class="line">        &gt; affiliatedbasenum STRING,</span><br><span class="line">        &gt; locationid STRING,</span><br><span class="line">        &gt; dispatchingbasenum STRING</span><br><span class="line">        &gt; ) PARTITIONED BY (month STRING,day STRING)</span><br><span class="line">        &gt; stored AS textfile;</span><br><span class="line">    OK</span><br><span class="line">    Time taken: 0.238 seconds</span><br><span class="line"></span><br><span class="line">//设置动态分区属性</span><br><span class="line">    hive&gt; SET hive.exec.dynamic.partition=true;  </span><br><span class="line">    hive&gt; SET hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line">    hive&gt; SET hive.exec.max.dynamic.partitions.pernode = 1000;</span><br><span class="line">    hive&gt; SET hive.exec.max.dynamic.partitions=1000;</span><br><span class="line"></span><br><span class="line">//时间格式 pickupdate = &quot;5/31/2014 23:59:00&quot; 按天分区则获取年月日即可。利用substr函数：substr(affiliatedbasenum,2,1) AS month,substr(affiliatedbasenum,2,9) AS day</span><br><span class="line">//向分区添加数据</span><br><span class="line">    hive&gt; INSERT overwrite TABLE commodity_partitioned PARTITION (month,day)</span><br><span class="line">        &gt; SELECT locationid,pickupdate,dispatchingbasenum,substr(affiliatedbasenum,2,1) AS month,substr(affiliatedbasenum,2,9) AS day</span><br><span class="line">        &gt; FROM commodity20190320;</span><br></pre></td></tr></table></figure><p><img data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/hive_partitions.gif" class="lozad"></p><h4 id="为外部表挂载分区"><a href="#为外部表挂载分区" class="headerlink" title="为外部表挂载分区"></a>为外部表挂载分区</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---------------------------------java代码-----------------------------------------</span><br><span class="line">    /**</span><br><span class="line">     * @param tableName 外部表名</span><br><span class="line">     * @param yyyyMMdd  分区标识</span><br><span class="line">     * @param dfsUrl    dfs地址</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void loadOuterHiveDataPartitions(String tableName, String yyyyMMdd, String dfsUrl) &#123;</span><br><span class="line">        StringBuffer sql = new StringBuffer(&quot;alter table &quot; + tableName);</span><br><span class="line">        sql.append(&quot; add partition (day=&apos;&quot; + yyyyMMdd + &quot;&apos;) location &apos;&quot; + dfsUrl + yyyyMMdd + &quot;/&apos;&quot;);</span><br><span class="line">        Log.info(&quot;Load data into OuterHiveDataPartitions successfully...&quot;);</span><br><span class="line">        try &#123;</span><br><span class="line">            hiveJdbcTemplate.execute(sql.toString());</span><br><span class="line">        &#125; catch (DataAccessException dae) &#123;</span><br><span class="line">            Log.error(dae.fillInStackTrace());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">---------------------------------Sql-----------------------------------------</span><br><span class="line">  alter table uber_outer_partitioned add partition (day=&apos;2019-03-21&apos;) location &apos;/data/outerClientSummary/2019-03-21&apos;</span><br></pre></td></tr></table></figure><p><img data-src="http://updatecg.oss-cn-beijing.aliyuncs.com/hive_outer_partitions.jpg" class="lozad"></p><p><code>注意</code>：分区数据支持sql查询</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对于大数据初学者的我，这才是我的第一步，都说万事开头难，坚持吧。</p><ul><li>知道如何把已有的数据采集到HDFS上，包括离线采集和实时采集；</li><li>知道sqoop是HDFS和其他数据源之间的数据交换工具,支持把数据在HDFS\HIVE\MYSQL互相传输；</li><li>知道Hadoop的MRV1与Yarn(MRV2)的区别，最主要的单点故障以及性能大大提升。<ul><li>JobTracker被RescourceManager替换</li><li>每一个节点的TaskTacker被NodeManager替换</li><li>Yarn大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗。</li><li>监测每一个 Job 子任务 (tasks) 状态的程序分布式化了</li></ul></li><li>Hive外部表被删除时，不会删除元数据，可以直接在外部表基础啊上创建分区表。</li><li>Hive一般作为数据仓库，几乎不会被用作与OLAP操作<ul><li>原因则在于hive数据量庞大时查询速度太慢.<code>下一章则会着重介绍</code>.</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;基于Hdfs、hive、mysql数据处理案例，闲时自玩项目&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;数据采集&quot;&gt;&lt;a href=&quot;#数据采集&quot; class=&quot;headerlink&quot; title=&quot;数据采集&quot;&gt;&lt;/a&gt;数据采集&lt;/h2&gt;
      
    
    </summary>
    
      <category term="大数据" scheme="http://www.updatecg.xin/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="http://www.updatecg.xin/tags/Hadoop/"/>
    
      <category term="Sqoop" scheme="http://www.updatecg.xin/tags/Sqoop/"/>
    
      <category term="Hive" scheme="http://www.updatecg.xin/tags/Hive/"/>
    
      <category term="Python" scheme="http://www.updatecg.xin/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>sqoop安装部署问题事项</title>
    <link href="http://www.updatecg.xin/2019/03/13/sqoop%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E9%97%AE%E9%A2%98%E4%BA%8B%E9%A1%B9/"/>
    <id>http://www.updatecg.xin/2019/03/13/sqoop安装部署问题事项/</id>
    <published>2019-03-13T03:02:00.000Z</published>
    <updated>2020-05-28T04:03:09.174Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中</p></blockquote><blockquote><p>sqoop主要有两个版本：1.4.x、1.99.x ; sqoop1和sqoop2两个版本。</p></blockquote><h2 id="环境变量配置无问题。-【以下问题是1-99-6版本，经过多方尝试，仍报错】"><a href="#环境变量配置无问题。-【以下问题是1-99-6版本，经过多方尝试，仍报错】" class="headerlink" title="环境变量配置无问题。 【以下问题是1.99.6版本，经过多方尝试，仍报错】"></a>环境变量配置无问题。 <spane style="color:red">【以下问题是1.99.6版本，经过多方尝试，仍报错】</spane></h2><blockquote><p>报错</p></blockquote><p>【-bash: sqoop: command not found】</p><ul><li>sqoop2中已经没有sqoop command指令了…sqoop指令是适用与sqoop1的</li></ul><h2 id="进入sqoop-sh-client，使用show-job-等。"><a href="#进入sqoop-sh-client，使用show-job-等。" class="headerlink" title="进入sqoop.sh client，使用show job 等。"></a>进入sqoop.sh client，使用show job 等。</h2><blockquote><p>报错</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop:000&gt; show job</span><br><span class="line">Exception has occurred during processing command</span><br><span class="line">Exception: org.apache.sqoop.common.SqoopException Message: CLIENT_0000:An unknown error has occurred</span><br></pre></td></tr></table></figure><ul><li><p>原因是没有指定服务端，需设置 set server –host 主机名或IP地址</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop:000&gt; set server --host 主机名或IP地址</span><br><span class="line">Server is set successfully</span><br></pre></td></tr></table></figure></li><li><p>可通过设置,查看错误原因</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop:000&gt; set option --name verbose --value true</span><br><span class="line">Verbose option was changed to true</span><br></pre></td></tr></table></figure></li></ul><h2 id="尝试利用sqoop2-1-99-7版本"><a href="#尝试利用sqoop2-1-99-7版本" class="headerlink" title="尝试利用sqoop2 1.99.7版本"></a>尝试利用sqoop2 1.99.7版本</h2><h2 id="下载地址-https-mirrors-tuna-tsinghua-edu-cn-apache-sqoop"><a href="#下载地址-https-mirrors-tuna-tsinghua-edu-cn-apache-sqoop" class="headerlink" title="下载地址 [https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/]"></a>下载地址 <a href="https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/" target="_blank" rel="noopener">[https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/]</a></h2><h3 id="配置好环境变量"><a href="#配置好环境变量" class="headerlink" title="配置好环境变量"></a>配置好环境变量</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export SQOOP2_HOME=/usr/local/sqoop/</span><br><span class="line">export PATH=$PATH:$SQOOP2_HOME/bin</span><br><span class="line">export CATALINA_BASE=$SQOOP2_HOME/server</span><br></pre></td></tr></table></figure><h3 id="修改-SQOOP2-HOME-conf-sqoop-properties"><a href="#修改-SQOOP2-HOME-conf-sqoop-properties" class="headerlink" title="修改 $SQOOP2_HOME/conf/sqoop.properties"></a>修改 $SQOOP2_HOME/conf/sqoop.properties</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.apache.sqoop.submission.engine.mapreduce.configuration.directory=/usr/local/hadoop-2.7.7/etc/hadoop</span><br><span class="line">org.apache.sqoop.security.authentication.type=SIMPLE</span><br><span class="line">org.apache.sqoop.security.authentication.handler=org.apache.sqoop.security.authentication.SimpleAuthenticationHandler</span><br><span class="line">org.apache.sqoop.security.authentication.anonymous=true</span><br><span class="line"># Number of milliseconds, submissions created before this limit will be removed, default is one day     //锁定提交的job时间，锁定时间内不能删除</span><br><span class="line">org.apache.sqoop.submission.purge.threshold=300000</span><br><span class="line"># JDBC repository provider configuration    //jdbc配置目录</span><br><span class="line">org.apache.sqoop.repository.jdbc.url=jdbc:derby:/usr/local/sqoop/logs/repository/db;create=true</span><br><span class="line">org.apache.sqoop.log4j.appender.file.File=/usr/local/sqoop/logs/sqoop.log                         //sqoop2日志文件目录</span><br><span class="line">org.apache.sqoop.repository.sysprop.derby.stream.error.file=/usr/local/sqoop/logs/derbyrepo.log   //错误日志文件目录</span><br></pre></td></tr></table></figure><h3 id="启动服务端-SQOOP2-HOME-bin-sqoop2-server-start"><a href="#启动服务端-SQOOP2-HOME-bin-sqoop2-server-start" class="headerlink" title="启动服务端 $SQOOP2_HOME/bin/sqoop2-server start"></a>启动服务端 $SQOOP2_HOME/bin/sqoop2-server start</h3><blockquote><p>报错</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Setting conf dir: /usr/local/sqoop/bin/../conf</span><br><span class="line">Sqoop home directory: /usr/local/sqoop</span><br><span class="line">Can&apos;t load the Hadoop related java lib, please check the setting for the following environment variables:</span><br><span class="line">HADOOP_COMMON_HOME, HADOOP_HDFS_HOME, HADOOP_MAPRED_HOME, HADOOP_YARN_HOME</span><br></pre></td></tr></table></figure><blockquote><p>检查Hadoop环境是否配置正确</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export HADOOP_HOME=/usr/local/hadoop-2.7.7</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin;</span><br></pre></td></tr></table></figure><p><span style="color:red"><code>注意</code></span>：配置这个变量主要是让Sqoop能找到以下目录的jar文件和Hadoop配置文件：</p><ul><li>$HADOOP_HOME/share/hadoop/common</li><li>$HADOOP_HOME/share/hadoop/hdfs</li><li>$HADOOP_HOME/share/hadoop/mapreduce</li><li>$HADOOP_HOME/share/hadoop/yarn</li></ul><p><span style="color:red"><br>官网上说名了可以单独对各个组建进行配置，使用以下变量：<br>$HADOOP_COMMON_HOME, $HADOOP_HDFS_HOME,  $HADOOP_MAPRED_HOME, $HADOOP_YARN_HOME<br>若$HADOOP_HOME已经配置了，最好不要再配置下面的变量，可能会有些莫名错误。<br></span></p><h4 id="查看是否启动成功方式有三种"><a href="#查看是否启动成功方式有三种" class="headerlink" title="查看是否启动成功方式有三种"></a>查看是否启动成功方式有三种</h4><ul><li><p>第一种查看日志</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# sqoop2-server start</span><br><span class="line">Setting conf dir: /usr/local/sqoop/bin/../conf</span><br><span class="line">Sqoop home directory: /usr/local/sqoop</span><br><span class="line">Starting the Sqoop2 server...</span><br><span class="line">0    [main] INFO  org.apache.sqoop.core.SqoopServer  - Initializing Sqoop server.</span><br><span class="line">5    [main] INFO  org.apache.sqoop.core.PropertiesConfigurationProvider  - Starting config file poller thread</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/usr/local/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">Sqoop2 server started.</span><br></pre></td></tr></table></figure></li><li><p>第二种执行访问 <a href="http://IP地址:12000/sqoop/version" target="_blank" rel="noopener">http://IP地址:12000/sqoop/version</a></p></li><li>第三种执行JPS命令查看进程：Bootstrap、SqoopJettyServer<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# jps</span><br><span class="line">22402 RunJar</span><br><span class="line">5861 Jps</span><br><span class="line">11848 NamesrvStartup</span><br><span class="line">2936 DataNode</span><br><span class="line">3513 jenkins.war</span><br><span class="line">5561 SqoopJettyServer</span><br><span class="line">2060 NameNode</span><br><span class="line">22317 RunJar</span><br><span class="line">12285 JswLauncher</span><br><span class="line">12686 NodeManager</span><br><span class="line">12399 ResourceManager</span><br><span class="line">5135 Bootstrap</span><br></pre></td></tr></table></figure></li></ul><h3 id="启动客户端-SQOOP2-HOME-bin-sqoop2-shell"><a href="#启动客户端-SQOOP2-HOME-bin-sqoop2-shell" class="headerlink" title="启动客户端 $SQOOP2_HOME/bin/sqoop2-shell"></a>启动客户端 $SQOOP2_HOME/bin/sqoop2-shell</h3><blockquote><p>再次尝试 show job、show connector 没有报错 这说明安装部署成功</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqoop:000&gt; show connector</span><br><span class="line">0    [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">+------------------------+---------+------------------------------------------------------------+----------------------+</span><br><span class="line">|          Name          | Version |                           Class                            | Supported Directions |</span><br><span class="line">+------------------------+---------+------------------------------------------------------------+----------------------+</span><br><span class="line">| generic-jdbc-connector | 1.99.7  | org.apache.sqoop.connector.jdbc.GenericJdbcConnector       | FROM/TO              |</span><br><span class="line">| kite-connector         | 1.99.7  | org.apache.sqoop.connector.kite.KiteConnector              | FROM/TO              |</span><br><span class="line">| oracle-jdbc-connector  | 1.99.7  | org.apache.sqoop.connector.jdbc.oracle.OracleJdbcConnector | FROM/TO              |</span><br><span class="line">| ftp-connector          | 1.99.7  | org.apache.sqoop.connector.ftp.FtpConnector                | TO                   |</span><br><span class="line">| hdfs-connector         | 1.99.7  | org.apache.sqoop.connector.hdfs.HdfsConnector              | FROM/TO              |</span><br><span class="line">| kafka-connector        | 1.99.7  | org.apache.sqoop.connector.kafka.KafkaConnector            | TO                   |</span><br><span class="line">| sftp-connector         | 1.99.7  | org.apache.sqoop.connector.sftp.SftpConnector              | TO                   |</span><br><span class="line">+------------------------+---------+------------------------------------------------------------+----------------------+</span><br><span class="line">sqoop:000&gt; show job</span><br><span class="line">+----+------+----------------+--------------+---------+</span><br><span class="line">| Id | Name | From Connector | To Connector | Enabled |</span><br><span class="line">+----+------+----------------+--------------+---------+</span><br><span class="line">+----+------+----------------+--------------+---------+</span><br></pre></td></tr></table></figure><h3 id="尝试后"><a href="#尝试后" class="headerlink" title="尝试后"></a>尝试后</h3><blockquote><p>我想要的功能是将hive数据移入mysql，经对sqoop2的使用发现，sqoop2并不支持。遗憾。接下来将尝试sqoop1。</p></blockquote><h3 id="区别在于"><a href="#区别在于" class="headerlink" title="区别在于"></a>区别在于</h3><table><thead><tr><th>功能</th><th>Sqoop 1</th><th>Sqoop 2</th></tr></thead><tbody><tr><td>用于所有主要 RDBMS 的连接器</td><td>支持</td><td>不支持  解决办法： 使用已在以下数据库上执行测试的通用 JDBC 连接器： Microsoft SQL Server 、 PostgreSQL 、 MySQL 和 Oracle 。 此连接器应在任何其它符合 JDBC 要求的数据库上运行。但是，性能可能无法与 Sqoop 中的专用连接器相比</td></tr><tr><td>Kerberos 安全集成</td><td>支持</td><td>不支持</td></tr><tr><td>数据从 RDBMS 传输至 Hive 或 HBase</td><td>支持</td><td>不支持 解决办法： 按照此两步方法操作。 将数据从 RDBMS 导入 HDFS 在 Hive 中使用相应的工具和命令（例如 LOAD DATA 语句），手动将数据载入 Hive 或 HBase</td></tr><tr><td>数据从 Hive 或 HBase 传输至 RDBMS</td><td>不支持 解决办法： 按照此两步方法操作。 从 Hive 或 HBase 将数据提取至 HDFS （作为文本或 Avro 文件） 使用 Sqoop 将上一步的输出导出至 RDBMS</td><td>不支持 按照与 Sqoop 1 相同的解决方法操作</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数
      
    
    </summary>
    
      <category term="大数据" scheme="http://www.updatecg.xin/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Sqoop" scheme="http://www.updatecg.xin/tags/Sqoop/"/>
    
      <category term="Hive" scheme="http://www.updatecg.xin/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>性能调优参数</title>
    <link href="http://www.updatecg.xin/2019/01/24/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0/"/>
    <id>http://www.updatecg.xin/2019/01/24/性能调优参数/</id>
    <published>2019-01-24T01:00:00.000Z</published>
    <updated>2020-05-28T04:03:09.590Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>堆内存性能、垃圾回收性能</p></blockquote><h1 id="堆内存性能优化参数"><a href="#堆内存性能优化参数" class="headerlink" title="堆内存性能优化参数"></a>堆内存性能优化参数</h1><table><thead><tr><th>参数</th><th style="text-align:right">含义</th><th style="text-align:center">案例</th></tr></thead><tbody><tr><td>-Xmx</td><td style="text-align:right">设置JVM 最大堆内存</td><td style="text-align:center">-Xmx3550m</td></tr><tr><td>-Xms</td><td style="text-align:right">设置JVM 初始堆内存,此值可以设置与-Xmx相同,以避免每次垃圾回收完成后JVM重新分配内存</td><td style="text-align:center">-Xms3550m</td></tr><tr><td>-Xss</td><td style="text-align:right">设置每个线程的栈大小.JDK5.0以后每个线程栈大小为1M，之前每个线程栈大小为256K应当根据应用的线程所需内存大小进行调整在相同物理内存下。减小这个值能生成更多的线程但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右需要注意的是：当这个值被设置的较大（例如&gt; 2MB）时将会在很大程度上降低系统的性能</td><td style="text-align:center">-Xss128k</td></tr><tr><td>-Xmn</td><td style="text-align:right">设置年轻代。大小为2G在整个堆内存大小确定的情况下，增大年轻代将会减小年老代，反之亦然此值关系到JVM垃圾回收，对系统性能影响较大，官方推荐配置为整个堆大小的3/8</td><td style="text-align:center">-Xmn2g</td></tr><tr><td>-XX</td><td style="text-align:right">设置年轻代初始值为1024M</td><td style="text-align:center">-XX</td></tr><tr><td>-XX：MaxNewSize</td><td style="text-align:right">设置年轻代最大值</td><td style="text-align:center">-XX：MaxNewSize = 1024</td></tr><tr><td>-XX：PermSize</td><td style="text-align:right">设置持久代初始值</td><td style="text-align:center">-XX：PermSize = 256</td></tr><tr><td>-XX：MaxPermSize</td><td style="text-align:right">设置持久代最大值</td><td style="text-align:center">-XX：MaxPermSize = 256</td></tr><tr><td>-XX：NewRatio</td><td style="text-align:right">设置年轻代（包括1个伊甸和2个幸存者区）与年老代的比值</td><td style="text-align:center">-XX：NewRatio = 4(表示1:4)</td></tr><tr><td>-XX：SurvivorRatio</td><td style="text-align:right">设置年轻代中伊甸区与幸存者区的比值。表示2个幸存者区（JVM堆内存年轻代中默认有2个大小相等的幸存者区）与1个伊甸区的比值为2:4，即1个幸存者区占整个年轻代大小的1/6</td><td style="text-align:center">-XX：SurvivorRatio = 4</td></tr><tr><td>-XX：MaxTenuringThreshold</td><td style="text-align:right">表示一个对象如果在幸存者区（救助空间）移动了7次还没有被垃圾回收就进入年老代如果设置为0的话，则年轻代对象不经过幸存者区，直接进入年老代，对于需要大量常驻内存的应用，这样做可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在幸存者区进行多次复制，这样可以增加对象在年轻代存活时间，增加对象在年轻代被垃圾回收的概率，减少Full GC的频率，这样做可以在某种程度上提高服务稳定性。</td><td style="text-align:center">-XX：MaxTenuringThreshold = 7</td></tr></tbody></table><h1 id="垃圾回收性能优化参数"><a href="#垃圾回收性能优化参数" class="headerlink" title="垃圾回收性能优化参数"></a>垃圾回收性能优化参数</h1><table><thead><tr><th>参数</th><th style="text-align:right">含义</th><th style="text-align:center">案例</th></tr></thead><tbody><tr><td>-XX：+ UseSerialGC</td><td style="text-align:right">设置串行收集器</td><td style="text-align:center">-XX：+ UseSerialGC</td></tr><tr><td>-XX：+ UseParallelGC</td><td style="text-align:right">置为并行收集器此配置仅对年轻代有效即年轻代使用并行收集，而年老代仍使用串行收集。</td><td style="text-align:center">-XX：+ UseParallelGC</td></tr><tr><td>-XX：ParallelGCThreads</td><td style="text-align:right">配置并行收集器的线程数，即：同时有多少个线程一起进行垃圾回收此值建议配置与CPU数目相等。</td><td style="text-align:center">-XX：ParallelGCThreads = 20</td></tr><tr><td>-XX：+ UseParallelOldGC</td><td style="text-align:right">配置年老代垃圾收集方式为并行收集.JDK6.0开始支持对年老代并行收集。</td><td style="text-align:center">-XX：+ UseParallelOldGC</td></tr><tr><td>-XX：MaxGCPauseMillis</td><td style="text-align:right">设置每次年轻代代垃圾回收的最长时间（单位毫秒）如果无法满足此时间，JVM会自动调整年轻代大小，以满足此时间。</td><td style="text-align:center">-XX：MaxGCPauseMillis = 100</td></tr><tr><td>-XX：+ UseAdaptiveSizePolicy</td><td style="text-align:right">设置此选项后，并行收集器会自动调整年轻代伊甸区大小和幸存者区大小的比例，以达成目标系统规定的最低响应时间或者收集频率等指标此参数建议在使用并行收集器时，一直打开。</td><td style="text-align:center">-XX：+ UseAdaptiveSizePolicy</td></tr><tr><td>-XX：+ UseConcMarkSweepGC</td><td style="text-align:right">即CMS收集，设置年老代为并发收集的.cms收集是JDK1.4后期版本开始引入的新GC算法它的主要适合场景是对响应时间的重要性需求大于对吞吐量的需求，能够承受垃圾回收线程和应用线程共享CPU资源，并且应用中存在比较多的长生命周期对象的的的.cms收集的目标是尽量减少应用的暂停时间，减少全GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存。</td><td style="text-align:center">-XX：+ UseConcMarkSweepGC</td></tr><tr><td>-XX：+ UseParNewGC</td><td style="text-align:right">设置年轻代为并发收集可与CMS收集同时使用.JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此参数。</td><td style="text-align:center">-XX：+ UseSerialGC</td></tr><tr><td>-XX：CMSFullGCsBeforeCompaction</td><td style="text-align:right">由于并发收集器不对内存空间进行压缩和整理，所以运行一段时间并行收集以后会产生内存碎片，内存使用效率降低。此参数设置运行0次Full GC后对内存空间进行压缩和整理，即每次Full GC后立刻开始压缩和整理内存。</td><td style="text-align:center">-XX：CMSFullGCsBeforeCompaction = 0</td></tr><tr><td>-XX：+ UseCMSCompactAtFullCollection</td><td style="text-align:right">打开内存空间的压缩和整理，在Full GC后执行。可能会影响性能，但可以消除内存碎片。</td><td style="text-align:center">-XX：+ UseCMSCompactAtFullCollection</td></tr><tr><td>-XX：+ CMSIncrementalMode</td><td style="text-align:right">设置为增量收集模式一般适用于单CPU情况。</td><td style="text-align:center">-XX：+ CMSIncrementalMode</td></tr><tr><td>-XX：CMSInitiatingOccupancyFraction</td><td style="text-align:right">表示年老代内存空间使用到70％时就开始执行CMS收集，以确保年老代有足够的空间接纳来自年代代的对象，避免Full GC的发生。</td><td style="text-align:center">-XX：CMSInitiatingOccupancyFraction = 70</td></tr></tbody></table><h1 id="JVM服务参数调优实战"><a href="#JVM服务参数调优实战" class="headerlink" title="JVM服务参数调优实战"></a>JVM服务参数调优实战</h1><p>服务器配置：8 CPU，8G MEM，JDK 1.6.X<br>参数方案：-server -Xmx3550m -Xms3550m -Xmn1256m -Xss128k -XX：SurvivorRatio = 6 -XX：MaxPermSize = 256m -XX：ParallelGCThreads = 8 -XX：MaxTenuringThreshold = 0 -XX：+ UseConcMarkSweepGC<br>调优说明：</p><ul><li>-Xmx与-Xms相同以避免JVM反复重新申请内存。-XMX的大小约等于系统内存大小的一半，即充分利用系统资源，又给予系统安全运行的空间。</li><li>-Xmn1256m设置年轻代大小为1256MB。此值对系统性能影响较大，太阳官方推荐配置年轻代大小为整个堆的3/8。</li><li>-Xss128k设置较小的线程栈以支持创建更多的线程，支持海量访问，并提升系统性能。</li><li>-XX：SurvivorRatio = 6设置年轻代中Eden区与Survivor区的比值。系统默认是8，根据经验设置为6，则2个幸存者区与1个Eden区的比值为2：6，一个幸存者区占整个年轻代的1/8。</li><li>-XX：ParallelGCThreads = 8配置并行收集器的线程数，即同时8个线程一起进行垃圾回收。此值一般配置为与CPU数目相等。</li><li>-XX：MaxTenuringThreshold = 0设置垃圾最大年龄（在年轻代的存活次数）。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，可以提高效率;如果将此值设置为一个较大值，则年轻代对象会在幸存者区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概率根据被海量访问的动态网络应用之特点，其内存要么被缓存起来以减少直接访问数据库，要么被快速回收以支持高并发海量请求，因此其内存对象在年轻代存活多次意义不大，可以直接进入年老代，根据实际应用效果，在这里设置此值为0。</li><li>-XX：+ UseConcMarkSweepGC设置年老代为并发收集.CMS（ConcMarkSweepGC）收集的目标是尽量减少应用的暂停时间，减少完全GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存，适用于应用中存在比较多的长生命周期对象的情况。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;堆内存性能、垃圾回收性能&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;堆内存性能优化参数&quot;&gt;&lt;a href=&quot;#堆内存性能优化参数&quot; class=&quot;headerlink&quot; title=&quot;堆内存性能优化参数&quot;&gt;&lt;/a&gt;堆内存性能优化参数&lt;/h
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="架构师" scheme="http://www.updatecg.xin/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/"/>
    
  </entry>
  
  <entry>
    <title>微信支付宝支付经验以及相关坑</title>
    <link href="http://www.updatecg.xin/2018/11/29/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98%E5%AE%9D%E6%94%AF%E4%BB%98%E7%BB%8F%E9%AA%8C%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%9D%91/"/>
    <id>http://www.updatecg.xin/2018/11/29/微信支付宝支付经验以及相关坑/</id>
    <published>2018-11-29T06:00:02.000Z</published>
    <updated>2020-05-28T04:03:10.560Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>此片文章介绍对接微信、支付宝所遇到的问题以及经验之谈。</p></blockquote><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><table><thead><tr><th>支付类型</th><th>文档</th><th>对接难易程度</th><th>文档地址</th></tr></thead><tbody><tr><td>支付宝</td><td>文档写的不错</td><td>易</td><td><a href="https://docs.open.alipay.com/api_1/alipay.trade.fastpay.refund.query" target="_blank" rel="noopener">https://docs.open.alipay.com/api_1/alipay.trade.fastpay.refund.query</a></td></tr><tr><td>微信</td><td>不想说了</td><td>难（也不能说难应该是坑）</td><td><a href="https://pay.weixin.qq.com/wiki/doc/api/app/app.php?chapter=8_1" target="_blank" rel="noopener">https://pay.weixin.qq.com/wiki/doc/api/app/app.php?chapter=8_1</a></td></tr></tbody></table><h3 id="熟悉支付流程"><a href="#熟悉支付流程" class="headerlink" title="熟悉支付流程"></a>熟悉支付流程</h3><h4 id="支付宝"><a href="#支付宝" class="headerlink" title="支付宝"></a>支付宝</h4><p><img data-src="/img/ali.jpg" class="lozad"><br><a href="https://docs.open.alipay.com/20160728150111277227/intro" target="_blank" rel="noopener">[详情文档请参考]</a></p><h4 id="微信"><a href="#微信" class="headerlink" title="微信"></a>微信</h4><p><img data-src="/img/wx.png" class="lozad"><br><a href="https://pay.weixin.qq.com/wiki/doc/api/app/app.php?chapter=8_3" target="_blank" rel="noopener">[详情文档请参考]</a></p><h2 id="有萝卜有坑"><a href="#有萝卜有坑" class="headerlink" title="有萝卜有坑"></a>有萝卜有坑</h2><table><thead><tr><th>序号</th><th>类型</th><th>问题描述</th></tr></thead><tbody><tr><td>No1</td><td>支付宝</td><td>支付宝秘钥使用pkcs8加密方式，以及相关参数key配置。</td></tr><tr><td>No2</td><td>微信</td><td>微信key值一定要使用微信支付的key，不要用平台key。</td></tr><tr><td>No3</td><td>微信</td><td>一直报签名错误，下面详细介绍。</td></tr><tr><td>No4</td><td>微信</td><td>得到的签名一定要转MD5，然后在将其转换成大写，并且生成MD5必须要以UTF-8的方式。</td></tr><tr><td>No5</td><td>微信</td><td>订单金额需要转换成以分为单位。</td></tr><tr><td>No6</td><td>微信</td><td>且值为空的参数不参与签名。</td></tr><tr><td>No7</td><td>微信</td><td>参数需按ASCII码从小到大排序。</td></tr><tr><td>No8</td><td>微信</td><td>第二次签名认证参数已消息的格式。</td></tr><tr><td>No9</td><td>微信</td><td>第二次签名参数package，需要赋值Sign=WXPay</td></tr></tbody></table><h2 id="一句签名错误概括全部错误信息，我就弱弱的问句错误码有用么？"><a href="#一句签名错误概括全部错误信息，我就弱弱的问句错误码有用么？" class="headerlink" title="一句签名错误概括全部错误信息，我就弱弱的问句错误码有用么？"></a>一句签名错误概括全部错误信息，我就弱弱的问句错误码有用么？</h2><p>“验证签名错误”第一反应肯定是检测签名是否正确，<a href="https://pay.weixin.qq.com/wiki/doc/api/app/app.php?chapter=20_1" target="_blank" rel="noopener">[官方验证签名地址]</a>。<br>然而，这才刚刚开始，签名正确了还是特么的报“验证签名错误”。特么的把以上几点全部检测了“有萝卜有坑”，然并卵。上面说了<span style="color:red">签名验证有两次，这是第二次验证错误</span>,最后发现<span style="color:red">【传入微信端的时间戳参数 ios需要32位 安卓需要10位】</span>，笑哭。首先看见“验证签名错误”，肯定是服务端问题，然而呢。。。</p><h2 id="签名两次重要参数"><a href="#签名两次重要参数" class="headerlink" title="签名两次重要参数"></a>签名两次重要参数</h2><h3 id="第一次签名参数"><a href="#第一次签名参数" class="headerlink" title="第一次签名参数"></a>第一次签名参数</h3><p>得到sign并赋值pay.setSign(sign) ；接下来就是将pay对象转换成xml，调用统一下单接口进行统一支付，并将统一支付返回的xml转换成bean。<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">notify_url //回调地址</span><br><span class="line">time_start //交易起始时间</span><br><span class="line">time_expire //交易结束时间</span><br><span class="line">spbill_create_ip //IP地址</span><br><span class="line">trade_type //交易类型</span><br><span class="line">limit_pay //no_credit--指定不能使用信用卡支付</span><br><span class="line">appid //微信开放平台审核通过的应用APPID</span><br><span class="line">mch_id //微信支付分配的商户号</span><br><span class="line">nonce_str //随机字符串，不长于32位。</span><br><span class="line">sign_type //签名类型，目前支持HMAC-SHA256和MD5，默认为MD5</span><br><span class="line">body //商品描述交易字段格式根据不同的应用场景按照以下格式：APP——需传入应用市场上的APP名字-实际商品名称，天天爱消除-游戏充值。</span><br><span class="line">out_trade_no //订单号</span><br><span class="line">total_fee //交易金额默认为人民币交易，接口中参数支付金额单位为【分】，参数值不能带小数。</span><br><span class="line">sign //根据以上数据生成签名</span><br></pre></td></tr></table></figure></p><h3 id="第二次签名参数"><a href="#第二次签名参数" class="headerlink" title="第二次签名参数"></a>第二次签名参数</h3><p>统一下单成功会返回微信预支付订单号prepay_id，我们需要根据这个prepay_id进行二次签名，二次签名所用参数如下（不包括paySign）。<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">noncestr //随机字符串</span><br><span class="line">appid //微信开放平台审核通过的应用APPID</span><br><span class="line">timestamp //就是这B,传入微信端的时间戳参数 ios需要32位 安卓需要10位</span><br><span class="line">partnerid //商户号</span><br><span class="line">package //Sign=WXPay</span><br><span class="line">prepayid //微信预支付订单号prepay_id</span><br><span class="line">sign //根据以上数据生成签名</span><br></pre></td></tr></table></figure></p><h3 id="实例代码后续上传GitHub"><a href="#实例代码后续上传GitHub" class="headerlink" title="实例代码后续上传GitHub"></a>实例代码后续上传GitHub</h3><p>第三方文档能不能写专业第一，之前和中兴、华为对接一样，特么的文档写的一塌糊涂。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;此片文章介绍对接微信、支付宝所遇到的问题以及经验之谈。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h2&gt;&lt;ta
      
    
    </summary>
    
      <category term="工作" scheme="http://www.updatecg.xin/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
      <category term="支付" scheme="http://www.updatecg.xin/tags/%E6%94%AF%E4%BB%98/"/>
    
  </entry>
  
  <entry>
    <title>SpringCloud服务多实例注入Consul挂掉问题</title>
    <link href="http://www.updatecg.xin/2018/09/07/SpringCloud%E6%9C%8D%E5%8A%A1%E5%A4%9A%E5%AE%9E%E4%BE%8B%E6%B3%A8%E5%85%A5Consul%E6%8C%82%E6%8E%89%E9%97%AE%E9%A2%98/"/>
    <id>http://www.updatecg.xin/2018/09/07/SpringCloud服务多实例注入Consul挂掉问题/</id>
    <published>2018-09-07T05:25:02.000Z</published>
    <updated>2020-05-28T04:03:11.208Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>相信大家在使用SpringCloud服务的发现与注册，都会对Eureka、Zookeeper、Consul熟悉吧。18年7月份爆出了Eureka2.0不在对外开源的消息。相信会有一部分程序猿逐渐往Consul发展。这其中也包含小生我。</p></blockquote><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>SpringCloud+1.2.x时候最严重的一个问题，就是多实例注册的问题.</p><h2 id="原因概述"><a href="#原因概述" class="headerlink" title="原因概述"></a>原因概述</h2><p>主要原因是SpringCloud中Consul在注册的时候实例名采用了：服务名-端口号{spring.application.name}-{server.port}）的值，可以看到这个实例名如果不改变端口号的情况下，实例名都是相同的。由于Consul对实例唯一性的判断标准也有改变，在老版本的Consul中，对于实例名相同，但是服务地址不同，依然会认为是不同的实例。在Consul 1.2.x中，服务实例名成为了集群中的唯一标识。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>通过配置 spring.cloud.consul.discovery.instance-id 参数来实例命令规则。利用随机数来控制实例名。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spring.cloud.consul.discovery.instance-id=$&#123;spring.application.name&#125;-$&#123;random.int[10000,99999]&#125;</span><br></pre></td></tr></table></figure></p><h2 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h2><p><img data-src="https://updatecg.oss-cn-beijing.aliyuncs.com/consulpic.png" class="lozad"></p><p><span style="color:red;font-size:16px">! ! ! 效果图中的错误不必关注，那是因为外网问题</span></p><h2 id="SpringCloud注入与注册类别简单介绍"><a href="#SpringCloud注入与注册类别简单介绍" class="headerlink" title="SpringCloud注入与注册类别简单介绍"></a>SpringCloud注入与注册类别简单介绍</h2><table><thead><tr><th>Feature</th><th>Consul</th><th>zookeeper</th><th>euerka</th></tr></thead><tbody><tr><td>服务健康检查</td><td>服务状态，内存，硬盘等</td><td>(弱)长连接，keepalive</td><td>可配支持</td></tr><tr><td>多数据中心</td><td>支持</td><td>—</td><td>—</td></tr><tr><td>kv存储服务</td><td>支持</td><td>支持</td><td>—</td></tr><tr><td>一致性</td><td>raft</td><td>paxos</td><td>—</td></tr><tr><td>cap</td><td>ca</td><td>cp</td><td>ap</td></tr><tr><td>使用接口(多语言能力)</td><td>支持http和dns</td><td>客户端</td><td>http（sidecar）</td></tr><tr><td>watch支持</td><td>全量/支持long polling</td><td>支持</td><td>支持 long polling/大部分增量</td></tr><tr><td>自身监控</td><td>metrics</td><td>—</td><td>metrics</td></tr><tr><td>安全</td><td>acl /https</td><td>acl</td><td>—</td></tr><tr><td>spring cloud集成</td><td>已支持</td><td>已支持</td><td>已支持</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;相信大家在使用SpringCloud服务的发现与注册，都会对Eureka、Zookeeper、Consul熟悉吧。18年7月份爆出了Eureka2.0不在对外开源的消息。相信会有一部分程序猿逐渐往Consul发展。这其中也包含小生我。&lt;/p&gt;
&lt;/
      
    
    </summary>
    
      <category term="闲时" scheme="http://www.updatecg.xin/categories/%E9%97%B2%E6%97%B6/"/>
    
    
      <category term="SpringCloud" scheme="http://www.updatecg.xin/tags/SpringCloud/"/>
    
      <category term="Consul" scheme="http://www.updatecg.xin/tags/Consul/"/>
    
  </entry>
  
</feed>
